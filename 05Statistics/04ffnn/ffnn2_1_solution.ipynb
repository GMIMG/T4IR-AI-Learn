{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom FFNN\n",
    "#### 2) 여러개의 layer가 있는 FFNN\n",
    "이제 여러개의 layer가 있는 FFNN을 고려해보자.\n",
    "$$\\begin{aligned}\n",
    "s_1 &= x \\cdot w_1 + b_1,  &(b, h_1^1=2)\\\\\n",
    "h_1 &= f_1(s_1), &(b, h_1^1) \\\\\n",
    "s_2 &= h_1 \\cdot w_2 + b_2,  &(b, h_2^1=3) \\\\\n",
    "h_2 &= f_2(s_2),  &(b, h_2^1) \\\\\n",
    "s_3 &= h_2 \\cdot w_3 + b_3,  &(b, h_3^1 = 1) \\\\\n",
    "\\hat y &= f(s_3),  &(b, 1) \\\\\n",
    "e &= \\sum_i (\\hat y - y)^2, &(1, ) \\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_3} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial w_3}, &(h_2^1, h_3^1=1) \\\\\n",
    "&= h_2^T \\cdot \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right]\\\\\n",
    "(h_2^1, h_3^1=1) &= (b, h_2^1)^T \\cdot [(b, 1) \\times (b, 1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_2} &= \\cfrac{\\partial e}{\\partial \\hat y} \\cfrac{\\partial \\hat y}{\\partial s_3} \\cfrac{\\partial s_3}{\\partial h_2}, &(b, h_2^1) \\\\\n",
    "&= \\left[ 2(\\hat y - y) \\times f^{'}(s_3) \\right] \\cdot w_3 \\\\\n",
    "(b, h_2^1) &= [(b, 1) \\times (b, 1)] \\cdot (h_3^1=1, h_2^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial w_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial w_2}, &(h_1^1, h_2^1) \\\\\n",
    "&= h_1^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_1^1, h_2^1) &= (b, h_1^1)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\\\\\n",
    "& \\\\\n",
    "\\text{for b, }& \\text{ We assume } b \\cdot x_0, \\text{ and } x_0 = \\text{np.zeros(h.shape[-1])} \\\\\n",
    "\\cfrac {\\partial e}{\\partial b_2} &= \\cfrac {\\partial e}{\\partial h_2} \\cfrac{\\partial h_2}{\\partial s_2} \\cfrac{\\partial s_2}{\\partial b_2}, &(h_2^1,) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_2} \\times f_2^{'}(s_2) \\right]\\\\\n",
    "(h_2^1,) &= (b,)^T \\cdot [(b, h_2^1) \\times (b, h_2^1)]\n",
    "\\end{aligned}$$\n",
    "\n",
    "따라서 일반화를 하면:\n",
    "$$\\begin{aligned}\n",
    "\\cfrac {\\partial e}{\\partial w_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial w_i}, &(h_{i-1}^1, h_i^1) \\\\\n",
    "&= h_{i-1}^T \\cdot \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_{i-1}^1, h_i^1) &= (b, h_{i-1}^1)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial h_i} &= \\cfrac{\\partial e}{\\partial h_{i+1}} \\cfrac{\\partial h_{i+1}}{\\partial s_{i+1}} \\cfrac{\\partial s_{i+1}}{\\partial h_i}, &(b, h_2^1) \\\\\n",
    "&= \\left[ \\cfrac{\\partial e}{\\partial h_{i+1}}  \\times f^{'}(s_{i+1}) \\right] \\cdot w_{i+1}^T \\\\\n",
    "(b, h_i^1) &= [(b, h_{i+1}^1) \\times (b, h_{i+1}^1)] \\cdot (h_{i+1}^1, h_i^1)\\\\\n",
    "& \\\\\n",
    "\\cfrac {\\partial e}{\\partial b_i} &= \\cfrac {\\partial e}{\\partial h_i} \\cfrac{\\partial h_i}{\\partial s_i} \\cfrac{\\partial s_i}{\\partial b_i}, &(h_i^1, ) \\\\\n",
    "&= \\sum_b \\left[ \\cfrac {\\partial e}{\\partial h_i} \\times f_i^{'}(s_i) \\right]\\\\\n",
    "(h_i^1,) &= (b,)^T \\cdot [(b, h_i^1) \\times (b, h_i^1)]\n",
    "\\end{aligned}$$\n",
    "- $b_i$를 구할 때, np.sum(arr, axis=-1)을 사용하면 된다.\n",
    "- 아래 첨자가 없는 b는 batch size를 의미한다.\n",
    "\n",
    "이를 위해 propagate_forward(self, x)함수를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(1024,2)\n",
    "y_train = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_train ] )\n",
    "\n",
    "x_val = np.random.rand(32,2)\n",
    "y_val = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_val ] )\n",
    "\n",
    "x_test = np.array( [ [0.2, 0.1], [0.3, 0.1], [0.4, 0.1], [0.5, 0.1] ] )\n",
    "y_test = np.array( [ [3 * x[0] - 1.2 * x[1] + .5] for x in x_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 activation 함수 구현:\n",
    "$$\\begin{aligned}\n",
    "\\text{Linear}(x) &= x\\\\\n",
    "\\cfrac {\\partial \\text{Linear}(x)}{\\partial x} &= 1\\\\\n",
    "\\text{Sigmoid}(x) &= \\sigma (x) = \\cfrac {1}{1-\\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{Sigmoid}(x)}{\\partial x} &= \\sigma(x) * (1-\\sigma(x))\\\\\n",
    "\\text{tahn}(x) &= \\cfrac {\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}\\\\\n",
    "\\cfrac {\\partial \\text{tahn}(x)}{\\partial x} &= 1-\\text{tahn}^2(x)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x): # linear y = x\n",
    "    return x\n",
    "\n",
    "def linear_deriv(x): # derivative of y = x\n",
    "    return 1\n",
    "\n",
    "def sigmoid(x): # sigmoid\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x): # derivative of sigmoid\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x): # hyperbolicv tangent\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x): # derivative of hyperbolic tangent\n",
    "    return 1 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 위해 multi layer를 구현할 수 있도록 다음과 같은 절차에 따라 작성한다.\n",
    "\n",
    "1. layer를 추가할 수 있는 add 함수를 구현한다.\n",
    " - 인자로, output의 size인 units와 activation, activation_deriv를 갖는다.\n",
    " - 첫 layer는 반드시 input_dim을 지정해야 하며, 이후는 추론한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    \n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr # learning rate\n",
    "        # weights list\n",
    "        self.ws = []; self.bs = []\n",
    "        self.fs = []; self.f_derivs = []\n",
    "        self.nLayers = 0\n",
    "        \n",
    "    # layer를 추가하며, weights를 초기화하기\n",
    "    def add(self, units, activation=linear, activation_deriv=linear_deriv, \n",
    "            input_dim=None):\n",
    "        if input_dim == None:\n",
    "            if self.nLayers == 0:\n",
    "                raise ValueError\n",
    "            else:\n",
    "                input_dim = self.bs[-1].shape[0]\n",
    "        w = np.random.rand(input_dim, units) - .5\n",
    "        self.ws.append(w)\n",
    "        b = np.zeros(units)\n",
    "        self.bs.append(b)\n",
    "        self.fs.append(activation)\n",
    "        self.f_derivs.append(activation_deriv)\n",
    "        self.nLayers += 1\n",
    "        \n",
    "    # feed forwarding\n",
    "    def propagate_forward(self, x):\n",
    "        s = []; o=[]\n",
    "        for l in range(self.nLayers):\n",
    "            if l == 0:\n",
    "                z = x.dot(self.ws[l]) + self.bs[l]\n",
    "            else: \n",
    "                z = o[l-1].dot(self.ws[l]) + self.bs[l]\n",
    "            s.append(z)\n",
    "            o.append(self.fs[l](z))\n",
    "        return s, o\n",
    "\n",
    "    # predicting\n",
    "    def predict(self, x):\n",
    "        s, o = self.propagate_forward(x)\n",
    "        return o[-1] # output from the last layer\n",
    "\n",
    "    # train for one batch. x 자체가 batch\n",
    "    def train_on_batch(self, x, y, istrain=True):\n",
    "        # batch forward propagation\n",
    "        s, o = self.propagate_forward(x)\n",
    "        loss = 1/2 * np.sum((o[-1] - y)**2)\n",
    "        \n",
    "        # batch back propagatgion\n",
    "        if istrain:\n",
    "            nL = self.nLayers\n",
    "            dws = [0.] * nL; dbs = [0.] * nL; dos = [0.] * nL\n",
    "            N = x.shape[0]\n",
    "            \n",
    "            # for nL-1 last layer\n",
    "            dos[-1] = (o[-1] - y)\n",
    "            if nL == 1: \n",
    "                dws[-1] = x.T.dot(dos[-1] * self.f_derivs[-1](s[-1]))\n",
    "            else: \n",
    "                dws[-1] = o[-2].T.dot(dos[-1] * self.f_derivs[-1](s[-1]))\n",
    "            dbs[-1] = np.sum(dos[-1] * self.f_derivs[-1](s[-1]))\n",
    "            \n",
    "            if nL > 1:\n",
    "                for l in range(nL-2, -1, -1):\n",
    "                    dos[l] = (dos[l+1]*self.f_derivs[l+1](s[l+1])).dot(self.ws[l+1].T)\n",
    "                    if l == 0: dws[l] = x.T.dot(dos[l] * self.f_derivs[l](s[l]))\n",
    "                    else: dws[l] = o[l-1].T.dot(dos[l] * self.f_derivs[l](s[l]))\n",
    "                    dbs[l] = np.sum(dos[l] * self.f_derivs[l](s[l]))\n",
    "            \n",
    "            for l in range(nL-1, -1, -1):\n",
    "                dws[l] /= N; dbs[l] /= N\n",
    "                self.ws[l] -= self.lr * dws[l]; self.bs[l] -= self.lr * dbs[l]\n",
    "                \n",
    "        return loss\n",
    "\n",
    "    # epochs에 대해 batch 별로 학습하기\n",
    "    def fit(self, x, y, batch_size=16, epochs=5000, val_data=None):\n",
    "        Losses = {}\n",
    "        Losses[\"train_loss\"] = []\n",
    "        if val_data is not None:\n",
    "            Losses[\"val_loss\"] = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            Loss = 0\n",
    "            N = x.shape[0]\n",
    "            for j in range(0, N, batch_size):\n",
    "                x_batch = x[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                n = x_batch.shape[0]\n",
    "                Loss += (self.train_on_batch(x_batch, y_batch) / n)\n",
    "        \n",
    "            print(\"Train Loss at Epoch %d is %.8f\" %(i, Loss))\n",
    "            Losses[\"train_loss\"].append(Loss)\n",
    "            if val_data is not None:\n",
    "                val_N = val_data[0].shape[0]\n",
    "                val_loss = self.train_on_batch(*val_data, istrain=False) / val_N\n",
    "                print(\"Val Loss at Epoch %d is %.8f\" %(i, val_loss))\n",
    "                Losses[\"val_loss\"].append(val_loss)\n",
    "                \n",
    "        return Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로:\n",
    "- $h_0 = x$, $s_0 = x$, $f_0 = \\text{linear}$\n",
    "- $s_i = h_{i-1} \\cdot w_{i-1} + b_{i-1}$\n",
    "- $h_i = f_i(s_i)$ 로, 설정하면 코딩이 훨씬 쉬웠을 것이다.\n",
    "\n",
    "----\n",
    "2 > 3 > 3 > 1 layer를 갖는 FFNN의 인스턴스를 생성한다.\n",
    "- 출력 2개의 선형 활성함수를 갖는 첫 hidden layer 추가\n",
    "- 출력 3개의 sigmoid 활성함수를 갖는 둘째 hidden layer 추가\n",
    "- 출력 3개의 tanh 활성함수를 갖는 셋째 hidden layer 추가\n",
    "- 출력 1개의 선형 활성함수를 갖는 출력 layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNN(0.1)\n",
    "model.add(2, input_dim=2) # hidden layer\n",
    "model.add(3, sigmoid, sigmoid_deriv) # hidden layer\n",
    "model.add(3, tanh, tanh_deriv) # hidden layer\n",
    "model.add(1) # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 0 is 32.25786922\n",
      "Val Loss at Epoch 0 is 0.53363717\n",
      "Train Loss at Epoch 1 is 27.13516232\n",
      "Val Loss at Epoch 1 is 0.53317718\n",
      "Train Loss at Epoch 2 is 27.11714942\n",
      "Val Loss at Epoch 2 is 0.53285990\n",
      "Train Loss at Epoch 3 is 27.10194380\n",
      "Val Loss at Epoch 3 is 0.53259244\n",
      "Train Loss at Epoch 4 is 27.08796002\n",
      "Val Loss at Epoch 4 is 0.53233973\n",
      "Train Loss at Epoch 5 is 27.07388957\n",
      "Val Loss at Epoch 5 is 0.53206814\n",
      "Train Loss at Epoch 6 is 27.05840974\n",
      "Val Loss at Epoch 6 is 0.53173939\n",
      "Train Loss at Epoch 7 is 27.03990209\n",
      "Val Loss at Epoch 7 is 0.53130279\n",
      "Train Loss at Epoch 8 is 27.01604321\n",
      "Val Loss at Epoch 8 is 0.53068220\n",
      "Train Loss at Epoch 9 is 26.98305681\n",
      "Val Loss at Epoch 9 is 0.52975039\n",
      "Train Loss at Epoch 10 is 26.93412862\n",
      "Val Loss at Epoch 10 is 0.52827248\n",
      "Train Loss at Epoch 11 is 26.85560123\n",
      "Val Loss at Epoch 11 is 0.52576479\n",
      "Train Loss at Epoch 12 is 26.71647039\n",
      "Val Loss at Epoch 12 is 0.52108779\n",
      "Train Loss at Epoch 13 is 26.43356174\n",
      "Val Loss at Epoch 13 is 0.51101503\n",
      "Train Loss at Epoch 14 is 25.72139238\n",
      "Val Loss at Epoch 14 is 0.48356067\n",
      "Train Loss at Epoch 15 is 23.14052078\n",
      "Val Loss at Epoch 15 is 0.37316765\n",
      "Train Loss at Epoch 16 is 11.23614691\n",
      "Val Loss at Epoch 16 is 0.03927191\n",
      "Train Loss at Epoch 17 is 0.64779252\n",
      "Val Loss at Epoch 17 is 0.00452153\n",
      "Train Loss at Epoch 18 is 0.21236901\n",
      "Val Loss at Epoch 18 is 0.00341881\n",
      "Train Loss at Epoch 19 is 0.17150557\n",
      "Val Loss at Epoch 19 is 0.00287231\n",
      "Train Loss at Epoch 20 is 0.15203043\n",
      "Val Loss at Epoch 20 is 0.00251547\n",
      "Train Loss at Epoch 21 is 0.13984184\n",
      "Val Loss at Epoch 21 is 0.00227171\n",
      "Train Loss at Epoch 22 is 0.13139100\n",
      "Val Loss at Epoch 22 is 0.00209778\n",
      "Train Loss at Epoch 23 is 0.12505506\n",
      "Val Loss at Epoch 23 is 0.00196764\n",
      "Train Loss at Epoch 24 is 0.11997665\n",
      "Val Loss at Epoch 24 is 0.00186578\n",
      "Train Loss at Epoch 25 is 0.11568563\n",
      "Val Loss at Epoch 25 is 0.00178283\n",
      "Train Loss at Epoch 26 is 0.11191736\n",
      "Val Loss at Epoch 26 is 0.00171301\n",
      "Train Loss at Epoch 27 is 0.10851858\n",
      "Val Loss at Epoch 27 is 0.00165266\n",
      "Train Loss at Epoch 28 is 0.10539750\n",
      "Val Loss at Epoch 28 is 0.00159936\n",
      "Train Loss at Epoch 29 is 0.10249695\n",
      "Val Loss at Epoch 29 is 0.00155148\n",
      "Train Loss at Epoch 30 is 0.09977964\n",
      "Val Loss at Epoch 30 is 0.00150791\n",
      "Train Loss at Epoch 31 is 0.09721998\n",
      "Val Loss at Epoch 31 is 0.00146784\n",
      "Train Loss at Epoch 32 is 0.09479946\n",
      "Val Loss at Epoch 32 is 0.00143068\n",
      "Train Loss at Epoch 33 is 0.09250398\n",
      "Val Loss at Epoch 33 is 0.00139598\n",
      "Train Loss at Epoch 34 is 0.09032232\n",
      "Val Loss at Epoch 34 is 0.00136341\n",
      "Train Loss at Epoch 35 is 0.08824520\n",
      "Val Loss at Epoch 35 is 0.00133270\n",
      "Train Loss at Epoch 36 is 0.08626469\n",
      "Val Loss at Epoch 36 is 0.00130363\n",
      "Train Loss at Epoch 37 is 0.08437391\n",
      "Val Loss at Epoch 37 is 0.00127604\n",
      "Train Loss at Epoch 38 is 0.08256673\n",
      "Val Loss at Epoch 38 is 0.00124979\n",
      "Train Loss at Epoch 39 is 0.08083768\n",
      "Val Loss at Epoch 39 is 0.00122474\n",
      "Train Loss at Epoch 40 is 0.07918178\n",
      "Val Loss at Epoch 40 is 0.00120081\n",
      "Train Loss at Epoch 41 is 0.07759452\n",
      "Val Loss at Epoch 41 is 0.00117789\n",
      "Train Loss at Epoch 42 is 0.07607175\n",
      "Val Loss at Epoch 42 is 0.00115592\n",
      "Train Loss at Epoch 43 is 0.07460967\n",
      "Val Loss at Epoch 43 is 0.00113483\n",
      "Train Loss at Epoch 44 is 0.07320478\n",
      "Val Loss at Epoch 44 is 0.00111456\n",
      "Train Loss at Epoch 45 is 0.07185382\n",
      "Val Loss at Epoch 45 is 0.00109505\n",
      "Train Loss at Epoch 46 is 0.07055381\n",
      "Val Loss at Epoch 46 is 0.00107626\n",
      "Train Loss at Epoch 47 is 0.06930195\n",
      "Val Loss at Epoch 47 is 0.00105815\n",
      "Train Loss at Epoch 48 is 0.06809567\n",
      "Val Loss at Epoch 48 is 0.00104067\n",
      "Train Loss at Epoch 49 is 0.06693255\n",
      "Val Loss at Epoch 49 is 0.00102379\n",
      "Train Loss at Epoch 50 is 0.06581036\n",
      "Val Loss at Epoch 50 is 0.00100748\n",
      "Train Loss at Epoch 51 is 0.06472701\n",
      "Val Loss at Epoch 51 is 0.00099170\n",
      "Train Loss at Epoch 52 is 0.06368053\n",
      "Val Loss at Epoch 52 is 0.00097643\n",
      "Train Loss at Epoch 53 is 0.06266912\n",
      "Val Loss at Epoch 53 is 0.00096165\n",
      "Train Loss at Epoch 54 is 0.06169105\n",
      "Val Loss at Epoch 54 is 0.00094733\n",
      "Train Loss at Epoch 55 is 0.06074472\n",
      "Val Loss at Epoch 55 is 0.00093344\n",
      "Train Loss at Epoch 56 is 0.05982865\n",
      "Val Loss at Epoch 56 is 0.00091997\n",
      "Train Loss at Epoch 57 is 0.05894141\n",
      "Val Loss at Epoch 57 is 0.00090689\n",
      "Train Loss at Epoch 58 is 0.05808168\n",
      "Val Loss at Epoch 58 is 0.00089420\n",
      "Train Loss at Epoch 59 is 0.05724822\n",
      "Val Loss at Epoch 59 is 0.00088187\n",
      "Train Loss at Epoch 60 is 0.05643986\n",
      "Val Loss at Epoch 60 is 0.00086988\n",
      "Train Loss at Epoch 61 is 0.05565548\n",
      "Val Loss at Epoch 61 is 0.00085823\n",
      "Train Loss at Epoch 62 is 0.05489406\n",
      "Val Loss at Epoch 62 is 0.00084689\n",
      "Train Loss at Epoch 63 is 0.05415460\n",
      "Val Loss at Epoch 63 is 0.00083586\n",
      "Train Loss at Epoch 64 is 0.05343617\n",
      "Val Loss at Epoch 64 is 0.00082511\n",
      "Train Loss at Epoch 65 is 0.05273791\n",
      "Val Loss at Epoch 65 is 0.00081465\n",
      "Train Loss at Epoch 66 is 0.05205898\n",
      "Val Loss at Epoch 66 is 0.00080446\n",
      "Train Loss at Epoch 67 is 0.05139860\n",
      "Val Loss at Epoch 67 is 0.00079452\n",
      "Train Loss at Epoch 68 is 0.05075602\n",
      "Val Loss at Epoch 68 is 0.00078484\n",
      "Train Loss at Epoch 69 is 0.05013054\n",
      "Val Loss at Epoch 69 is 0.00077539\n",
      "Train Loss at Epoch 70 is 0.04952149\n",
      "Val Loss at Epoch 70 is 0.00076617\n",
      "Train Loss at Epoch 71 is 0.04892824\n",
      "Val Loss at Epoch 71 is 0.00075717\n",
      "Train Loss at Epoch 72 is 0.04835018\n",
      "Val Loss at Epoch 72 is 0.00074839\n",
      "Train Loss at Epoch 73 is 0.04778673\n",
      "Val Loss at Epoch 73 is 0.00073981\n",
      "Train Loss at Epoch 74 is 0.04723737\n",
      "Val Loss at Epoch 74 is 0.00073143\n",
      "Train Loss at Epoch 75 is 0.04670156\n",
      "Val Loss at Epoch 75 is 0.00072324\n",
      "Train Loss at Epoch 76 is 0.04617882\n",
      "Val Loss at Epoch 76 is 0.00071524\n",
      "Train Loss at Epoch 77 is 0.04566868\n",
      "Val Loss at Epoch 77 is 0.00070741\n",
      "Train Loss at Epoch 78 is 0.04517068\n",
      "Val Loss at Epoch 78 is 0.00069976\n",
      "Train Loss at Epoch 79 is 0.04468441\n",
      "Val Loss at Epoch 79 is 0.00069227\n",
      "Train Loss at Epoch 80 is 0.04420945\n",
      "Val Loss at Epoch 80 is 0.00068494\n",
      "Train Loss at Epoch 81 is 0.04374541\n",
      "Val Loss at Epoch 81 is 0.00067777\n",
      "Train Loss at Epoch 82 is 0.04329193\n",
      "Val Loss at Epoch 82 is 0.00067075\n",
      "Train Loss at Epoch 83 is 0.04284865\n",
      "Val Loss at Epoch 83 is 0.00066387\n",
      "Train Loss at Epoch 84 is 0.04241523\n",
      "Val Loss at Epoch 84 is 0.00065714\n",
      "Train Loss at Epoch 85 is 0.04199135\n",
      "Val Loss at Epoch 85 is 0.00065055\n",
      "Train Loss at Epoch 86 is 0.04157670\n",
      "Val Loss at Epoch 86 is 0.00064408\n",
      "Train Loss at Epoch 87 is 0.04117097\n",
      "Val Loss at Epoch 87 is 0.00063775\n",
      "Train Loss at Epoch 88 is 0.04077389\n",
      "Val Loss at Epoch 88 is 0.00063154\n",
      "Train Loss at Epoch 89 is 0.04038518\n",
      "Val Loss at Epoch 89 is 0.00062545\n",
      "Train Loss at Epoch 90 is 0.04000458\n",
      "Val Loss at Epoch 90 is 0.00061947\n",
      "Train Loss at Epoch 91 is 0.03963184\n",
      "Val Loss at Epoch 91 is 0.00061362\n",
      "Train Loss at Epoch 92 is 0.03926672\n",
      "Val Loss at Epoch 92 is 0.00060787\n",
      "Train Loss at Epoch 93 is 0.03890899\n",
      "Val Loss at Epoch 93 is 0.00060223\n",
      "Train Loss at Epoch 94 is 0.03855843\n",
      "Val Loss at Epoch 94 is 0.00059670\n",
      "Train Loss at Epoch 95 is 0.03821482\n",
      "Val Loss at Epoch 95 is 0.00059126\n",
      "Train Loss at Epoch 96 is 0.03787796\n",
      "Val Loss at Epoch 96 is 0.00058593\n",
      "Train Loss at Epoch 97 is 0.03754766\n",
      "Val Loss at Epoch 97 is 0.00058069\n",
      "Train Loss at Epoch 98 is 0.03722371\n",
      "Val Loss at Epoch 98 is 0.00057554\n",
      "Train Loss at Epoch 99 is 0.03690595\n",
      "Val Loss at Epoch 99 is 0.00057049\n",
      "Train Loss at Epoch 100 is 0.03659420\n",
      "Val Loss at Epoch 100 is 0.00056553\n",
      "Train Loss at Epoch 101 is 0.03628828\n",
      "Val Loss at Epoch 101 is 0.00056065\n",
      "Train Loss at Epoch 102 is 0.03598804\n",
      "Val Loss at Epoch 102 is 0.00055585\n",
      "Train Loss at Epoch 103 is 0.03569332\n",
      "Val Loss at Epoch 103 is 0.00055114\n",
      "Train Loss at Epoch 104 is 0.03540397\n",
      "Val Loss at Epoch 104 is 0.00054651\n",
      "Train Loss at Epoch 105 is 0.03511984\n",
      "Val Loss at Epoch 105 is 0.00054195\n",
      "Train Loss at Epoch 106 is 0.03484079\n",
      "Val Loss at Epoch 106 is 0.00053747\n",
      "Train Loss at Epoch 107 is 0.03456670\n",
      "Val Loss at Epoch 107 is 0.00053306\n",
      "Train Loss at Epoch 108 is 0.03429742\n",
      "Val Loss at Epoch 108 is 0.00052873\n",
      "Train Loss at Epoch 109 is 0.03403283\n",
      "Val Loss at Epoch 109 is 0.00052447\n",
      "Train Loss at Epoch 110 is 0.03377281\n",
      "Val Loss at Epoch 110 is 0.00052027\n",
      "Train Loss at Epoch 111 is 0.03351724\n",
      "Val Loss at Epoch 111 is 0.00051614\n",
      "Train Loss at Epoch 112 is 0.03326601\n",
      "Val Loss at Epoch 112 is 0.00051208\n",
      "Train Loss at Epoch 113 is 0.03301902\n",
      "Val Loss at Epoch 113 is 0.00050808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 114 is 0.03277614\n",
      "Val Loss at Epoch 114 is 0.00050414\n",
      "Train Loss at Epoch 115 is 0.03253729\n",
      "Val Loss at Epoch 115 is 0.00050027\n",
      "Train Loss at Epoch 116 is 0.03230236\n",
      "Val Loss at Epoch 116 is 0.00049645\n",
      "Train Loss at Epoch 117 is 0.03207125\n",
      "Val Loss at Epoch 117 is 0.00049269\n",
      "Train Loss at Epoch 118 is 0.03184388\n",
      "Val Loss at Epoch 118 is 0.00048899\n",
      "Train Loss at Epoch 119 is 0.03162015\n",
      "Val Loss at Epoch 119 is 0.00048535\n",
      "Train Loss at Epoch 120 is 0.03139998\n",
      "Val Loss at Epoch 120 is 0.00048175\n",
      "Train Loss at Epoch 121 is 0.03118328\n",
      "Val Loss at Epoch 121 is 0.00047822\n",
      "Train Loss at Epoch 122 is 0.03096997\n",
      "Val Loss at Epoch 122 is 0.00047473\n",
      "Train Loss at Epoch 123 is 0.03075998\n",
      "Val Loss at Epoch 123 is 0.00047129\n",
      "Train Loss at Epoch 124 is 0.03055321\n",
      "Val Loss at Epoch 124 is 0.00046791\n",
      "Train Loss at Epoch 125 is 0.03034961\n",
      "Val Loss at Epoch 125 is 0.00046457\n",
      "Train Loss at Epoch 126 is 0.03014910\n",
      "Val Loss at Epoch 126 is 0.00046128\n",
      "Train Loss at Epoch 127 is 0.02995161\n",
      "Val Loss at Epoch 127 is 0.00045804\n",
      "Train Loss at Epoch 128 is 0.02975707\n",
      "Val Loss at Epoch 128 is 0.00045484\n",
      "Train Loss at Epoch 129 is 0.02956541\n",
      "Val Loss at Epoch 129 is 0.00045168\n",
      "Train Loss at Epoch 130 is 0.02937658\n",
      "Val Loss at Epoch 130 is 0.00044858\n",
      "Train Loss at Epoch 131 is 0.02919051\n",
      "Val Loss at Epoch 131 is 0.00044551\n",
      "Train Loss at Epoch 132 is 0.02900713\n",
      "Val Loss at Epoch 132 is 0.00044248\n",
      "Train Loss at Epoch 133 is 0.02882640\n",
      "Val Loss at Epoch 133 is 0.00043950\n",
      "Train Loss at Epoch 134 is 0.02864826\n",
      "Val Loss at Epoch 134 is 0.00043656\n",
      "Train Loss at Epoch 135 is 0.02847264\n",
      "Val Loss at Epoch 135 is 0.00043365\n",
      "Train Loss at Epoch 136 is 0.02829950\n",
      "Val Loss at Epoch 136 is 0.00043079\n",
      "Train Loss at Epoch 137 is 0.02812878\n",
      "Val Loss at Epoch 137 is 0.00042796\n",
      "Train Loss at Epoch 138 is 0.02796044\n",
      "Val Loss at Epoch 138 is 0.00042517\n",
      "Train Loss at Epoch 139 is 0.02779442\n",
      "Val Loss at Epoch 139 is 0.00042242\n",
      "Train Loss at Epoch 140 is 0.02763068\n",
      "Val Loss at Epoch 140 is 0.00041970\n",
      "Train Loss at Epoch 141 is 0.02746916\n",
      "Val Loss at Epoch 141 is 0.00041702\n",
      "Train Loss at Epoch 142 is 0.02730984\n",
      "Val Loss at Epoch 142 is 0.00041437\n",
      "Train Loss at Epoch 143 is 0.02715265\n",
      "Val Loss at Epoch 143 is 0.00041176\n",
      "Train Loss at Epoch 144 is 0.02699756\n",
      "Val Loss at Epoch 144 is 0.00040918\n",
      "Train Loss at Epoch 145 is 0.02684453\n",
      "Val Loss at Epoch 145 is 0.00040663\n",
      "Train Loss at Epoch 146 is 0.02669351\n",
      "Val Loss at Epoch 146 is 0.00040411\n",
      "Train Loss at Epoch 147 is 0.02654447\n",
      "Val Loss at Epoch 147 is 0.00040163\n",
      "Train Loss at Epoch 148 is 0.02639736\n",
      "Val Loss at Epoch 148 is 0.00039918\n",
      "Train Loss at Epoch 149 is 0.02625216\n",
      "Val Loss at Epoch 149 is 0.00039675\n",
      "Train Loss at Epoch 150 is 0.02610882\n",
      "Val Loss at Epoch 150 is 0.00039436\n",
      "Train Loss at Epoch 151 is 0.02596731\n",
      "Val Loss at Epoch 151 is 0.00039199\n",
      "Train Loss at Epoch 152 is 0.02582759\n",
      "Val Loss at Epoch 152 is 0.00038966\n",
      "Train Loss at Epoch 153 is 0.02568962\n",
      "Val Loss at Epoch 153 is 0.00038735\n",
      "Train Loss at Epoch 154 is 0.02555339\n",
      "Val Loss at Epoch 154 is 0.00038507\n",
      "Train Loss at Epoch 155 is 0.02541885\n",
      "Val Loss at Epoch 155 is 0.00038282\n",
      "Train Loss at Epoch 156 is 0.02528597\n",
      "Val Loss at Epoch 156 is 0.00038059\n",
      "Train Loss at Epoch 157 is 0.02515473\n",
      "Val Loss at Epoch 157 is 0.00037839\n",
      "Train Loss at Epoch 158 is 0.02502508\n",
      "Val Loss at Epoch 158 is 0.00037621\n",
      "Train Loss at Epoch 159 is 0.02489701\n",
      "Val Loss at Epoch 159 is 0.00037407\n",
      "Train Loss at Epoch 160 is 0.02477049\n",
      "Val Loss at Epoch 160 is 0.00037194\n",
      "Train Loss at Epoch 161 is 0.02464548\n",
      "Val Loss at Epoch 161 is 0.00036984\n",
      "Train Loss at Epoch 162 is 0.02452196\n",
      "Val Loss at Epoch 162 is 0.00036777\n",
      "Train Loss at Epoch 163 is 0.02439990\n",
      "Val Loss at Epoch 163 is 0.00036571\n",
      "Train Loss at Epoch 164 is 0.02427929\n",
      "Val Loss at Epoch 164 is 0.00036369\n",
      "Train Loss at Epoch 165 is 0.02416008\n",
      "Val Loss at Epoch 165 is 0.00036168\n",
      "Train Loss at Epoch 166 is 0.02404226\n",
      "Val Loss at Epoch 166 is 0.00035970\n",
      "Train Loss at Epoch 167 is 0.02392581\n",
      "Val Loss at Epoch 167 is 0.00035774\n",
      "Train Loss at Epoch 168 is 0.02381070\n",
      "Val Loss at Epoch 168 is 0.00035580\n",
      "Train Loss at Epoch 169 is 0.02369690\n",
      "Val Loss at Epoch 169 is 0.00035388\n",
      "Train Loss at Epoch 170 is 0.02358440\n",
      "Val Loss at Epoch 170 is 0.00035198\n",
      "Train Loss at Epoch 171 is 0.02347318\n",
      "Val Loss at Epoch 171 is 0.00035011\n",
      "Train Loss at Epoch 172 is 0.02336320\n",
      "Val Loss at Epoch 172 is 0.00034825\n",
      "Train Loss at Epoch 173 is 0.02325446\n",
      "Val Loss at Epoch 173 is 0.00034642\n",
      "Train Loss at Epoch 174 is 0.02314692\n",
      "Val Loss at Epoch 174 is 0.00034460\n",
      "Train Loss at Epoch 175 is 0.02304058\n",
      "Val Loss at Epoch 175 is 0.00034281\n",
      "Train Loss at Epoch 176 is 0.02293541\n",
      "Val Loss at Epoch 176 is 0.00034103\n",
      "Train Loss at Epoch 177 is 0.02283138\n",
      "Val Loss at Epoch 177 is 0.00033927\n",
      "Train Loss at Epoch 178 is 0.02272850\n",
      "Val Loss at Epoch 178 is 0.00033753\n",
      "Train Loss at Epoch 179 is 0.02262672\n",
      "Val Loss at Epoch 179 is 0.00033581\n",
      "Train Loss at Epoch 180 is 0.02252605\n",
      "Val Loss at Epoch 180 is 0.00033411\n",
      "Train Loss at Epoch 181 is 0.02242645\n",
      "Val Loss at Epoch 181 is 0.00033243\n",
      "Train Loss at Epoch 182 is 0.02232791\n",
      "Val Loss at Epoch 182 is 0.00033076\n",
      "Train Loss at Epoch 183 is 0.02223042\n",
      "Val Loss at Epoch 183 is 0.00032911\n",
      "Train Loss at Epoch 184 is 0.02213396\n",
      "Val Loss at Epoch 184 is 0.00032748\n",
      "Train Loss at Epoch 185 is 0.02203851\n",
      "Val Loss at Epoch 185 is 0.00032586\n",
      "Train Loss at Epoch 186 is 0.02194406\n",
      "Val Loss at Epoch 186 is 0.00032426\n",
      "Train Loss at Epoch 187 is 0.02185059\n",
      "Val Loss at Epoch 187 is 0.00032268\n",
      "Train Loss at Epoch 188 is 0.02175808\n",
      "Val Loss at Epoch 188 is 0.00032111\n",
      "Train Loss at Epoch 189 is 0.02166653\n",
      "Val Loss at Epoch 189 is 0.00031956\n",
      "Train Loss at Epoch 190 is 0.02157592\n",
      "Val Loss at Epoch 190 is 0.00031802\n",
      "Train Loss at Epoch 191 is 0.02148623\n",
      "Val Loss at Epoch 191 is 0.00031650\n",
      "Train Loss at Epoch 192 is 0.02139744\n",
      "Val Loss at Epoch 192 is 0.00031500\n",
      "Train Loss at Epoch 193 is 0.02130955\n",
      "Val Loss at Epoch 193 is 0.00031350\n",
      "Train Loss at Epoch 194 is 0.02122255\n",
      "Val Loss at Epoch 194 is 0.00031203\n",
      "Train Loss at Epoch 195 is 0.02113641\n",
      "Val Loss at Epoch 195 is 0.00031057\n",
      "Train Loss at Epoch 196 is 0.02105113\n",
      "Val Loss at Epoch 196 is 0.00030912\n",
      "Train Loss at Epoch 197 is 0.02096670\n",
      "Val Loss at Epoch 197 is 0.00030769\n",
      "Train Loss at Epoch 198 is 0.02088309\n",
      "Val Loss at Epoch 198 is 0.00030627\n",
      "Train Loss at Epoch 199 is 0.02080030\n",
      "Val Loss at Epoch 199 is 0.00030486\n",
      "Train Loss at Epoch 200 is 0.02071833\n",
      "Val Loss at Epoch 200 is 0.00030347\n",
      "Train Loss at Epoch 201 is 0.02063714\n",
      "Val Loss at Epoch 201 is 0.00030209\n",
      "Train Loss at Epoch 202 is 0.02055674\n",
      "Val Loss at Epoch 202 is 0.00030072\n",
      "Train Loss at Epoch 203 is 0.02047712\n",
      "Val Loss at Epoch 203 is 0.00029937\n",
      "Train Loss at Epoch 204 is 0.02039826\n",
      "Val Loss at Epoch 204 is 0.00029803\n",
      "Train Loss at Epoch 205 is 0.02032014\n",
      "Val Loss at Epoch 205 is 0.00029670\n",
      "Train Loss at Epoch 206 is 0.02024277\n",
      "Val Loss at Epoch 206 is 0.00029539\n",
      "Train Loss at Epoch 207 is 0.02016613\n",
      "Val Loss at Epoch 207 is 0.00029408\n",
      "Train Loss at Epoch 208 is 0.02009021\n",
      "Val Loss at Epoch 208 is 0.00029279\n",
      "Train Loss at Epoch 209 is 0.02001500\n",
      "Val Loss at Epoch 209 is 0.00029152\n",
      "Train Loss at Epoch 210 is 0.01994050\n",
      "Val Loss at Epoch 210 is 0.00029025\n",
      "Train Loss at Epoch 211 is 0.01986668\n",
      "Val Loss at Epoch 211 is 0.00028899\n",
      "Train Loss at Epoch 212 is 0.01979354\n",
      "Val Loss at Epoch 212 is 0.00028775\n",
      "Train Loss at Epoch 213 is 0.01972108\n",
      "Val Loss at Epoch 213 is 0.00028652\n",
      "Train Loss at Epoch 214 is 0.01964928\n",
      "Val Loss at Epoch 214 is 0.00028529\n",
      "Train Loss at Epoch 215 is 0.01957814\n",
      "Val Loss at Epoch 215 is 0.00028408\n",
      "Train Loss at Epoch 216 is 0.01950764\n",
      "Val Loss at Epoch 216 is 0.00028288\n",
      "Train Loss at Epoch 217 is 0.01943777\n",
      "Val Loss at Epoch 217 is 0.00028169\n",
      "Train Loss at Epoch 218 is 0.01936854\n",
      "Val Loss at Epoch 218 is 0.00028052\n",
      "Train Loss at Epoch 219 is 0.01929993\n",
      "Val Loss at Epoch 219 is 0.00027935\n",
      "Train Loss at Epoch 220 is 0.01923193\n",
      "Val Loss at Epoch 220 is 0.00027819\n",
      "Train Loss at Epoch 221 is 0.01916453\n",
      "Val Loss at Epoch 221 is 0.00027704\n",
      "Train Loss at Epoch 222 is 0.01909773\n",
      "Val Loss at Epoch 222 is 0.00027590\n",
      "Train Loss at Epoch 223 is 0.01903152\n",
      "Val Loss at Epoch 223 is 0.00027478\n",
      "Train Loss at Epoch 224 is 0.01896589\n",
      "Val Loss at Epoch 224 is 0.00027366\n",
      "Train Loss at Epoch 225 is 0.01890083\n",
      "Val Loss at Epoch 225 is 0.00027255\n",
      "Train Loss at Epoch 226 is 0.01883634\n",
      "Val Loss at Epoch 226 is 0.00027145\n",
      "Train Loss at Epoch 227 is 0.01877241\n",
      "Val Loss at Epoch 227 is 0.00027036\n",
      "Train Loss at Epoch 228 is 0.01870903\n",
      "Val Loss at Epoch 228 is 0.00026928\n",
      "Train Loss at Epoch 229 is 0.01864620\n",
      "Val Loss at Epoch 229 is 0.00026821\n",
      "Train Loss at Epoch 230 is 0.01858390\n",
      "Val Loss at Epoch 230 is 0.00026715\n",
      "Train Loss at Epoch 231 is 0.01852214\n",
      "Val Loss at Epoch 231 is 0.00026610\n",
      "Train Loss at Epoch 232 is 0.01846090\n",
      "Val Loss at Epoch 232 is 0.00026505\n",
      "Train Loss at Epoch 233 is 0.01840018\n",
      "Val Loss at Epoch 233 is 0.00026402\n",
      "Train Loss at Epoch 234 is 0.01833997\n",
      "Val Loss at Epoch 234 is 0.00026299\n",
      "Train Loss at Epoch 235 is 0.01828027\n",
      "Val Loss at Epoch 235 is 0.00026197\n",
      "Train Loss at Epoch 236 is 0.01822107\n",
      "Val Loss at Epoch 236 is 0.00026096\n",
      "Train Loss at Epoch 237 is 0.01816236\n",
      "Val Loss at Epoch 237 is 0.00025996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 238 is 0.01810414\n",
      "Val Loss at Epoch 238 is 0.00025897\n",
      "Train Loss at Epoch 239 is 0.01804640\n",
      "Val Loss at Epoch 239 is 0.00025798\n",
      "Train Loss at Epoch 240 is 0.01798913\n",
      "Val Loss at Epoch 240 is 0.00025701\n",
      "Train Loss at Epoch 241 is 0.01793234\n",
      "Val Loss at Epoch 241 is 0.00025604\n",
      "Train Loss at Epoch 242 is 0.01787601\n",
      "Val Loss at Epoch 242 is 0.00025508\n",
      "Train Loss at Epoch 243 is 0.01782014\n",
      "Val Loss at Epoch 243 is 0.00025412\n",
      "Train Loss at Epoch 244 is 0.01776473\n",
      "Val Loss at Epoch 244 is 0.00025318\n",
      "Train Loss at Epoch 245 is 0.01770976\n",
      "Val Loss at Epoch 245 is 0.00025224\n",
      "Train Loss at Epoch 246 is 0.01765524\n",
      "Val Loss at Epoch 246 is 0.00025131\n",
      "Train Loss at Epoch 247 is 0.01760115\n",
      "Val Loss at Epoch 247 is 0.00025038\n",
      "Train Loss at Epoch 248 is 0.01754750\n",
      "Val Loss at Epoch 248 is 0.00024947\n",
      "Train Loss at Epoch 249 is 0.01749427\n",
      "Val Loss at Epoch 249 is 0.00024856\n",
      "Train Loss at Epoch 250 is 0.01744147\n",
      "Val Loss at Epoch 250 is 0.00024766\n",
      "Train Loss at Epoch 251 is 0.01738909\n",
      "Val Loss at Epoch 251 is 0.00024676\n",
      "Train Loss at Epoch 252 is 0.01733712\n",
      "Val Loss at Epoch 252 is 0.00024588\n",
      "Train Loss at Epoch 253 is 0.01728556\n",
      "Val Loss at Epoch 253 is 0.00024499\n",
      "Train Loss at Epoch 254 is 0.01723440\n",
      "Val Loss at Epoch 254 is 0.00024412\n",
      "Train Loss at Epoch 255 is 0.01718365\n",
      "Val Loss at Epoch 255 is 0.00024325\n",
      "Train Loss at Epoch 256 is 0.01713328\n",
      "Val Loss at Epoch 256 is 0.00024239\n",
      "Train Loss at Epoch 257 is 0.01708331\n",
      "Val Loss at Epoch 257 is 0.00024154\n",
      "Train Loss at Epoch 258 is 0.01703373\n",
      "Val Loss at Epoch 258 is 0.00024069\n",
      "Train Loss at Epoch 259 is 0.01698453\n",
      "Val Loss at Epoch 259 is 0.00023985\n",
      "Train Loss at Epoch 260 is 0.01693570\n",
      "Val Loss at Epoch 260 is 0.00023901\n",
      "Train Loss at Epoch 261 is 0.01688725\n",
      "Val Loss at Epoch 261 is 0.00023818\n",
      "Train Loss at Epoch 262 is 0.01683917\n",
      "Val Loss at Epoch 262 is 0.00023736\n",
      "Train Loss at Epoch 263 is 0.01679146\n",
      "Val Loss at Epoch 263 is 0.00023655\n",
      "Train Loss at Epoch 264 is 0.01674410\n",
      "Val Loss at Epoch 264 is 0.00023573\n",
      "Train Loss at Epoch 265 is 0.01669711\n",
      "Val Loss at Epoch 265 is 0.00023493\n",
      "Train Loss at Epoch 266 is 0.01665047\n",
      "Val Loss at Epoch 266 is 0.00023413\n",
      "Train Loss at Epoch 267 is 0.01660418\n",
      "Val Loss at Epoch 267 is 0.00023334\n",
      "Train Loss at Epoch 268 is 0.01655823\n",
      "Val Loss at Epoch 268 is 0.00023255\n",
      "Train Loss at Epoch 269 is 0.01651263\n",
      "Val Loss at Epoch 269 is 0.00023177\n",
      "Train Loss at Epoch 270 is 0.01646737\n",
      "Val Loss at Epoch 270 is 0.00023100\n",
      "Train Loss at Epoch 271 is 0.01642244\n",
      "Val Loss at Epoch 271 is 0.00023023\n",
      "Train Loss at Epoch 272 is 0.01637785\n",
      "Val Loss at Epoch 272 is 0.00022946\n",
      "Train Loss at Epoch 273 is 0.01633358\n",
      "Val Loss at Epoch 273 is 0.00022870\n",
      "Train Loss at Epoch 274 is 0.01628964\n",
      "Val Loss at Epoch 274 is 0.00022795\n",
      "Train Loss at Epoch 275 is 0.01624602\n",
      "Val Loss at Epoch 275 is 0.00022720\n",
      "Train Loss at Epoch 276 is 0.01620272\n",
      "Val Loss at Epoch 276 is 0.00022646\n",
      "Train Loss at Epoch 277 is 0.01615973\n",
      "Val Loss at Epoch 277 is 0.00022572\n",
      "Train Loss at Epoch 278 is 0.01611706\n",
      "Val Loss at Epoch 278 is 0.00022499\n",
      "Train Loss at Epoch 279 is 0.01607470\n",
      "Val Loss at Epoch 279 is 0.00022426\n",
      "Train Loss at Epoch 280 is 0.01603264\n",
      "Val Loss at Epoch 280 is 0.00022354\n",
      "Train Loss at Epoch 281 is 0.01599088\n",
      "Val Loss at Epoch 281 is 0.00022282\n",
      "Train Loss at Epoch 282 is 0.01594942\n",
      "Val Loss at Epoch 282 is 0.00022211\n",
      "Train Loss at Epoch 283 is 0.01590826\n",
      "Val Loss at Epoch 283 is 0.00022140\n",
      "Train Loss at Epoch 284 is 0.01586740\n",
      "Val Loss at Epoch 284 is 0.00022070\n",
      "Train Loss at Epoch 285 is 0.01582682\n",
      "Val Loss at Epoch 285 is 0.00022000\n",
      "Train Loss at Epoch 286 is 0.01578653\n",
      "Val Loss at Epoch 286 is 0.00021931\n",
      "Train Loss at Epoch 287 is 0.01574653\n",
      "Val Loss at Epoch 287 is 0.00021862\n",
      "Train Loss at Epoch 288 is 0.01570681\n",
      "Val Loss at Epoch 288 is 0.00021793\n",
      "Train Loss at Epoch 289 is 0.01566737\n",
      "Val Loss at Epoch 289 is 0.00021725\n",
      "Train Loss at Epoch 290 is 0.01562820\n",
      "Val Loss at Epoch 290 is 0.00021658\n",
      "Train Loss at Epoch 291 is 0.01558931\n",
      "Val Loss at Epoch 291 is 0.00021591\n",
      "Train Loss at Epoch 292 is 0.01555069\n",
      "Val Loss at Epoch 292 is 0.00021524\n",
      "Train Loss at Epoch 293 is 0.01551234\n",
      "Val Loss at Epoch 293 is 0.00021458\n",
      "Train Loss at Epoch 294 is 0.01547426\n",
      "Val Loss at Epoch 294 is 0.00021393\n",
      "Train Loss at Epoch 295 is 0.01543644\n",
      "Val Loss at Epoch 295 is 0.00021327\n",
      "Train Loss at Epoch 296 is 0.01539888\n",
      "Val Loss at Epoch 296 is 0.00021262\n",
      "Train Loss at Epoch 297 is 0.01536157\n",
      "Val Loss at Epoch 297 is 0.00021198\n",
      "Train Loss at Epoch 298 is 0.01532453\n",
      "Val Loss at Epoch 298 is 0.00021134\n",
      "Train Loss at Epoch 299 is 0.01528774\n",
      "Val Loss at Epoch 299 is 0.00021070\n",
      "Train Loss at Epoch 300 is 0.01525120\n",
      "Val Loss at Epoch 300 is 0.00021007\n",
      "Train Loss at Epoch 301 is 0.01521490\n",
      "Val Loss at Epoch 301 is 0.00020944\n",
      "Train Loss at Epoch 302 is 0.01517886\n",
      "Val Loss at Epoch 302 is 0.00020882\n",
      "Train Loss at Epoch 303 is 0.01514306\n",
      "Val Loss at Epoch 303 is 0.00020820\n",
      "Train Loss at Epoch 304 is 0.01510750\n",
      "Val Loss at Epoch 304 is 0.00020758\n",
      "Train Loss at Epoch 305 is 0.01507218\n",
      "Val Loss at Epoch 305 is 0.00020697\n",
      "Train Loss at Epoch 306 is 0.01503710\n",
      "Val Loss at Epoch 306 is 0.00020636\n",
      "Train Loss at Epoch 307 is 0.01500225\n",
      "Val Loss at Epoch 307 is 0.00020576\n",
      "Train Loss at Epoch 308 is 0.01496764\n",
      "Val Loss at Epoch 308 is 0.00020516\n",
      "Train Loss at Epoch 309 is 0.01493326\n",
      "Val Loss at Epoch 309 is 0.00020456\n",
      "Train Loss at Epoch 310 is 0.01489911\n",
      "Val Loss at Epoch 310 is 0.00020397\n",
      "Train Loss at Epoch 311 is 0.01486518\n",
      "Val Loss at Epoch 311 is 0.00020338\n",
      "Train Loss at Epoch 312 is 0.01483148\n",
      "Val Loss at Epoch 312 is 0.00020279\n",
      "Train Loss at Epoch 313 is 0.01479800\n",
      "Val Loss at Epoch 313 is 0.00020221\n",
      "Train Loss at Epoch 314 is 0.01476475\n",
      "Val Loss at Epoch 314 is 0.00020163\n",
      "Train Loss at Epoch 315 is 0.01473171\n",
      "Val Loss at Epoch 315 is 0.00020105\n",
      "Train Loss at Epoch 316 is 0.01469889\n",
      "Val Loss at Epoch 316 is 0.00020048\n",
      "Train Loss at Epoch 317 is 0.01466629\n",
      "Val Loss at Epoch 317 is 0.00019991\n",
      "Train Loss at Epoch 318 is 0.01463389\n",
      "Val Loss at Epoch 318 is 0.00019935\n",
      "Train Loss at Epoch 319 is 0.01460171\n",
      "Val Loss at Epoch 319 is 0.00019879\n",
      "Train Loss at Epoch 320 is 0.01456974\n",
      "Val Loss at Epoch 320 is 0.00019823\n",
      "Train Loss at Epoch 321 is 0.01453798\n",
      "Val Loss at Epoch 321 is 0.00019767\n",
      "Train Loss at Epoch 322 is 0.01450642\n",
      "Val Loss at Epoch 322 is 0.00019712\n",
      "Train Loss at Epoch 323 is 0.01447507\n",
      "Val Loss at Epoch 323 is 0.00019657\n",
      "Train Loss at Epoch 324 is 0.01444392\n",
      "Val Loss at Epoch 324 is 0.00019603\n",
      "Train Loss at Epoch 325 is 0.01441297\n",
      "Val Loss at Epoch 325 is 0.00019548\n",
      "Train Loss at Epoch 326 is 0.01438222\n",
      "Val Loss at Epoch 326 is 0.00019494\n",
      "Train Loss at Epoch 327 is 0.01435167\n",
      "Val Loss at Epoch 327 is 0.00019441\n",
      "Train Loss at Epoch 328 is 0.01432131\n",
      "Val Loss at Epoch 328 is 0.00019387\n",
      "Train Loss at Epoch 329 is 0.01429115\n",
      "Val Loss at Epoch 329 is 0.00019334\n",
      "Train Loss at Epoch 330 is 0.01426118\n",
      "Val Loss at Epoch 330 is 0.00019282\n",
      "Train Loss at Epoch 331 is 0.01423140\n",
      "Val Loss at Epoch 331 is 0.00019229\n",
      "Train Loss at Epoch 332 is 0.01420181\n",
      "Val Loss at Epoch 332 is 0.00019177\n",
      "Train Loss at Epoch 333 is 0.01417240\n",
      "Val Loss at Epoch 333 is 0.00019125\n",
      "Train Loss at Epoch 334 is 0.01414319\n",
      "Val Loss at Epoch 334 is 0.00019074\n",
      "Train Loss at Epoch 335 is 0.01411415\n",
      "Val Loss at Epoch 335 is 0.00019022\n",
      "Train Loss at Epoch 336 is 0.01408530\n",
      "Val Loss at Epoch 336 is 0.00018971\n",
      "Train Loss at Epoch 337 is 0.01405664\n",
      "Val Loss at Epoch 337 is 0.00018921\n",
      "Train Loss at Epoch 338 is 0.01402815\n",
      "Val Loss at Epoch 338 is 0.00018870\n",
      "Train Loss at Epoch 339 is 0.01399984\n",
      "Val Loss at Epoch 339 is 0.00018820\n",
      "Train Loss at Epoch 340 is 0.01397171\n",
      "Val Loss at Epoch 340 is 0.00018770\n",
      "Train Loss at Epoch 341 is 0.01394375\n",
      "Val Loss at Epoch 341 is 0.00018720\n",
      "Train Loss at Epoch 342 is 0.01391597\n",
      "Val Loss at Epoch 342 is 0.00018671\n",
      "Train Loss at Epoch 343 is 0.01388836\n",
      "Val Loss at Epoch 343 is 0.00018622\n",
      "Train Loss at Epoch 344 is 0.01386092\n",
      "Val Loss at Epoch 344 is 0.00018573\n",
      "Train Loss at Epoch 345 is 0.01383365\n",
      "Val Loss at Epoch 345 is 0.00018525\n",
      "Train Loss at Epoch 346 is 0.01380656\n",
      "Val Loss at Epoch 346 is 0.00018476\n",
      "Train Loss at Epoch 347 is 0.01377963\n",
      "Val Loss at Epoch 347 is 0.00018428\n",
      "Train Loss at Epoch 348 is 0.01375286\n",
      "Val Loss at Epoch 348 is 0.00018380\n",
      "Train Loss at Epoch 349 is 0.01372626\n",
      "Val Loss at Epoch 349 is 0.00018333\n",
      "Train Loss at Epoch 350 is 0.01369982\n",
      "Val Loss at Epoch 350 is 0.00018285\n",
      "Train Loss at Epoch 351 is 0.01367355\n",
      "Val Loss at Epoch 351 is 0.00018238\n",
      "Train Loss at Epoch 352 is 0.01364744\n",
      "Val Loss at Epoch 352 is 0.00018192\n",
      "Train Loss at Epoch 353 is 0.01362149\n",
      "Val Loss at Epoch 353 is 0.00018145\n",
      "Train Loss at Epoch 354 is 0.01359569\n",
      "Val Loss at Epoch 354 is 0.00018099\n",
      "Train Loss at Epoch 355 is 0.01357005\n",
      "Val Loss at Epoch 355 is 0.00018052\n",
      "Train Loss at Epoch 356 is 0.01354457\n",
      "Val Loss at Epoch 356 is 0.00018007\n",
      "Train Loss at Epoch 357 is 0.01351925\n",
      "Val Loss at Epoch 357 is 0.00017961\n",
      "Train Loss at Epoch 358 is 0.01349408\n",
      "Val Loss at Epoch 358 is 0.00017915\n",
      "Train Loss at Epoch 359 is 0.01346906\n",
      "Val Loss at Epoch 359 is 0.00017870\n",
      "Train Loss at Epoch 360 is 0.01344419\n",
      "Val Loss at Epoch 360 is 0.00017825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 361 is 0.01341947\n",
      "Val Loss at Epoch 361 is 0.00017780\n",
      "Train Loss at Epoch 362 is 0.01339491\n",
      "Val Loss at Epoch 362 is 0.00017736\n",
      "Train Loss at Epoch 363 is 0.01337049\n",
      "Val Loss at Epoch 363 is 0.00017692\n",
      "Train Loss at Epoch 364 is 0.01334622\n",
      "Val Loss at Epoch 364 is 0.00017647\n",
      "Train Loss at Epoch 365 is 0.01332209\n",
      "Val Loss at Epoch 365 is 0.00017603\n",
      "Train Loss at Epoch 366 is 0.01329811\n",
      "Val Loss at Epoch 366 is 0.00017560\n",
      "Train Loss at Epoch 367 is 0.01327427\n",
      "Val Loss at Epoch 367 is 0.00017516\n",
      "Train Loss at Epoch 368 is 0.01325058\n",
      "Val Loss at Epoch 368 is 0.00017473\n",
      "Train Loss at Epoch 369 is 0.01322703\n",
      "Val Loss at Epoch 369 is 0.00017430\n",
      "Train Loss at Epoch 370 is 0.01320362\n",
      "Val Loss at Epoch 370 is 0.00017387\n",
      "Train Loss at Epoch 371 is 0.01318034\n",
      "Val Loss at Epoch 371 is 0.00017344\n",
      "Train Loss at Epoch 372 is 0.01315721\n",
      "Val Loss at Epoch 372 is 0.00017302\n",
      "Train Loss at Epoch 373 is 0.01313422\n",
      "Val Loss at Epoch 373 is 0.00017260\n",
      "Train Loss at Epoch 374 is 0.01311136\n",
      "Val Loss at Epoch 374 is 0.00017218\n",
      "Train Loss at Epoch 375 is 0.01308864\n",
      "Val Loss at Epoch 375 is 0.00017176\n",
      "Train Loss at Epoch 376 is 0.01306605\n",
      "Val Loss at Epoch 376 is 0.00017134\n",
      "Train Loss at Epoch 377 is 0.01304360\n",
      "Val Loss at Epoch 377 is 0.00017092\n",
      "Train Loss at Epoch 378 is 0.01302128\n",
      "Val Loss at Epoch 378 is 0.00017051\n",
      "Train Loss at Epoch 379 is 0.01299909\n",
      "Val Loss at Epoch 379 is 0.00017010\n",
      "Train Loss at Epoch 380 is 0.01297703\n",
      "Val Loss at Epoch 380 is 0.00016969\n",
      "Train Loss at Epoch 381 is 0.01295510\n",
      "Val Loss at Epoch 381 is 0.00016928\n",
      "Train Loss at Epoch 382 is 0.01293331\n",
      "Val Loss at Epoch 382 is 0.00016888\n",
      "Train Loss at Epoch 383 is 0.01291164\n",
      "Val Loss at Epoch 383 is 0.00016847\n",
      "Train Loss at Epoch 384 is 0.01289010\n",
      "Val Loss at Epoch 384 is 0.00016807\n",
      "Train Loss at Epoch 385 is 0.01286868\n",
      "Val Loss at Epoch 385 is 0.00016767\n",
      "Train Loss at Epoch 386 is 0.01284740\n",
      "Val Loss at Epoch 386 is 0.00016727\n",
      "Train Loss at Epoch 387 is 0.01282623\n",
      "Val Loss at Epoch 387 is 0.00016687\n",
      "Train Loss at Epoch 388 is 0.01280519\n",
      "Val Loss at Epoch 388 is 0.00016648\n",
      "Train Loss at Epoch 389 is 0.01278428\n",
      "Val Loss at Epoch 389 is 0.00016609\n",
      "Train Loss at Epoch 390 is 0.01276348\n",
      "Val Loss at Epoch 390 is 0.00016569\n",
      "Train Loss at Epoch 391 is 0.01274281\n",
      "Val Loss at Epoch 391 is 0.00016530\n",
      "Train Loss at Epoch 392 is 0.01272226\n",
      "Val Loss at Epoch 392 is 0.00016492\n",
      "Train Loss at Epoch 393 is 0.01270183\n",
      "Val Loss at Epoch 393 is 0.00016453\n",
      "Train Loss at Epoch 394 is 0.01268152\n",
      "Val Loss at Epoch 394 is 0.00016414\n",
      "Train Loss at Epoch 395 is 0.01266133\n",
      "Val Loss at Epoch 395 is 0.00016376\n",
      "Train Loss at Epoch 396 is 0.01264126\n",
      "Val Loss at Epoch 396 is 0.00016338\n",
      "Train Loss at Epoch 397 is 0.01262130\n",
      "Val Loss at Epoch 397 is 0.00016300\n",
      "Train Loss at Epoch 398 is 0.01260146\n",
      "Val Loss at Epoch 398 is 0.00016262\n",
      "Train Loss at Epoch 399 is 0.01258173\n",
      "Val Loss at Epoch 399 is 0.00016224\n",
      "Train Loss at Epoch 400 is 0.01256212\n",
      "Val Loss at Epoch 400 is 0.00016187\n",
      "Train Loss at Epoch 401 is 0.01254262\n",
      "Val Loss at Epoch 401 is 0.00016149\n",
      "Train Loss at Epoch 402 is 0.01252324\n",
      "Val Loss at Epoch 402 is 0.00016112\n",
      "Train Loss at Epoch 403 is 0.01250397\n",
      "Val Loss at Epoch 403 is 0.00016075\n",
      "Train Loss at Epoch 404 is 0.01248481\n",
      "Val Loss at Epoch 404 is 0.00016038\n",
      "Train Loss at Epoch 405 is 0.01246576\n",
      "Val Loss at Epoch 405 is 0.00016001\n",
      "Train Loss at Epoch 406 is 0.01244682\n",
      "Val Loss at Epoch 406 is 0.00015964\n",
      "Train Loss at Epoch 407 is 0.01242799\n",
      "Val Loss at Epoch 407 is 0.00015928\n",
      "Train Loss at Epoch 408 is 0.01240928\n",
      "Val Loss at Epoch 408 is 0.00015891\n",
      "Train Loss at Epoch 409 is 0.01239067\n",
      "Val Loss at Epoch 409 is 0.00015855\n",
      "Train Loss at Epoch 410 is 0.01237216\n",
      "Val Loss at Epoch 410 is 0.00015819\n",
      "Train Loss at Epoch 411 is 0.01235377\n",
      "Val Loss at Epoch 411 is 0.00015783\n",
      "Train Loss at Epoch 412 is 0.01233548\n",
      "Val Loss at Epoch 412 is 0.00015747\n",
      "Train Loss at Epoch 413 is 0.01231729\n",
      "Val Loss at Epoch 413 is 0.00015712\n",
      "Train Loss at Epoch 414 is 0.01229922\n",
      "Val Loss at Epoch 414 is 0.00015676\n",
      "Train Loss at Epoch 415 is 0.01228124\n",
      "Val Loss at Epoch 415 is 0.00015641\n",
      "Train Loss at Epoch 416 is 0.01226337\n",
      "Val Loss at Epoch 416 is 0.00015605\n",
      "Train Loss at Epoch 417 is 0.01224560\n",
      "Val Loss at Epoch 417 is 0.00015570\n",
      "Train Loss at Epoch 418 is 0.01222794\n",
      "Val Loss at Epoch 418 is 0.00015535\n",
      "Train Loss at Epoch 419 is 0.01221038\n",
      "Val Loss at Epoch 419 is 0.00015500\n",
      "Train Loss at Epoch 420 is 0.01219292\n",
      "Val Loss at Epoch 420 is 0.00015466\n",
      "Train Loss at Epoch 421 is 0.01217556\n",
      "Val Loss at Epoch 421 is 0.00015431\n",
      "Train Loss at Epoch 422 is 0.01215830\n",
      "Val Loss at Epoch 422 is 0.00015397\n",
      "Train Loss at Epoch 423 is 0.01214114\n",
      "Val Loss at Epoch 423 is 0.00015362\n",
      "Train Loss at Epoch 424 is 0.01212407\n",
      "Val Loss at Epoch 424 is 0.00015328\n",
      "Train Loss at Epoch 425 is 0.01210711\n",
      "Val Loss at Epoch 425 is 0.00015294\n",
      "Train Loss at Epoch 426 is 0.01209025\n",
      "Val Loss at Epoch 426 is 0.00015260\n",
      "Train Loss at Epoch 427 is 0.01207348\n",
      "Val Loss at Epoch 427 is 0.00015226\n",
      "Train Loss at Epoch 428 is 0.01205681\n",
      "Val Loss at Epoch 428 is 0.00015192\n",
      "Train Loss at Epoch 429 is 0.01204023\n",
      "Val Loss at Epoch 429 is 0.00015159\n",
      "Train Loss at Epoch 430 is 0.01202375\n",
      "Val Loss at Epoch 430 is 0.00015125\n",
      "Train Loss at Epoch 431 is 0.01200737\n",
      "Val Loss at Epoch 431 is 0.00015092\n",
      "Train Loss at Epoch 432 is 0.01199108\n",
      "Val Loss at Epoch 432 is 0.00015059\n",
      "Train Loss at Epoch 433 is 0.01197488\n",
      "Val Loss at Epoch 433 is 0.00015026\n",
      "Train Loss at Epoch 434 is 0.01195878\n",
      "Val Loss at Epoch 434 is 0.00014993\n",
      "Train Loss at Epoch 435 is 0.01194277\n",
      "Val Loss at Epoch 435 is 0.00014960\n",
      "Train Loss at Epoch 436 is 0.01192685\n",
      "Val Loss at Epoch 436 is 0.00014927\n",
      "Train Loss at Epoch 437 is 0.01191102\n",
      "Val Loss at Epoch 437 is 0.00014894\n",
      "Train Loss at Epoch 438 is 0.01189529\n",
      "Val Loss at Epoch 438 is 0.00014862\n",
      "Train Loss at Epoch 439 is 0.01187964\n",
      "Val Loss at Epoch 439 is 0.00014829\n",
      "Train Loss at Epoch 440 is 0.01186409\n",
      "Val Loss at Epoch 440 is 0.00014797\n",
      "Train Loss at Epoch 441 is 0.01184862\n",
      "Val Loss at Epoch 441 is 0.00014765\n",
      "Train Loss at Epoch 442 is 0.01183325\n",
      "Val Loss at Epoch 442 is 0.00014733\n",
      "Train Loss at Epoch 443 is 0.01181796\n",
      "Val Loss at Epoch 443 is 0.00014701\n",
      "Train Loss at Epoch 444 is 0.01180277\n",
      "Val Loss at Epoch 444 is 0.00014669\n",
      "Train Loss at Epoch 445 is 0.01178766\n",
      "Val Loss at Epoch 445 is 0.00014637\n",
      "Train Loss at Epoch 446 is 0.01177263\n",
      "Val Loss at Epoch 446 is 0.00014606\n",
      "Train Loss at Epoch 447 is 0.01175770\n",
      "Val Loss at Epoch 447 is 0.00014574\n",
      "Train Loss at Epoch 448 is 0.01174285\n",
      "Val Loss at Epoch 448 is 0.00014543\n",
      "Train Loss at Epoch 449 is 0.01172808\n",
      "Val Loss at Epoch 449 is 0.00014511\n",
      "Train Loss at Epoch 450 is 0.01171341\n",
      "Val Loss at Epoch 450 is 0.00014480\n",
      "Train Loss at Epoch 451 is 0.01169881\n",
      "Val Loss at Epoch 451 is 0.00014449\n",
      "Train Loss at Epoch 452 is 0.01168430\n",
      "Val Loss at Epoch 452 is 0.00014418\n",
      "Train Loss at Epoch 453 is 0.01166988\n",
      "Val Loss at Epoch 453 is 0.00014387\n",
      "Train Loss at Epoch 454 is 0.01165554\n",
      "Val Loss at Epoch 454 is 0.00014356\n",
      "Train Loss at Epoch 455 is 0.01164128\n",
      "Val Loss at Epoch 455 is 0.00014325\n",
      "Train Loss at Epoch 456 is 0.01162711\n",
      "Val Loss at Epoch 456 is 0.00014295\n",
      "Train Loss at Epoch 457 is 0.01161301\n",
      "Val Loss at Epoch 457 is 0.00014264\n",
      "Train Loss at Epoch 458 is 0.01159900\n",
      "Val Loss at Epoch 458 is 0.00014234\n",
      "Train Loss at Epoch 459 is 0.01158507\n",
      "Val Loss at Epoch 459 is 0.00014204\n",
      "Train Loss at Epoch 460 is 0.01157122\n",
      "Val Loss at Epoch 460 is 0.00014173\n",
      "Train Loss at Epoch 461 is 0.01155745\n",
      "Val Loss at Epoch 461 is 0.00014143\n",
      "Train Loss at Epoch 462 is 0.01154377\n",
      "Val Loss at Epoch 462 is 0.00014113\n",
      "Train Loss at Epoch 463 is 0.01153016\n",
      "Val Loss at Epoch 463 is 0.00014083\n",
      "Train Loss at Epoch 464 is 0.01151663\n",
      "Val Loss at Epoch 464 is 0.00014054\n",
      "Train Loss at Epoch 465 is 0.01150318\n",
      "Val Loss at Epoch 465 is 0.00014024\n",
      "Train Loss at Epoch 466 is 0.01148981\n",
      "Val Loss at Epoch 466 is 0.00013994\n",
      "Train Loss at Epoch 467 is 0.01147651\n",
      "Val Loss at Epoch 467 is 0.00013965\n",
      "Train Loss at Epoch 468 is 0.01146329\n",
      "Val Loss at Epoch 468 is 0.00013935\n",
      "Train Loss at Epoch 469 is 0.01145016\n",
      "Val Loss at Epoch 469 is 0.00013906\n",
      "Train Loss at Epoch 470 is 0.01143709\n",
      "Val Loss at Epoch 470 is 0.00013877\n",
      "Train Loss at Epoch 471 is 0.01142411\n",
      "Val Loss at Epoch 471 is 0.00013847\n",
      "Train Loss at Epoch 472 is 0.01141120\n",
      "Val Loss at Epoch 472 is 0.00013818\n",
      "Train Loss at Epoch 473 is 0.01139836\n",
      "Val Loss at Epoch 473 is 0.00013789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 474 is 0.01138560\n",
      "Val Loss at Epoch 474 is 0.00013760\n",
      "Train Loss at Epoch 475 is 0.01137292\n",
      "Val Loss at Epoch 475 is 0.00013732\n",
      "Train Loss at Epoch 476 is 0.01136031\n",
      "Val Loss at Epoch 476 is 0.00013703\n",
      "Train Loss at Epoch 477 is 0.01134777\n",
      "Val Loss at Epoch 477 is 0.00013674\n",
      "Train Loss at Epoch 478 is 0.01133531\n",
      "Val Loss at Epoch 478 is 0.00013646\n",
      "Train Loss at Epoch 479 is 0.01132292\n",
      "Val Loss at Epoch 479 is 0.00013617\n",
      "Train Loss at Epoch 480 is 0.01131061\n",
      "Val Loss at Epoch 480 is 0.00013589\n",
      "Train Loss at Epoch 481 is 0.01129836\n",
      "Val Loss at Epoch 481 is 0.00013561\n",
      "Train Loss at Epoch 482 is 0.01128619\n",
      "Val Loss at Epoch 482 is 0.00013533\n",
      "Train Loss at Epoch 483 is 0.01127409\n",
      "Val Loss at Epoch 483 is 0.00013504\n",
      "Train Loss at Epoch 484 is 0.01126207\n",
      "Val Loss at Epoch 484 is 0.00013476\n",
      "Train Loss at Epoch 485 is 0.01125011\n",
      "Val Loss at Epoch 485 is 0.00013448\n",
      "Train Loss at Epoch 486 is 0.01123822\n",
      "Val Loss at Epoch 486 is 0.00013421\n",
      "Train Loss at Epoch 487 is 0.01122641\n",
      "Val Loss at Epoch 487 is 0.00013393\n",
      "Train Loss at Epoch 488 is 0.01121466\n",
      "Val Loss at Epoch 488 is 0.00013365\n",
      "Train Loss at Epoch 489 is 0.01120299\n",
      "Val Loss at Epoch 489 is 0.00013338\n",
      "Train Loss at Epoch 490 is 0.01119138\n",
      "Val Loss at Epoch 490 is 0.00013310\n",
      "Train Loss at Epoch 491 is 0.01117984\n",
      "Val Loss at Epoch 491 is 0.00013283\n",
      "Train Loss at Epoch 492 is 0.01116837\n",
      "Val Loss at Epoch 492 is 0.00013255\n",
      "Train Loss at Epoch 493 is 0.01115697\n",
      "Val Loss at Epoch 493 is 0.00013228\n",
      "Train Loss at Epoch 494 is 0.01114564\n",
      "Val Loss at Epoch 494 is 0.00013201\n",
      "Train Loss at Epoch 495 is 0.01113437\n",
      "Val Loss at Epoch 495 is 0.00013174\n",
      "Train Loss at Epoch 496 is 0.01112317\n",
      "Val Loss at Epoch 496 is 0.00013147\n",
      "Train Loss at Epoch 497 is 0.01111204\n",
      "Val Loss at Epoch 497 is 0.00013120\n",
      "Train Loss at Epoch 498 is 0.01110098\n",
      "Val Loss at Epoch 498 is 0.00013093\n",
      "Train Loss at Epoch 499 is 0.01108998\n",
      "Val Loss at Epoch 499 is 0.00013066\n",
      "Train Loss at Epoch 500 is 0.01107905\n",
      "Val Loss at Epoch 500 is 0.00013040\n",
      "Train Loss at Epoch 501 is 0.01106818\n",
      "Val Loss at Epoch 501 is 0.00013013\n",
      "Train Loss at Epoch 502 is 0.01105738\n",
      "Val Loss at Epoch 502 is 0.00012986\n",
      "Train Loss at Epoch 503 is 0.01104664\n",
      "Val Loss at Epoch 503 is 0.00012960\n",
      "Train Loss at Epoch 504 is 0.01103597\n",
      "Val Loss at Epoch 504 is 0.00012934\n",
      "Train Loss at Epoch 505 is 0.01102536\n",
      "Val Loss at Epoch 505 is 0.00012907\n",
      "Train Loss at Epoch 506 is 0.01101481\n",
      "Val Loss at Epoch 506 is 0.00012881\n",
      "Train Loss at Epoch 507 is 0.01100433\n",
      "Val Loss at Epoch 507 is 0.00012855\n",
      "Train Loss at Epoch 508 is 0.01099391\n",
      "Val Loss at Epoch 508 is 0.00012829\n",
      "Train Loss at Epoch 509 is 0.01098356\n",
      "Val Loss at Epoch 509 is 0.00012803\n",
      "Train Loss at Epoch 510 is 0.01097326\n",
      "Val Loss at Epoch 510 is 0.00012777\n",
      "Train Loss at Epoch 511 is 0.01096303\n",
      "Val Loss at Epoch 511 is 0.00012751\n",
      "Train Loss at Epoch 512 is 0.01095286\n",
      "Val Loss at Epoch 512 is 0.00012726\n",
      "Train Loss at Epoch 513 is 0.01094276\n",
      "Val Loss at Epoch 513 is 0.00012700\n",
      "Train Loss at Epoch 514 is 0.01093271\n",
      "Val Loss at Epoch 514 is 0.00012674\n",
      "Train Loss at Epoch 515 is 0.01092273\n",
      "Val Loss at Epoch 515 is 0.00012649\n",
      "Train Loss at Epoch 516 is 0.01091280\n",
      "Val Loss at Epoch 516 is 0.00012623\n",
      "Train Loss at Epoch 517 is 0.01090294\n",
      "Val Loss at Epoch 517 is 0.00012598\n",
      "Train Loss at Epoch 518 is 0.01089313\n",
      "Val Loss at Epoch 518 is 0.00012573\n",
      "Train Loss at Epoch 519 is 0.01088339\n",
      "Val Loss at Epoch 519 is 0.00012547\n",
      "Train Loss at Epoch 520 is 0.01087370\n",
      "Val Loss at Epoch 520 is 0.00012522\n",
      "Train Loss at Epoch 521 is 0.01086408\n",
      "Val Loss at Epoch 521 is 0.00012497\n",
      "Train Loss at Epoch 522 is 0.01085451\n",
      "Val Loss at Epoch 522 is 0.00012472\n",
      "Train Loss at Epoch 523 is 0.01084500\n",
      "Val Loss at Epoch 523 is 0.00012447\n",
      "Train Loss at Epoch 524 is 0.01083555\n",
      "Val Loss at Epoch 524 is 0.00012422\n",
      "Train Loss at Epoch 525 is 0.01082615\n",
      "Val Loss at Epoch 525 is 0.00012398\n",
      "Train Loss at Epoch 526 is 0.01081682\n",
      "Val Loss at Epoch 526 is 0.00012373\n",
      "Train Loss at Epoch 527 is 0.01080754\n",
      "Val Loss at Epoch 527 is 0.00012348\n",
      "Train Loss at Epoch 528 is 0.01079832\n",
      "Val Loss at Epoch 528 is 0.00012324\n",
      "Train Loss at Epoch 529 is 0.01078915\n",
      "Val Loss at Epoch 529 is 0.00012299\n",
      "Train Loss at Epoch 530 is 0.01078004\n",
      "Val Loss at Epoch 530 is 0.00012275\n",
      "Train Loss at Epoch 531 is 0.01077099\n",
      "Val Loss at Epoch 531 is 0.00012251\n",
      "Train Loss at Epoch 532 is 0.01076199\n",
      "Val Loss at Epoch 532 is 0.00012226\n",
      "Train Loss at Epoch 533 is 0.01075305\n",
      "Val Loss at Epoch 533 is 0.00012202\n",
      "Train Loss at Epoch 534 is 0.01074416\n",
      "Val Loss at Epoch 534 is 0.00012178\n",
      "Train Loss at Epoch 535 is 0.01073533\n",
      "Val Loss at Epoch 535 is 0.00012154\n",
      "Train Loss at Epoch 536 is 0.01072655\n",
      "Val Loss at Epoch 536 is 0.00012130\n",
      "Train Loss at Epoch 537 is 0.01071782\n",
      "Val Loss at Epoch 537 is 0.00012106\n",
      "Train Loss at Epoch 538 is 0.01070915\n",
      "Val Loss at Epoch 538 is 0.00012082\n",
      "Train Loss at Epoch 539 is 0.01070053\n",
      "Val Loss at Epoch 539 is 0.00012059\n",
      "Train Loss at Epoch 540 is 0.01069197\n",
      "Val Loss at Epoch 540 is 0.00012035\n",
      "Train Loss at Epoch 541 is 0.01068345\n",
      "Val Loss at Epoch 541 is 0.00012011\n",
      "Train Loss at Epoch 542 is 0.01067499\n",
      "Val Loss at Epoch 542 is 0.00011988\n",
      "Train Loss at Epoch 543 is 0.01066659\n",
      "Val Loss at Epoch 543 is 0.00011964\n",
      "Train Loss at Epoch 544 is 0.01065823\n",
      "Val Loss at Epoch 544 is 0.00011941\n",
      "Train Loss at Epoch 545 is 0.01064993\n",
      "Val Loss at Epoch 545 is 0.00011918\n",
      "Train Loss at Epoch 546 is 0.01064167\n",
      "Val Loss at Epoch 546 is 0.00011894\n",
      "Train Loss at Epoch 547 is 0.01063347\n",
      "Val Loss at Epoch 547 is 0.00011871\n",
      "Train Loss at Epoch 548 is 0.01062532\n",
      "Val Loss at Epoch 548 is 0.00011848\n",
      "Train Loss at Epoch 549 is 0.01061722\n",
      "Val Loss at Epoch 549 is 0.00011825\n",
      "Train Loss at Epoch 550 is 0.01060917\n",
      "Val Loss at Epoch 550 is 0.00011802\n",
      "Train Loss at Epoch 551 is 0.01060116\n",
      "Val Loss at Epoch 551 is 0.00011779\n",
      "Train Loss at Epoch 552 is 0.01059321\n",
      "Val Loss at Epoch 552 is 0.00011756\n",
      "Train Loss at Epoch 553 is 0.01058531\n",
      "Val Loss at Epoch 553 is 0.00011733\n",
      "Train Loss at Epoch 554 is 0.01057745\n",
      "Val Loss at Epoch 554 is 0.00011711\n",
      "Train Loss at Epoch 555 is 0.01056965\n",
      "Val Loss at Epoch 555 is 0.00011688\n",
      "Train Loss at Epoch 556 is 0.01056189\n",
      "Val Loss at Epoch 556 is 0.00011666\n",
      "Train Loss at Epoch 557 is 0.01055418\n",
      "Val Loss at Epoch 557 is 0.00011643\n",
      "Train Loss at Epoch 558 is 0.01054651\n",
      "Val Loss at Epoch 558 is 0.00011621\n",
      "Train Loss at Epoch 559 is 0.01053890\n",
      "Val Loss at Epoch 559 is 0.00011598\n",
      "Train Loss at Epoch 560 is 0.01053133\n",
      "Val Loss at Epoch 560 is 0.00011576\n",
      "Train Loss at Epoch 561 is 0.01052381\n",
      "Val Loss at Epoch 561 is 0.00011554\n",
      "Train Loss at Epoch 562 is 0.01051633\n",
      "Val Loss at Epoch 562 is 0.00011532\n",
      "Train Loss at Epoch 563 is 0.01050890\n",
      "Val Loss at Epoch 563 is 0.00011510\n",
      "Train Loss at Epoch 564 is 0.01050151\n",
      "Val Loss at Epoch 564 is 0.00011488\n",
      "Train Loss at Epoch 565 is 0.01049417\n",
      "Val Loss at Epoch 565 is 0.00011466\n",
      "Train Loss at Epoch 566 is 0.01048688\n",
      "Val Loss at Epoch 566 is 0.00011444\n",
      "Train Loss at Epoch 567 is 0.01047963\n",
      "Val Loss at Epoch 567 is 0.00011422\n",
      "Train Loss at Epoch 568 is 0.01047242\n",
      "Val Loss at Epoch 568 is 0.00011400\n",
      "Train Loss at Epoch 569 is 0.01046526\n",
      "Val Loss at Epoch 569 is 0.00011378\n",
      "Train Loss at Epoch 570 is 0.01045814\n",
      "Val Loss at Epoch 570 is 0.00011357\n",
      "Train Loss at Epoch 571 is 0.01045107\n",
      "Val Loss at Epoch 571 is 0.00011335\n",
      "Train Loss at Epoch 572 is 0.01044404\n",
      "Val Loss at Epoch 572 is 0.00011314\n",
      "Train Loss at Epoch 573 is 0.01043705\n",
      "Val Loss at Epoch 573 is 0.00011293\n",
      "Train Loss at Epoch 574 is 0.01043010\n",
      "Val Loss at Epoch 574 is 0.00011271\n",
      "Train Loss at Epoch 575 is 0.01042320\n",
      "Val Loss at Epoch 575 is 0.00011250\n",
      "Train Loss at Epoch 576 is 0.01041633\n",
      "Val Loss at Epoch 576 is 0.00011229\n",
      "Train Loss at Epoch 577 is 0.01040951\n",
      "Val Loss at Epoch 577 is 0.00011208\n",
      "Train Loss at Epoch 578 is 0.01040273\n",
      "Val Loss at Epoch 578 is 0.00011187\n",
      "Train Loss at Epoch 579 is 0.01039599\n",
      "Val Loss at Epoch 579 is 0.00011166\n",
      "Train Loss at Epoch 580 is 0.01038929\n",
      "Val Loss at Epoch 580 is 0.00011145\n",
      "Train Loss at Epoch 581 is 0.01038263\n",
      "Val Loss at Epoch 581 is 0.00011124\n",
      "Train Loss at Epoch 582 is 0.01037601\n",
      "Val Loss at Epoch 582 is 0.00011103\n",
      "Train Loss at Epoch 583 is 0.01036943\n",
      "Val Loss at Epoch 583 is 0.00011082\n",
      "Train Loss at Epoch 584 is 0.01036289\n",
      "Val Loss at Epoch 584 is 0.00011062\n",
      "Train Loss at Epoch 585 is 0.01035639\n",
      "Val Loss at Epoch 585 is 0.00011041\n",
      "Train Loss at Epoch 586 is 0.01034993\n",
      "Val Loss at Epoch 586 is 0.00011021\n",
      "Train Loss at Epoch 587 is 0.01034350\n",
      "Val Loss at Epoch 587 is 0.00011000\n",
      "Train Loss at Epoch 588 is 0.01033711\n",
      "Val Loss at Epoch 588 is 0.00010980\n",
      "Train Loss at Epoch 589 is 0.01033076\n",
      "Val Loss at Epoch 589 is 0.00010959\n",
      "Train Loss at Epoch 590 is 0.01032445\n",
      "Val Loss at Epoch 590 is 0.00010939\n",
      "Train Loss at Epoch 591 is 0.01031817\n",
      "Val Loss at Epoch 591 is 0.00010919\n",
      "Train Loss at Epoch 592 is 0.01031193\n",
      "Val Loss at Epoch 592 is 0.00010899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 593 is 0.01030573\n",
      "Val Loss at Epoch 593 is 0.00010879\n",
      "Train Loss at Epoch 594 is 0.01029956\n",
      "Val Loss at Epoch 594 is 0.00010859\n",
      "Train Loss at Epoch 595 is 0.01029343\n",
      "Val Loss at Epoch 595 is 0.00010839\n",
      "Train Loss at Epoch 596 is 0.01028733\n",
      "Val Loss at Epoch 596 is 0.00010819\n",
      "Train Loss at Epoch 597 is 0.01028127\n",
      "Val Loss at Epoch 597 is 0.00010799\n",
      "Train Loss at Epoch 598 is 0.01027524\n",
      "Val Loss at Epoch 598 is 0.00010780\n",
      "Train Loss at Epoch 599 is 0.01026925\n",
      "Val Loss at Epoch 599 is 0.00010760\n",
      "Train Loss at Epoch 600 is 0.01026329\n",
      "Val Loss at Epoch 600 is 0.00010740\n",
      "Train Loss at Epoch 601 is 0.01025736\n",
      "Val Loss at Epoch 601 is 0.00010721\n",
      "Train Loss at Epoch 602 is 0.01025147\n",
      "Val Loss at Epoch 602 is 0.00010701\n",
      "Train Loss at Epoch 603 is 0.01024561\n",
      "Val Loss at Epoch 603 is 0.00010682\n",
      "Train Loss at Epoch 604 is 0.01023978\n",
      "Val Loss at Epoch 604 is 0.00010663\n",
      "Train Loss at Epoch 605 is 0.01023398\n",
      "Val Loss at Epoch 605 is 0.00010643\n",
      "Train Loss at Epoch 606 is 0.01022822\n",
      "Val Loss at Epoch 606 is 0.00010624\n",
      "Train Loss at Epoch 607 is 0.01022248\n",
      "Val Loss at Epoch 607 is 0.00010605\n",
      "Train Loss at Epoch 608 is 0.01021678\n",
      "Val Loss at Epoch 608 is 0.00010586\n",
      "Train Loss at Epoch 609 is 0.01021111\n",
      "Val Loss at Epoch 609 is 0.00010567\n",
      "Train Loss at Epoch 610 is 0.01020547\n",
      "Val Loss at Epoch 610 is 0.00010548\n",
      "Train Loss at Epoch 611 is 0.01019986\n",
      "Val Loss at Epoch 611 is 0.00010529\n",
      "Train Loss at Epoch 612 is 0.01019428\n",
      "Val Loss at Epoch 612 is 0.00010510\n",
      "Train Loss at Epoch 613 is 0.01018872\n",
      "Val Loss at Epoch 613 is 0.00010492\n",
      "Train Loss at Epoch 614 is 0.01018320\n",
      "Val Loss at Epoch 614 is 0.00010473\n",
      "Train Loss at Epoch 615 is 0.01017771\n",
      "Val Loss at Epoch 615 is 0.00010454\n",
      "Train Loss at Epoch 616 is 0.01017224\n",
      "Val Loss at Epoch 616 is 0.00010436\n",
      "Train Loss at Epoch 617 is 0.01016680\n",
      "Val Loss at Epoch 617 is 0.00010418\n",
      "Train Loss at Epoch 618 is 0.01016139\n",
      "Val Loss at Epoch 618 is 0.00010399\n",
      "Train Loss at Epoch 619 is 0.01015601\n",
      "Val Loss at Epoch 619 is 0.00010381\n",
      "Train Loss at Epoch 620 is 0.01015065\n",
      "Val Loss at Epoch 620 is 0.00010363\n",
      "Train Loss at Epoch 621 is 0.01014532\n",
      "Val Loss at Epoch 621 is 0.00010344\n",
      "Train Loss at Epoch 622 is 0.01014001\n",
      "Val Loss at Epoch 622 is 0.00010326\n",
      "Train Loss at Epoch 623 is 0.01013473\n",
      "Val Loss at Epoch 623 is 0.00010308\n",
      "Train Loss at Epoch 624 is 0.01012948\n",
      "Val Loss at Epoch 624 is 0.00010290\n",
      "Train Loss at Epoch 625 is 0.01012425\n",
      "Val Loss at Epoch 625 is 0.00010272\n",
      "Train Loss at Epoch 626 is 0.01011905\n",
      "Val Loss at Epoch 626 is 0.00010254\n",
      "Train Loss at Epoch 627 is 0.01011387\n",
      "Val Loss at Epoch 627 is 0.00010236\n",
      "Train Loss at Epoch 628 is 0.01010871\n",
      "Val Loss at Epoch 628 is 0.00010219\n",
      "Train Loss at Epoch 629 is 0.01010358\n",
      "Val Loss at Epoch 629 is 0.00010201\n",
      "Train Loss at Epoch 630 is 0.01009848\n",
      "Val Loss at Epoch 630 is 0.00010183\n",
      "Train Loss at Epoch 631 is 0.01009339\n",
      "Val Loss at Epoch 631 is 0.00010166\n",
      "Train Loss at Epoch 632 is 0.01008833\n",
      "Val Loss at Epoch 632 is 0.00010148\n",
      "Train Loss at Epoch 633 is 0.01008329\n",
      "Val Loss at Epoch 633 is 0.00010131\n",
      "Train Loss at Epoch 634 is 0.01007827\n",
      "Val Loss at Epoch 634 is 0.00010114\n",
      "Train Loss at Epoch 635 is 0.01007327\n",
      "Val Loss at Epoch 635 is 0.00010096\n",
      "Train Loss at Epoch 636 is 0.01006830\n",
      "Val Loss at Epoch 636 is 0.00010079\n",
      "Train Loss at Epoch 637 is 0.01006334\n",
      "Val Loss at Epoch 637 is 0.00010062\n",
      "Train Loss at Epoch 638 is 0.01005841\n",
      "Val Loss at Epoch 638 is 0.00010045\n",
      "Train Loss at Epoch 639 is 0.01005349\n",
      "Val Loss at Epoch 639 is 0.00010028\n",
      "Train Loss at Epoch 640 is 0.01004860\n",
      "Val Loss at Epoch 640 is 0.00010011\n",
      "Train Loss at Epoch 641 is 0.01004372\n",
      "Val Loss at Epoch 641 is 0.00009994\n",
      "Train Loss at Epoch 642 is 0.01003886\n",
      "Val Loss at Epoch 642 is 0.00009977\n",
      "Train Loss at Epoch 643 is 0.01003403\n",
      "Val Loss at Epoch 643 is 0.00009960\n",
      "Train Loss at Epoch 644 is 0.01002921\n",
      "Val Loss at Epoch 644 is 0.00009944\n",
      "Train Loss at Epoch 645 is 0.01002441\n",
      "Val Loss at Epoch 645 is 0.00009927\n",
      "Train Loss at Epoch 646 is 0.01001962\n",
      "Val Loss at Epoch 646 is 0.00009910\n",
      "Train Loss at Epoch 647 is 0.01001485\n",
      "Val Loss at Epoch 647 is 0.00009894\n",
      "Train Loss at Epoch 648 is 0.01001011\n",
      "Val Loss at Epoch 648 is 0.00009877\n",
      "Train Loss at Epoch 649 is 0.01000537\n",
      "Val Loss at Epoch 649 is 0.00009861\n",
      "Train Loss at Epoch 650 is 0.01000065\n",
      "Val Loss at Epoch 650 is 0.00009845\n",
      "Train Loss at Epoch 651 is 0.00999595\n",
      "Val Loss at Epoch 651 is 0.00009828\n",
      "Train Loss at Epoch 652 is 0.00999127\n",
      "Val Loss at Epoch 652 is 0.00009812\n",
      "Train Loss at Epoch 653 is 0.00998660\n",
      "Val Loss at Epoch 653 is 0.00009796\n",
      "Train Loss at Epoch 654 is 0.00998194\n",
      "Val Loss at Epoch 654 is 0.00009780\n",
      "Train Loss at Epoch 655 is 0.00997730\n",
      "Val Loss at Epoch 655 is 0.00009764\n",
      "Train Loss at Epoch 656 is 0.00997267\n",
      "Val Loss at Epoch 656 is 0.00009748\n",
      "Train Loss at Epoch 657 is 0.00996806\n",
      "Val Loss at Epoch 657 is 0.00009732\n",
      "Train Loss at Epoch 658 is 0.00996346\n",
      "Val Loss at Epoch 658 is 0.00009716\n",
      "Train Loss at Epoch 659 is 0.00995887\n",
      "Val Loss at Epoch 659 is 0.00009700\n",
      "Train Loss at Epoch 660 is 0.00995430\n",
      "Val Loss at Epoch 660 is 0.00009685\n",
      "Train Loss at Epoch 661 is 0.00994974\n",
      "Val Loss at Epoch 661 is 0.00009669\n",
      "Train Loss at Epoch 662 is 0.00994519\n",
      "Val Loss at Epoch 662 is 0.00009653\n",
      "Train Loss at Epoch 663 is 0.00994065\n",
      "Val Loss at Epoch 663 is 0.00009638\n",
      "Train Loss at Epoch 664 is 0.00993612\n",
      "Val Loss at Epoch 664 is 0.00009622\n",
      "Train Loss at Epoch 665 is 0.00993161\n",
      "Val Loss at Epoch 665 is 0.00009607\n",
      "Train Loss at Epoch 666 is 0.00992710\n",
      "Val Loss at Epoch 666 is 0.00009592\n",
      "Train Loss at Epoch 667 is 0.00992261\n",
      "Val Loss at Epoch 667 is 0.00009576\n",
      "Train Loss at Epoch 668 is 0.00991812\n",
      "Val Loss at Epoch 668 is 0.00009561\n",
      "Train Loss at Epoch 669 is 0.00991364\n",
      "Val Loss at Epoch 669 is 0.00009546\n",
      "Train Loss at Epoch 670 is 0.00990918\n",
      "Val Loss at Epoch 670 is 0.00009531\n",
      "Train Loss at Epoch 671 is 0.00990472\n",
      "Val Loss at Epoch 671 is 0.00009516\n",
      "Train Loss at Epoch 672 is 0.00990027\n",
      "Val Loss at Epoch 672 is 0.00009501\n",
      "Train Loss at Epoch 673 is 0.00989583\n",
      "Val Loss at Epoch 673 is 0.00009486\n",
      "Train Loss at Epoch 674 is 0.00989140\n",
      "Val Loss at Epoch 674 is 0.00009471\n",
      "Train Loss at Epoch 675 is 0.00988698\n",
      "Val Loss at Epoch 675 is 0.00009456\n",
      "Train Loss at Epoch 676 is 0.00988256\n",
      "Val Loss at Epoch 676 is 0.00009442\n",
      "Train Loss at Epoch 677 is 0.00987815\n",
      "Val Loss at Epoch 677 is 0.00009427\n",
      "Train Loss at Epoch 678 is 0.00987375\n",
      "Val Loss at Epoch 678 is 0.00009412\n",
      "Train Loss at Epoch 679 is 0.00986935\n",
      "Val Loss at Epoch 679 is 0.00009398\n",
      "Train Loss at Epoch 680 is 0.00986496\n",
      "Val Loss at Epoch 680 is 0.00009383\n",
      "Train Loss at Epoch 681 is 0.00986057\n",
      "Val Loss at Epoch 681 is 0.00009369\n",
      "Train Loss at Epoch 682 is 0.00985619\n",
      "Val Loss at Epoch 682 is 0.00009354\n",
      "Train Loss at Epoch 683 is 0.00985182\n",
      "Val Loss at Epoch 683 is 0.00009340\n",
      "Train Loss at Epoch 684 is 0.00984745\n",
      "Val Loss at Epoch 684 is 0.00009326\n",
      "Train Loss at Epoch 685 is 0.00984308\n",
      "Val Loss at Epoch 685 is 0.00009312\n",
      "Train Loss at Epoch 686 is 0.00983872\n",
      "Val Loss at Epoch 686 is 0.00009298\n",
      "Train Loss at Epoch 687 is 0.00983436\n",
      "Val Loss at Epoch 687 is 0.00009283\n",
      "Train Loss at Epoch 688 is 0.00983001\n",
      "Val Loss at Epoch 688 is 0.00009269\n",
      "Train Loss at Epoch 689 is 0.00982566\n",
      "Val Loss at Epoch 689 is 0.00009255\n",
      "Train Loss at Epoch 690 is 0.00982131\n",
      "Val Loss at Epoch 690 is 0.00009242\n",
      "Train Loss at Epoch 691 is 0.00981697\n",
      "Val Loss at Epoch 691 is 0.00009228\n",
      "Train Loss at Epoch 692 is 0.00981262\n",
      "Val Loss at Epoch 692 is 0.00009214\n",
      "Train Loss at Epoch 693 is 0.00980828\n",
      "Val Loss at Epoch 693 is 0.00009200\n",
      "Train Loss at Epoch 694 is 0.00980394\n",
      "Val Loss at Epoch 694 is 0.00009186\n",
      "Train Loss at Epoch 695 is 0.00979961\n",
      "Val Loss at Epoch 695 is 0.00009173\n",
      "Train Loss at Epoch 696 is 0.00979527\n",
      "Val Loss at Epoch 696 is 0.00009159\n",
      "Train Loss at Epoch 697 is 0.00979094\n",
      "Val Loss at Epoch 697 is 0.00009146\n",
      "Train Loss at Epoch 698 is 0.00978660\n",
      "Val Loss at Epoch 698 is 0.00009132\n",
      "Train Loss at Epoch 699 is 0.00978227\n",
      "Val Loss at Epoch 699 is 0.00009119\n",
      "Train Loss at Epoch 700 is 0.00977793\n",
      "Val Loss at Epoch 700 is 0.00009105\n",
      "Train Loss at Epoch 701 is 0.00977360\n",
      "Val Loss at Epoch 701 is 0.00009092\n",
      "Train Loss at Epoch 702 is 0.00976926\n",
      "Val Loss at Epoch 702 is 0.00009079\n",
      "Train Loss at Epoch 703 is 0.00976493\n",
      "Val Loss at Epoch 703 is 0.00009066\n",
      "Train Loss at Epoch 704 is 0.00976059\n",
      "Val Loss at Epoch 704 is 0.00009053\n",
      "Train Loss at Epoch 705 is 0.00975626\n",
      "Val Loss at Epoch 705 is 0.00009040\n",
      "Train Loss at Epoch 706 is 0.00975192\n",
      "Val Loss at Epoch 706 is 0.00009027\n",
      "Train Loss at Epoch 707 is 0.00974758\n",
      "Val Loss at Epoch 707 is 0.00009014\n",
      "Train Loss at Epoch 708 is 0.00974323\n",
      "Val Loss at Epoch 708 is 0.00009001\n",
      "Train Loss at Epoch 709 is 0.00973889\n",
      "Val Loss at Epoch 709 is 0.00008988\n",
      "Train Loss at Epoch 710 is 0.00973454\n",
      "Val Loss at Epoch 710 is 0.00008975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 711 is 0.00973019\n",
      "Val Loss at Epoch 711 is 0.00008962\n",
      "Train Loss at Epoch 712 is 0.00972584\n",
      "Val Loss at Epoch 712 is 0.00008950\n",
      "Train Loss at Epoch 713 is 0.00972148\n",
      "Val Loss at Epoch 713 is 0.00008937\n",
      "Train Loss at Epoch 714 is 0.00971712\n",
      "Val Loss at Epoch 714 is 0.00008924\n",
      "Train Loss at Epoch 715 is 0.00971276\n",
      "Val Loss at Epoch 715 is 0.00008912\n",
      "Train Loss at Epoch 716 is 0.00970839\n",
      "Val Loss at Epoch 716 is 0.00008899\n",
      "Train Loss at Epoch 717 is 0.00970402\n",
      "Val Loss at Epoch 717 is 0.00008887\n",
      "Train Loss at Epoch 718 is 0.00969964\n",
      "Val Loss at Epoch 718 is 0.00008875\n",
      "Train Loss at Epoch 719 is 0.00969526\n",
      "Val Loss at Epoch 719 is 0.00008862\n",
      "Train Loss at Epoch 720 is 0.00969088\n",
      "Val Loss at Epoch 720 is 0.00008850\n",
      "Train Loss at Epoch 721 is 0.00968649\n",
      "Val Loss at Epoch 721 is 0.00008838\n",
      "Train Loss at Epoch 722 is 0.00968209\n",
      "Val Loss at Epoch 722 is 0.00008826\n",
      "Train Loss at Epoch 723 is 0.00967769\n",
      "Val Loss at Epoch 723 is 0.00008813\n",
      "Train Loss at Epoch 724 is 0.00967328\n",
      "Val Loss at Epoch 724 is 0.00008801\n",
      "Train Loss at Epoch 725 is 0.00966887\n",
      "Val Loss at Epoch 725 is 0.00008789\n",
      "Train Loss at Epoch 726 is 0.00966445\n",
      "Val Loss at Epoch 726 is 0.00008777\n",
      "Train Loss at Epoch 727 is 0.00966003\n",
      "Val Loss at Epoch 727 is 0.00008765\n",
      "Train Loss at Epoch 728 is 0.00965560\n",
      "Val Loss at Epoch 728 is 0.00008754\n",
      "Train Loss at Epoch 729 is 0.00965116\n",
      "Val Loss at Epoch 729 is 0.00008742\n",
      "Train Loss at Epoch 730 is 0.00964671\n",
      "Val Loss at Epoch 730 is 0.00008730\n",
      "Train Loss at Epoch 731 is 0.00964226\n",
      "Val Loss at Epoch 731 is 0.00008718\n",
      "Train Loss at Epoch 732 is 0.00963780\n",
      "Val Loss at Epoch 732 is 0.00008707\n",
      "Train Loss at Epoch 733 is 0.00963334\n",
      "Val Loss at Epoch 733 is 0.00008695\n",
      "Train Loss at Epoch 734 is 0.00962886\n",
      "Val Loss at Epoch 734 is 0.00008683\n",
      "Train Loss at Epoch 735 is 0.00962438\n",
      "Val Loss at Epoch 735 is 0.00008672\n",
      "Train Loss at Epoch 736 is 0.00961989\n",
      "Val Loss at Epoch 736 is 0.00008660\n",
      "Train Loss at Epoch 737 is 0.00961539\n",
      "Val Loss at Epoch 737 is 0.00008649\n",
      "Train Loss at Epoch 738 is 0.00961089\n",
      "Val Loss at Epoch 738 is 0.00008638\n",
      "Train Loss at Epoch 739 is 0.00960637\n",
      "Val Loss at Epoch 739 is 0.00008626\n",
      "Train Loss at Epoch 740 is 0.00960185\n",
      "Val Loss at Epoch 740 is 0.00008615\n",
      "Train Loss at Epoch 741 is 0.00959732\n",
      "Val Loss at Epoch 741 is 0.00008604\n",
      "Train Loss at Epoch 742 is 0.00959278\n",
      "Val Loss at Epoch 742 is 0.00008593\n",
      "Train Loss at Epoch 743 is 0.00958823\n",
      "Val Loss at Epoch 743 is 0.00008581\n",
      "Train Loss at Epoch 744 is 0.00958368\n",
      "Val Loss at Epoch 744 is 0.00008570\n",
      "Train Loss at Epoch 745 is 0.00957911\n",
      "Val Loss at Epoch 745 is 0.00008559\n",
      "Train Loss at Epoch 746 is 0.00957453\n",
      "Val Loss at Epoch 746 is 0.00008548\n",
      "Train Loss at Epoch 747 is 0.00956995\n",
      "Val Loss at Epoch 747 is 0.00008537\n",
      "Train Loss at Epoch 748 is 0.00956535\n",
      "Val Loss at Epoch 748 is 0.00008526\n",
      "Train Loss at Epoch 749 is 0.00956075\n",
      "Val Loss at Epoch 749 is 0.00008516\n",
      "Train Loss at Epoch 750 is 0.00955613\n",
      "Val Loss at Epoch 750 is 0.00008505\n",
      "Train Loss at Epoch 751 is 0.00955151\n",
      "Val Loss at Epoch 751 is 0.00008494\n",
      "Train Loss at Epoch 752 is 0.00954687\n",
      "Val Loss at Epoch 752 is 0.00008483\n",
      "Train Loss at Epoch 753 is 0.00954223\n",
      "Val Loss at Epoch 753 is 0.00008473\n",
      "Train Loss at Epoch 754 is 0.00953757\n",
      "Val Loss at Epoch 754 is 0.00008462\n",
      "Train Loss at Epoch 755 is 0.00953290\n",
      "Val Loss at Epoch 755 is 0.00008451\n",
      "Train Loss at Epoch 756 is 0.00952823\n",
      "Val Loss at Epoch 756 is 0.00008441\n",
      "Train Loss at Epoch 757 is 0.00952354\n",
      "Val Loss at Epoch 757 is 0.00008430\n",
      "Train Loss at Epoch 758 is 0.00951884\n",
      "Val Loss at Epoch 758 is 0.00008420\n",
      "Train Loss at Epoch 759 is 0.00951413\n",
      "Val Loss at Epoch 759 is 0.00008409\n",
      "Train Loss at Epoch 760 is 0.00950942\n",
      "Val Loss at Epoch 760 is 0.00008399\n",
      "Train Loss at Epoch 761 is 0.00950469\n",
      "Val Loss at Epoch 761 is 0.00008389\n",
      "Train Loss at Epoch 762 is 0.00949994\n",
      "Val Loss at Epoch 762 is 0.00008378\n",
      "Train Loss at Epoch 763 is 0.00949519\n",
      "Val Loss at Epoch 763 is 0.00008368\n",
      "Train Loss at Epoch 764 is 0.00949043\n",
      "Val Loss at Epoch 764 is 0.00008358\n",
      "Train Loss at Epoch 765 is 0.00948565\n",
      "Val Loss at Epoch 765 is 0.00008348\n",
      "Train Loss at Epoch 766 is 0.00948087\n",
      "Val Loss at Epoch 766 is 0.00008338\n",
      "Train Loss at Epoch 767 is 0.00947607\n",
      "Val Loss at Epoch 767 is 0.00008328\n",
      "Train Loss at Epoch 768 is 0.00947126\n",
      "Val Loss at Epoch 768 is 0.00008318\n",
      "Train Loss at Epoch 769 is 0.00946644\n",
      "Val Loss at Epoch 769 is 0.00008308\n",
      "Train Loss at Epoch 770 is 0.00946161\n",
      "Val Loss at Epoch 770 is 0.00008298\n",
      "Train Loss at Epoch 771 is 0.00945676\n",
      "Val Loss at Epoch 771 is 0.00008288\n",
      "Train Loss at Epoch 772 is 0.00945191\n",
      "Val Loss at Epoch 772 is 0.00008278\n",
      "Train Loss at Epoch 773 is 0.00944704\n",
      "Val Loss at Epoch 773 is 0.00008268\n",
      "Train Loss at Epoch 774 is 0.00944216\n",
      "Val Loss at Epoch 774 is 0.00008258\n",
      "Train Loss at Epoch 775 is 0.00943727\n",
      "Val Loss at Epoch 775 is 0.00008248\n",
      "Train Loss at Epoch 776 is 0.00943237\n",
      "Val Loss at Epoch 776 is 0.00008239\n",
      "Train Loss at Epoch 777 is 0.00942746\n",
      "Val Loss at Epoch 777 is 0.00008229\n",
      "Train Loss at Epoch 778 is 0.00942253\n",
      "Val Loss at Epoch 778 is 0.00008219\n",
      "Train Loss at Epoch 779 is 0.00941759\n",
      "Val Loss at Epoch 779 is 0.00008210\n",
      "Train Loss at Epoch 780 is 0.00941264\n",
      "Val Loss at Epoch 780 is 0.00008200\n",
      "Train Loss at Epoch 781 is 0.00940768\n",
      "Val Loss at Epoch 781 is 0.00008191\n",
      "Train Loss at Epoch 782 is 0.00940270\n",
      "Val Loss at Epoch 782 is 0.00008181\n",
      "Train Loss at Epoch 783 is 0.00939772\n",
      "Val Loss at Epoch 783 is 0.00008172\n",
      "Train Loss at Epoch 784 is 0.00939272\n",
      "Val Loss at Epoch 784 is 0.00008162\n",
      "Train Loss at Epoch 785 is 0.00938771\n",
      "Val Loss at Epoch 785 is 0.00008153\n",
      "Train Loss at Epoch 786 is 0.00938269\n",
      "Val Loss at Epoch 786 is 0.00008144\n",
      "Train Loss at Epoch 787 is 0.00937765\n",
      "Val Loss at Epoch 787 is 0.00008134\n",
      "Train Loss at Epoch 788 is 0.00937261\n",
      "Val Loss at Epoch 788 is 0.00008125\n",
      "Train Loss at Epoch 789 is 0.00936755\n",
      "Val Loss at Epoch 789 is 0.00008116\n",
      "Train Loss at Epoch 790 is 0.00936248\n",
      "Val Loss at Epoch 790 is 0.00008106\n",
      "Train Loss at Epoch 791 is 0.00935739\n",
      "Val Loss at Epoch 791 is 0.00008097\n",
      "Train Loss at Epoch 792 is 0.00935230\n",
      "Val Loss at Epoch 792 is 0.00008088\n",
      "Train Loss at Epoch 793 is 0.00934719\n",
      "Val Loss at Epoch 793 is 0.00008079\n",
      "Train Loss at Epoch 794 is 0.00934207\n",
      "Val Loss at Epoch 794 is 0.00008070\n",
      "Train Loss at Epoch 795 is 0.00933694\n",
      "Val Loss at Epoch 795 is 0.00008061\n",
      "Train Loss at Epoch 796 is 0.00933179\n",
      "Val Loss at Epoch 796 is 0.00008052\n",
      "Train Loss at Epoch 797 is 0.00932664\n",
      "Val Loss at Epoch 797 is 0.00008043\n",
      "Train Loss at Epoch 798 is 0.00932147\n",
      "Val Loss at Epoch 798 is 0.00008034\n",
      "Train Loss at Epoch 799 is 0.00931629\n",
      "Val Loss at Epoch 799 is 0.00008025\n",
      "Train Loss at Epoch 800 is 0.00931110\n",
      "Val Loss at Epoch 800 is 0.00008016\n",
      "Train Loss at Epoch 801 is 0.00930589\n",
      "Val Loss at Epoch 801 is 0.00008008\n",
      "Train Loss at Epoch 802 is 0.00930068\n",
      "Val Loss at Epoch 802 is 0.00007999\n",
      "Train Loss at Epoch 803 is 0.00929545\n",
      "Val Loss at Epoch 803 is 0.00007990\n",
      "Train Loss at Epoch 804 is 0.00929021\n",
      "Val Loss at Epoch 804 is 0.00007981\n",
      "Train Loss at Epoch 805 is 0.00928496\n",
      "Val Loss at Epoch 805 is 0.00007973\n",
      "Train Loss at Epoch 806 is 0.00927970\n",
      "Val Loss at Epoch 806 is 0.00007964\n",
      "Train Loss at Epoch 807 is 0.00927442\n",
      "Val Loss at Epoch 807 is 0.00007955\n",
      "Train Loss at Epoch 808 is 0.00926913\n",
      "Val Loss at Epoch 808 is 0.00007947\n",
      "Train Loss at Epoch 809 is 0.00926383\n",
      "Val Loss at Epoch 809 is 0.00007938\n",
      "Train Loss at Epoch 810 is 0.00925852\n",
      "Val Loss at Epoch 810 is 0.00007930\n",
      "Train Loss at Epoch 811 is 0.00925320\n",
      "Val Loss at Epoch 811 is 0.00007921\n",
      "Train Loss at Epoch 812 is 0.00924787\n",
      "Val Loss at Epoch 812 is 0.00007913\n",
      "Train Loss at Epoch 813 is 0.00924252\n",
      "Val Loss at Epoch 813 is 0.00007904\n",
      "Train Loss at Epoch 814 is 0.00923716\n",
      "Val Loss at Epoch 814 is 0.00007896\n",
      "Train Loss at Epoch 815 is 0.00923180\n",
      "Val Loss at Epoch 815 is 0.00007888\n",
      "Train Loss at Epoch 816 is 0.00922642\n",
      "Val Loss at Epoch 816 is 0.00007879\n",
      "Train Loss at Epoch 817 is 0.00922102\n",
      "Val Loss at Epoch 817 is 0.00007871\n",
      "Train Loss at Epoch 818 is 0.00921562\n",
      "Val Loss at Epoch 818 is 0.00007863\n",
      "Train Loss at Epoch 819 is 0.00921021\n",
      "Val Loss at Epoch 819 is 0.00007854\n",
      "Train Loss at Epoch 820 is 0.00920478\n",
      "Val Loss at Epoch 820 is 0.00007846\n",
      "Train Loss at Epoch 821 is 0.00919935\n",
      "Val Loss at Epoch 821 is 0.00007838\n",
      "Train Loss at Epoch 822 is 0.00919390\n",
      "Val Loss at Epoch 822 is 0.00007830\n",
      "Train Loss at Epoch 823 is 0.00918844\n",
      "Val Loss at Epoch 823 is 0.00007822\n",
      "Train Loss at Epoch 824 is 0.00918297\n",
      "Val Loss at Epoch 824 is 0.00007814\n",
      "Train Loss at Epoch 825 is 0.00917749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss at Epoch 825 is 0.00007806\n",
      "Train Loss at Epoch 826 is 0.00917200\n",
      "Val Loss at Epoch 826 is 0.00007798\n",
      "Train Loss at Epoch 827 is 0.00916649\n",
      "Val Loss at Epoch 827 is 0.00007790\n",
      "Train Loss at Epoch 828 is 0.00916098\n",
      "Val Loss at Epoch 828 is 0.00007782\n",
      "Train Loss at Epoch 829 is 0.00915546\n",
      "Val Loss at Epoch 829 is 0.00007774\n",
      "Train Loss at Epoch 830 is 0.00914992\n",
      "Val Loss at Epoch 830 is 0.00007766\n",
      "Train Loss at Epoch 831 is 0.00914438\n",
      "Val Loss at Epoch 831 is 0.00007758\n",
      "Train Loss at Epoch 832 is 0.00913882\n",
      "Val Loss at Epoch 832 is 0.00007750\n",
      "Train Loss at Epoch 833 is 0.00913326\n",
      "Val Loss at Epoch 833 is 0.00007742\n",
      "Train Loss at Epoch 834 is 0.00912768\n",
      "Val Loss at Epoch 834 is 0.00007734\n",
      "Train Loss at Epoch 835 is 0.00912210\n",
      "Val Loss at Epoch 835 is 0.00007726\n",
      "Train Loss at Epoch 836 is 0.00911650\n",
      "Val Loss at Epoch 836 is 0.00007719\n",
      "Train Loss at Epoch 837 is 0.00911089\n",
      "Val Loss at Epoch 837 is 0.00007711\n",
      "Train Loss at Epoch 838 is 0.00910528\n",
      "Val Loss at Epoch 838 is 0.00007703\n",
      "Train Loss at Epoch 839 is 0.00909965\n",
      "Val Loss at Epoch 839 is 0.00007696\n",
      "Train Loss at Epoch 840 is 0.00909401\n",
      "Val Loss at Epoch 840 is 0.00007688\n",
      "Train Loss at Epoch 841 is 0.00908837\n",
      "Val Loss at Epoch 841 is 0.00007680\n",
      "Train Loss at Epoch 842 is 0.00908271\n",
      "Val Loss at Epoch 842 is 0.00007673\n",
      "Train Loss at Epoch 843 is 0.00907705\n",
      "Val Loss at Epoch 843 is 0.00007665\n",
      "Train Loss at Epoch 844 is 0.00907137\n",
      "Val Loss at Epoch 844 is 0.00007658\n",
      "Train Loss at Epoch 845 is 0.00906569\n",
      "Val Loss at Epoch 845 is 0.00007650\n",
      "Train Loss at Epoch 846 is 0.00905999\n",
      "Val Loss at Epoch 846 is 0.00007643\n",
      "Train Loss at Epoch 847 is 0.00905429\n",
      "Val Loss at Epoch 847 is 0.00007635\n",
      "Train Loss at Epoch 848 is 0.00904858\n",
      "Val Loss at Epoch 848 is 0.00007628\n",
      "Train Loss at Epoch 849 is 0.00904286\n",
      "Val Loss at Epoch 849 is 0.00007620\n",
      "Train Loss at Epoch 850 is 0.00903713\n",
      "Val Loss at Epoch 850 is 0.00007613\n",
      "Train Loss at Epoch 851 is 0.00903139\n",
      "Val Loss at Epoch 851 is 0.00007605\n",
      "Train Loss at Epoch 852 is 0.00902564\n",
      "Val Loss at Epoch 852 is 0.00007598\n",
      "Train Loss at Epoch 853 is 0.00901988\n",
      "Val Loss at Epoch 853 is 0.00007591\n",
      "Train Loss at Epoch 854 is 0.00901412\n",
      "Val Loss at Epoch 854 is 0.00007583\n",
      "Train Loss at Epoch 855 is 0.00900834\n",
      "Val Loss at Epoch 855 is 0.00007576\n",
      "Train Loss at Epoch 856 is 0.00900256\n",
      "Val Loss at Epoch 856 is 0.00007569\n",
      "Train Loss at Epoch 857 is 0.00899677\n",
      "Val Loss at Epoch 857 is 0.00007562\n",
      "Train Loss at Epoch 858 is 0.00899097\n",
      "Val Loss at Epoch 858 is 0.00007554\n",
      "Train Loss at Epoch 859 is 0.00898516\n",
      "Val Loss at Epoch 859 is 0.00007547\n",
      "Train Loss at Epoch 860 is 0.00897935\n",
      "Val Loss at Epoch 860 is 0.00007540\n",
      "Train Loss at Epoch 861 is 0.00897352\n",
      "Val Loss at Epoch 861 is 0.00007533\n",
      "Train Loss at Epoch 862 is 0.00896769\n",
      "Val Loss at Epoch 862 is 0.00007526\n",
      "Train Loss at Epoch 863 is 0.00896185\n",
      "Val Loss at Epoch 863 is 0.00007519\n",
      "Train Loss at Epoch 864 is 0.00895601\n",
      "Val Loss at Epoch 864 is 0.00007512\n",
      "Train Loss at Epoch 865 is 0.00895015\n",
      "Val Loss at Epoch 865 is 0.00007505\n",
      "Train Loss at Epoch 866 is 0.00894429\n",
      "Val Loss at Epoch 866 is 0.00007497\n",
      "Train Loss at Epoch 867 is 0.00893842\n",
      "Val Loss at Epoch 867 is 0.00007490\n",
      "Train Loss at Epoch 868 is 0.00893254\n",
      "Val Loss at Epoch 868 is 0.00007483\n",
      "Train Loss at Epoch 869 is 0.00892666\n",
      "Val Loss at Epoch 869 is 0.00007476\n",
      "Train Loss at Epoch 870 is 0.00892076\n",
      "Val Loss at Epoch 870 is 0.00007470\n",
      "Train Loss at Epoch 871 is 0.00891486\n",
      "Val Loss at Epoch 871 is 0.00007463\n",
      "Train Loss at Epoch 872 is 0.00890896\n",
      "Val Loss at Epoch 872 is 0.00007456\n",
      "Train Loss at Epoch 873 is 0.00890304\n",
      "Val Loss at Epoch 873 is 0.00007449\n",
      "Train Loss at Epoch 874 is 0.00889712\n",
      "Val Loss at Epoch 874 is 0.00007442\n",
      "Train Loss at Epoch 875 is 0.00889120\n",
      "Val Loss at Epoch 875 is 0.00007435\n",
      "Train Loss at Epoch 876 is 0.00888526\n",
      "Val Loss at Epoch 876 is 0.00007428\n",
      "Train Loss at Epoch 877 is 0.00887932\n",
      "Val Loss at Epoch 877 is 0.00007422\n",
      "Train Loss at Epoch 878 is 0.00887338\n",
      "Val Loss at Epoch 878 is 0.00007415\n",
      "Train Loss at Epoch 879 is 0.00886742\n",
      "Val Loss at Epoch 879 is 0.00007408\n",
      "Train Loss at Epoch 880 is 0.00886147\n",
      "Val Loss at Epoch 880 is 0.00007401\n",
      "Train Loss at Epoch 881 is 0.00885550\n",
      "Val Loss at Epoch 881 is 0.00007395\n",
      "Train Loss at Epoch 882 is 0.00884953\n",
      "Val Loss at Epoch 882 is 0.00007388\n",
      "Train Loss at Epoch 883 is 0.00884355\n",
      "Val Loss at Epoch 883 is 0.00007381\n",
      "Train Loss at Epoch 884 is 0.00883757\n",
      "Val Loss at Epoch 884 is 0.00007374\n",
      "Train Loss at Epoch 885 is 0.00883158\n",
      "Val Loss at Epoch 885 is 0.00007368\n",
      "Train Loss at Epoch 886 is 0.00882558\n",
      "Val Loss at Epoch 886 is 0.00007361\n",
      "Train Loss at Epoch 887 is 0.00881958\n",
      "Val Loss at Epoch 887 is 0.00007355\n",
      "Train Loss at Epoch 888 is 0.00881358\n",
      "Val Loss at Epoch 888 is 0.00007348\n",
      "Train Loss at Epoch 889 is 0.00880757\n",
      "Val Loss at Epoch 889 is 0.00007341\n",
      "Train Loss at Epoch 890 is 0.00880155\n",
      "Val Loss at Epoch 890 is 0.00007335\n",
      "Train Loss at Epoch 891 is 0.00879553\n",
      "Val Loss at Epoch 891 is 0.00007328\n",
      "Train Loss at Epoch 892 is 0.00878950\n",
      "Val Loss at Epoch 892 is 0.00007322\n",
      "Train Loss at Epoch 893 is 0.00878347\n",
      "Val Loss at Epoch 893 is 0.00007315\n",
      "Train Loss at Epoch 894 is 0.00877743\n",
      "Val Loss at Epoch 894 is 0.00007309\n",
      "Train Loss at Epoch 895 is 0.00877139\n",
      "Val Loss at Epoch 895 is 0.00007302\n",
      "Train Loss at Epoch 896 is 0.00876534\n",
      "Val Loss at Epoch 896 is 0.00007296\n",
      "Train Loss at Epoch 897 is 0.00875929\n",
      "Val Loss at Epoch 897 is 0.00007290\n",
      "Train Loss at Epoch 898 is 0.00875323\n",
      "Val Loss at Epoch 898 is 0.00007283\n",
      "Train Loss at Epoch 899 is 0.00874717\n",
      "Val Loss at Epoch 899 is 0.00007277\n",
      "Train Loss at Epoch 900 is 0.00874111\n",
      "Val Loss at Epoch 900 is 0.00007270\n",
      "Train Loss at Epoch 901 is 0.00873504\n",
      "Val Loss at Epoch 901 is 0.00007264\n",
      "Train Loss at Epoch 902 is 0.00872896\n",
      "Val Loss at Epoch 902 is 0.00007258\n",
      "Train Loss at Epoch 903 is 0.00872288\n",
      "Val Loss at Epoch 903 is 0.00007251\n",
      "Train Loss at Epoch 904 is 0.00871680\n",
      "Val Loss at Epoch 904 is 0.00007245\n",
      "Train Loss at Epoch 905 is 0.00871071\n",
      "Val Loss at Epoch 905 is 0.00007239\n",
      "Train Loss at Epoch 906 is 0.00870462\n",
      "Val Loss at Epoch 906 is 0.00007233\n",
      "Train Loss at Epoch 907 is 0.00869853\n",
      "Val Loss at Epoch 907 is 0.00007226\n",
      "Train Loss at Epoch 908 is 0.00869243\n",
      "Val Loss at Epoch 908 is 0.00007220\n",
      "Train Loss at Epoch 909 is 0.00868633\n",
      "Val Loss at Epoch 909 is 0.00007214\n",
      "Train Loss at Epoch 910 is 0.00868023\n",
      "Val Loss at Epoch 910 is 0.00007208\n",
      "Train Loss at Epoch 911 is 0.00867412\n",
      "Val Loss at Epoch 911 is 0.00007202\n",
      "Train Loss at Epoch 912 is 0.00866800\n",
      "Val Loss at Epoch 912 is 0.00007195\n",
      "Train Loss at Epoch 913 is 0.00866189\n",
      "Val Loss at Epoch 913 is 0.00007189\n",
      "Train Loss at Epoch 914 is 0.00865577\n",
      "Val Loss at Epoch 914 is 0.00007183\n",
      "Train Loss at Epoch 915 is 0.00864965\n",
      "Val Loss at Epoch 915 is 0.00007177\n",
      "Train Loss at Epoch 916 is 0.00864352\n",
      "Val Loss at Epoch 916 is 0.00007171\n",
      "Train Loss at Epoch 917 is 0.00863740\n",
      "Val Loss at Epoch 917 is 0.00007165\n",
      "Train Loss at Epoch 918 is 0.00863127\n",
      "Val Loss at Epoch 918 is 0.00007159\n",
      "Train Loss at Epoch 919 is 0.00862513\n",
      "Val Loss at Epoch 919 is 0.00007153\n",
      "Train Loss at Epoch 920 is 0.00861900\n",
      "Val Loss at Epoch 920 is 0.00007147\n",
      "Train Loss at Epoch 921 is 0.00861286\n",
      "Val Loss at Epoch 921 is 0.00007141\n",
      "Train Loss at Epoch 922 is 0.00860672\n",
      "Val Loss at Epoch 922 is 0.00007135\n",
      "Train Loss at Epoch 923 is 0.00860057\n",
      "Val Loss at Epoch 923 is 0.00007129\n",
      "Train Loss at Epoch 924 is 0.00859443\n",
      "Val Loss at Epoch 924 is 0.00007123\n",
      "Train Loss at Epoch 925 is 0.00858828\n",
      "Val Loss at Epoch 925 is 0.00007117\n",
      "Train Loss at Epoch 926 is 0.00858213\n",
      "Val Loss at Epoch 926 is 0.00007111\n",
      "Train Loss at Epoch 927 is 0.00857597\n",
      "Val Loss at Epoch 927 is 0.00007105\n",
      "Train Loss at Epoch 928 is 0.00856982\n",
      "Val Loss at Epoch 928 is 0.00007099\n",
      "Train Loss at Epoch 929 is 0.00856366\n",
      "Val Loss at Epoch 929 is 0.00007093\n",
      "Train Loss at Epoch 930 is 0.00855750\n",
      "Val Loss at Epoch 930 is 0.00007087\n",
      "Train Loss at Epoch 931 is 0.00855134\n",
      "Val Loss at Epoch 931 is 0.00007081\n",
      "Train Loss at Epoch 932 is 0.00854518\n",
      "Val Loss at Epoch 932 is 0.00007076\n",
      "Train Loss at Epoch 933 is 0.00853901\n",
      "Val Loss at Epoch 933 is 0.00007070\n",
      "Train Loss at Epoch 934 is 0.00853285\n",
      "Val Loss at Epoch 934 is 0.00007064\n",
      "Train Loss at Epoch 935 is 0.00852668\n",
      "Val Loss at Epoch 935 is 0.00007058\n",
      "Train Loss at Epoch 936 is 0.00852051\n",
      "Val Loss at Epoch 936 is 0.00007052\n",
      "Train Loss at Epoch 937 is 0.00851434\n",
      "Val Loss at Epoch 937 is 0.00007046\n",
      "Train Loss at Epoch 938 is 0.00850817\n",
      "Val Loss at Epoch 938 is 0.00007041\n",
      "Train Loss at Epoch 939 is 0.00850200\n",
      "Val Loss at Epoch 939 is 0.00007035\n",
      "Train Loss at Epoch 940 is 0.00849582\n",
      "Val Loss at Epoch 940 is 0.00007029\n",
      "Train Loss at Epoch 941 is 0.00848965\n",
      "Val Loss at Epoch 941 is 0.00007023\n",
      "Train Loss at Epoch 942 is 0.00848347\n",
      "Val Loss at Epoch 942 is 0.00007018\n",
      "Train Loss at Epoch 943 is 0.00847729\n",
      "Val Loss at Epoch 943 is 0.00007012\n",
      "Train Loss at Epoch 944 is 0.00847111\n",
      "Val Loss at Epoch 944 is 0.00007006\n",
      "Train Loss at Epoch 945 is 0.00846493\n",
      "Val Loss at Epoch 945 is 0.00007001\n",
      "Train Loss at Epoch 946 is 0.00845875\n",
      "Val Loss at Epoch 946 is 0.00006995\n",
      "Train Loss at Epoch 947 is 0.00845257\n",
      "Val Loss at Epoch 947 is 0.00006989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 948 is 0.00844639\n",
      "Val Loss at Epoch 948 is 0.00006984\n",
      "Train Loss at Epoch 949 is 0.00844021\n",
      "Val Loss at Epoch 949 is 0.00006978\n",
      "Train Loss at Epoch 950 is 0.00843403\n",
      "Val Loss at Epoch 950 is 0.00006973\n",
      "Train Loss at Epoch 951 is 0.00842785\n",
      "Val Loss at Epoch 951 is 0.00006967\n",
      "Train Loss at Epoch 952 is 0.00842166\n",
      "Val Loss at Epoch 952 is 0.00006961\n",
      "Train Loss at Epoch 953 is 0.00841548\n",
      "Val Loss at Epoch 953 is 0.00006956\n",
      "Train Loss at Epoch 954 is 0.00840930\n",
      "Val Loss at Epoch 954 is 0.00006950\n",
      "Train Loss at Epoch 955 is 0.00840311\n",
      "Val Loss at Epoch 955 is 0.00006945\n",
      "Train Loss at Epoch 956 is 0.00839693\n",
      "Val Loss at Epoch 956 is 0.00006939\n",
      "Train Loss at Epoch 957 is 0.00839075\n",
      "Val Loss at Epoch 957 is 0.00006934\n",
      "Train Loss at Epoch 958 is 0.00838456\n",
      "Val Loss at Epoch 958 is 0.00006928\n",
      "Train Loss at Epoch 959 is 0.00837838\n",
      "Val Loss at Epoch 959 is 0.00006923\n",
      "Train Loss at Epoch 960 is 0.00837219\n",
      "Val Loss at Epoch 960 is 0.00006917\n",
      "Train Loss at Epoch 961 is 0.00836601\n",
      "Val Loss at Epoch 961 is 0.00006912\n",
      "Train Loss at Epoch 962 is 0.00835983\n",
      "Val Loss at Epoch 962 is 0.00006906\n",
      "Train Loss at Epoch 963 is 0.00835365\n",
      "Val Loss at Epoch 963 is 0.00006901\n",
      "Train Loss at Epoch 964 is 0.00834746\n",
      "Val Loss at Epoch 964 is 0.00006895\n",
      "Train Loss at Epoch 965 is 0.00834128\n",
      "Val Loss at Epoch 965 is 0.00006890\n",
      "Train Loss at Epoch 966 is 0.00833510\n",
      "Val Loss at Epoch 966 is 0.00006885\n",
      "Train Loss at Epoch 967 is 0.00832892\n",
      "Val Loss at Epoch 967 is 0.00006879\n",
      "Train Loss at Epoch 968 is 0.00832274\n",
      "Val Loss at Epoch 968 is 0.00006874\n",
      "Train Loss at Epoch 969 is 0.00831656\n",
      "Val Loss at Epoch 969 is 0.00006868\n",
      "Train Loss at Epoch 970 is 0.00831038\n",
      "Val Loss at Epoch 970 is 0.00006863\n",
      "Train Loss at Epoch 971 is 0.00830420\n",
      "Val Loss at Epoch 971 is 0.00006858\n",
      "Train Loss at Epoch 972 is 0.00829803\n",
      "Val Loss at Epoch 972 is 0.00006852\n",
      "Train Loss at Epoch 973 is 0.00829185\n",
      "Val Loss at Epoch 973 is 0.00006847\n",
      "Train Loss at Epoch 974 is 0.00828567\n",
      "Val Loss at Epoch 974 is 0.00006842\n",
      "Train Loss at Epoch 975 is 0.00827950\n",
      "Val Loss at Epoch 975 is 0.00006836\n",
      "Train Loss at Epoch 976 is 0.00827333\n",
      "Val Loss at Epoch 976 is 0.00006831\n",
      "Train Loss at Epoch 977 is 0.00826716\n",
      "Val Loss at Epoch 977 is 0.00006826\n",
      "Train Loss at Epoch 978 is 0.00826098\n",
      "Val Loss at Epoch 978 is 0.00006821\n",
      "Train Loss at Epoch 979 is 0.00825481\n",
      "Val Loss at Epoch 979 is 0.00006815\n",
      "Train Loss at Epoch 980 is 0.00824865\n",
      "Val Loss at Epoch 980 is 0.00006810\n",
      "Train Loss at Epoch 981 is 0.00824248\n",
      "Val Loss at Epoch 981 is 0.00006805\n",
      "Train Loss at Epoch 982 is 0.00823631\n",
      "Val Loss at Epoch 982 is 0.00006800\n",
      "Train Loss at Epoch 983 is 0.00823015\n",
      "Val Loss at Epoch 983 is 0.00006795\n",
      "Train Loss at Epoch 984 is 0.00822399\n",
      "Val Loss at Epoch 984 is 0.00006789\n",
      "Train Loss at Epoch 985 is 0.00821783\n",
      "Val Loss at Epoch 985 is 0.00006784\n",
      "Train Loss at Epoch 986 is 0.00821167\n",
      "Val Loss at Epoch 986 is 0.00006779\n",
      "Train Loss at Epoch 987 is 0.00820551\n",
      "Val Loss at Epoch 987 is 0.00006774\n",
      "Train Loss at Epoch 988 is 0.00819935\n",
      "Val Loss at Epoch 988 is 0.00006769\n",
      "Train Loss at Epoch 989 is 0.00819320\n",
      "Val Loss at Epoch 989 is 0.00006763\n",
      "Train Loss at Epoch 990 is 0.00818705\n",
      "Val Loss at Epoch 990 is 0.00006758\n",
      "Train Loss at Epoch 991 is 0.00818090\n",
      "Val Loss at Epoch 991 is 0.00006753\n",
      "Train Loss at Epoch 992 is 0.00817475\n",
      "Val Loss at Epoch 992 is 0.00006748\n",
      "Train Loss at Epoch 993 is 0.00816860\n",
      "Val Loss at Epoch 993 is 0.00006743\n",
      "Train Loss at Epoch 994 is 0.00816245\n",
      "Val Loss at Epoch 994 is 0.00006738\n",
      "Train Loss at Epoch 995 is 0.00815631\n",
      "Val Loss at Epoch 995 is 0.00006733\n",
      "Train Loss at Epoch 996 is 0.00815017\n",
      "Val Loss at Epoch 996 is 0.00006728\n",
      "Train Loss at Epoch 997 is 0.00814403\n",
      "Val Loss at Epoch 997 is 0.00006723\n",
      "Train Loss at Epoch 998 is 0.00813789\n",
      "Val Loss at Epoch 998 is 0.00006718\n",
      "Train Loss at Epoch 999 is 0.00813176\n",
      "Val Loss at Epoch 999 is 0.00006713\n",
      "Train Loss at Epoch 1000 is 0.00812563\n",
      "Val Loss at Epoch 1000 is 0.00006708\n",
      "Train Loss at Epoch 1001 is 0.00811950\n",
      "Val Loss at Epoch 1001 is 0.00006703\n",
      "Train Loss at Epoch 1002 is 0.00811337\n",
      "Val Loss at Epoch 1002 is 0.00006698\n",
      "Train Loss at Epoch 1003 is 0.00810724\n",
      "Val Loss at Epoch 1003 is 0.00006693\n",
      "Train Loss at Epoch 1004 is 0.00810112\n",
      "Val Loss at Epoch 1004 is 0.00006688\n",
      "Train Loss at Epoch 1005 is 0.00809500\n",
      "Val Loss at Epoch 1005 is 0.00006683\n",
      "Train Loss at Epoch 1006 is 0.00808888\n",
      "Val Loss at Epoch 1006 is 0.00006678\n",
      "Train Loss at Epoch 1007 is 0.00808277\n",
      "Val Loss at Epoch 1007 is 0.00006673\n",
      "Train Loss at Epoch 1008 is 0.00807665\n",
      "Val Loss at Epoch 1008 is 0.00006668\n",
      "Train Loss at Epoch 1009 is 0.00807054\n",
      "Val Loss at Epoch 1009 is 0.00006663\n",
      "Train Loss at Epoch 1010 is 0.00806443\n",
      "Val Loss at Epoch 1010 is 0.00006658\n",
      "Train Loss at Epoch 1011 is 0.00805833\n",
      "Val Loss at Epoch 1011 is 0.00006653\n",
      "Train Loss at Epoch 1012 is 0.00805222\n",
      "Val Loss at Epoch 1012 is 0.00006648\n",
      "Train Loss at Epoch 1013 is 0.00804612\n",
      "Val Loss at Epoch 1013 is 0.00006643\n",
      "Train Loss at Epoch 1014 is 0.00804003\n",
      "Val Loss at Epoch 1014 is 0.00006638\n",
      "Train Loss at Epoch 1015 is 0.00803393\n",
      "Val Loss at Epoch 1015 is 0.00006633\n",
      "Train Loss at Epoch 1016 is 0.00802784\n",
      "Val Loss at Epoch 1016 is 0.00006628\n",
      "Train Loss at Epoch 1017 is 0.00802175\n",
      "Val Loss at Epoch 1017 is 0.00006624\n",
      "Train Loss at Epoch 1018 is 0.00801567\n",
      "Val Loss at Epoch 1018 is 0.00006619\n",
      "Train Loss at Epoch 1019 is 0.00800958\n",
      "Val Loss at Epoch 1019 is 0.00006614\n",
      "Train Loss at Epoch 1020 is 0.00800350\n",
      "Val Loss at Epoch 1020 is 0.00006609\n",
      "Train Loss at Epoch 1021 is 0.00799743\n",
      "Val Loss at Epoch 1021 is 0.00006604\n",
      "Train Loss at Epoch 1022 is 0.00799135\n",
      "Val Loss at Epoch 1022 is 0.00006599\n",
      "Train Loss at Epoch 1023 is 0.00798528\n",
      "Val Loss at Epoch 1023 is 0.00006595\n",
      "Train Loss at Epoch 1024 is 0.00797921\n",
      "Val Loss at Epoch 1024 is 0.00006590\n",
      "Train Loss at Epoch 1025 is 0.00797315\n",
      "Val Loss at Epoch 1025 is 0.00006585\n",
      "Train Loss at Epoch 1026 is 0.00796709\n",
      "Val Loss at Epoch 1026 is 0.00006580\n",
      "Train Loss at Epoch 1027 is 0.00796103\n",
      "Val Loss at Epoch 1027 is 0.00006575\n",
      "Train Loss at Epoch 1028 is 0.00795497\n",
      "Val Loss at Epoch 1028 is 0.00006571\n",
      "Train Loss at Epoch 1029 is 0.00794892\n",
      "Val Loss at Epoch 1029 is 0.00006566\n",
      "Train Loss at Epoch 1030 is 0.00794287\n",
      "Val Loss at Epoch 1030 is 0.00006561\n",
      "Train Loss at Epoch 1031 is 0.00793683\n",
      "Val Loss at Epoch 1031 is 0.00006556\n",
      "Train Loss at Epoch 1032 is 0.00793079\n",
      "Val Loss at Epoch 1032 is 0.00006552\n",
      "Train Loss at Epoch 1033 is 0.00792475\n",
      "Val Loss at Epoch 1033 is 0.00006547\n",
      "Train Loss at Epoch 1034 is 0.00791871\n",
      "Val Loss at Epoch 1034 is 0.00006542\n",
      "Train Loss at Epoch 1035 is 0.00791268\n",
      "Val Loss at Epoch 1035 is 0.00006537\n",
      "Train Loss at Epoch 1036 is 0.00790665\n",
      "Val Loss at Epoch 1036 is 0.00006533\n",
      "Train Loss at Epoch 1037 is 0.00790063\n",
      "Val Loss at Epoch 1037 is 0.00006528\n",
      "Train Loss at Epoch 1038 is 0.00789461\n",
      "Val Loss at Epoch 1038 is 0.00006523\n",
      "Train Loss at Epoch 1039 is 0.00788859\n",
      "Val Loss at Epoch 1039 is 0.00006519\n",
      "Train Loss at Epoch 1040 is 0.00788257\n",
      "Val Loss at Epoch 1040 is 0.00006514\n",
      "Train Loss at Epoch 1041 is 0.00787656\n",
      "Val Loss at Epoch 1041 is 0.00006509\n",
      "Train Loss at Epoch 1042 is 0.00787055\n",
      "Val Loss at Epoch 1042 is 0.00006505\n",
      "Train Loss at Epoch 1043 is 0.00786455\n",
      "Val Loss at Epoch 1043 is 0.00006500\n",
      "Train Loss at Epoch 1044 is 0.00785855\n",
      "Val Loss at Epoch 1044 is 0.00006495\n",
      "Train Loss at Epoch 1045 is 0.00785255\n",
      "Val Loss at Epoch 1045 is 0.00006491\n",
      "Train Loss at Epoch 1046 is 0.00784656\n",
      "Val Loss at Epoch 1046 is 0.00006486\n",
      "Train Loss at Epoch 1047 is 0.00784057\n",
      "Val Loss at Epoch 1047 is 0.00006482\n",
      "Train Loss at Epoch 1048 is 0.00783459\n",
      "Val Loss at Epoch 1048 is 0.00006477\n",
      "Train Loss at Epoch 1049 is 0.00782861\n",
      "Val Loss at Epoch 1049 is 0.00006472\n",
      "Train Loss at Epoch 1050 is 0.00782263\n",
      "Val Loss at Epoch 1050 is 0.00006468\n",
      "Train Loss at Epoch 1051 is 0.00781666\n",
      "Val Loss at Epoch 1051 is 0.00006463\n",
      "Train Loss at Epoch 1052 is 0.00781069\n",
      "Val Loss at Epoch 1052 is 0.00006459\n",
      "Train Loss at Epoch 1053 is 0.00780472\n",
      "Val Loss at Epoch 1053 is 0.00006454\n",
      "Train Loss at Epoch 1054 is 0.00779876\n",
      "Val Loss at Epoch 1054 is 0.00006450\n",
      "Train Loss at Epoch 1055 is 0.00779280\n",
      "Val Loss at Epoch 1055 is 0.00006445\n",
      "Train Loss at Epoch 1056 is 0.00778684\n",
      "Val Loss at Epoch 1056 is 0.00006441\n",
      "Train Loss at Epoch 1057 is 0.00778089\n",
      "Val Loss at Epoch 1057 is 0.00006436\n",
      "Train Loss at Epoch 1058 is 0.00777495\n",
      "Val Loss at Epoch 1058 is 0.00006431\n",
      "Train Loss at Epoch 1059 is 0.00776901\n",
      "Val Loss at Epoch 1059 is 0.00006427\n",
      "Train Loss at Epoch 1060 is 0.00776307\n",
      "Val Loss at Epoch 1060 is 0.00006422\n",
      "Train Loss at Epoch 1061 is 0.00775713\n",
      "Val Loss at Epoch 1061 is 0.00006418\n",
      "Train Loss at Epoch 1062 is 0.00775120\n",
      "Val Loss at Epoch 1062 is 0.00006413\n",
      "Train Loss at Epoch 1063 is 0.00774528\n",
      "Val Loss at Epoch 1063 is 0.00006409\n",
      "Train Loss at Epoch 1064 is 0.00773935\n",
      "Val Loss at Epoch 1064 is 0.00006405\n",
      "Train Loss at Epoch 1065 is 0.00773343\n",
      "Val Loss at Epoch 1065 is 0.00006400\n",
      "Train Loss at Epoch 1066 is 0.00772752\n",
      "Val Loss at Epoch 1066 is 0.00006396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1067 is 0.00772161\n",
      "Val Loss at Epoch 1067 is 0.00006391\n",
      "Train Loss at Epoch 1068 is 0.00771570\n",
      "Val Loss at Epoch 1068 is 0.00006387\n",
      "Train Loss at Epoch 1069 is 0.00770980\n",
      "Val Loss at Epoch 1069 is 0.00006382\n",
      "Train Loss at Epoch 1070 is 0.00770391\n",
      "Val Loss at Epoch 1070 is 0.00006378\n",
      "Train Loss at Epoch 1071 is 0.00769801\n",
      "Val Loss at Epoch 1071 is 0.00006373\n",
      "Train Loss at Epoch 1072 is 0.00769212\n",
      "Val Loss at Epoch 1072 is 0.00006369\n",
      "Train Loss at Epoch 1073 is 0.00768624\n",
      "Val Loss at Epoch 1073 is 0.00006365\n",
      "Train Loss at Epoch 1074 is 0.00768036\n",
      "Val Loss at Epoch 1074 is 0.00006360\n",
      "Train Loss at Epoch 1075 is 0.00767448\n",
      "Val Loss at Epoch 1075 is 0.00006356\n",
      "Train Loss at Epoch 1076 is 0.00766861\n",
      "Val Loss at Epoch 1076 is 0.00006351\n",
      "Train Loss at Epoch 1077 is 0.00766274\n",
      "Val Loss at Epoch 1077 is 0.00006347\n",
      "Train Loss at Epoch 1078 is 0.00765688\n",
      "Val Loss at Epoch 1078 is 0.00006343\n",
      "Train Loss at Epoch 1079 is 0.00765102\n",
      "Val Loss at Epoch 1079 is 0.00006338\n",
      "Train Loss at Epoch 1080 is 0.00764516\n",
      "Val Loss at Epoch 1080 is 0.00006334\n",
      "Train Loss at Epoch 1081 is 0.00763931\n",
      "Val Loss at Epoch 1081 is 0.00006330\n",
      "Train Loss at Epoch 1082 is 0.00763347\n",
      "Val Loss at Epoch 1082 is 0.00006325\n",
      "Train Loss at Epoch 1083 is 0.00762762\n",
      "Val Loss at Epoch 1083 is 0.00006321\n",
      "Train Loss at Epoch 1084 is 0.00762179\n",
      "Val Loss at Epoch 1084 is 0.00006317\n",
      "Train Loss at Epoch 1085 is 0.00761595\n",
      "Val Loss at Epoch 1085 is 0.00006312\n",
      "Train Loss at Epoch 1086 is 0.00761012\n",
      "Val Loss at Epoch 1086 is 0.00006308\n",
      "Train Loss at Epoch 1087 is 0.00760430\n",
      "Val Loss at Epoch 1087 is 0.00006304\n",
      "Train Loss at Epoch 1088 is 0.00759848\n",
      "Val Loss at Epoch 1088 is 0.00006299\n",
      "Train Loss at Epoch 1089 is 0.00759267\n",
      "Val Loss at Epoch 1089 is 0.00006295\n",
      "Train Loss at Epoch 1090 is 0.00758685\n",
      "Val Loss at Epoch 1090 is 0.00006291\n",
      "Train Loss at Epoch 1091 is 0.00758105\n",
      "Val Loss at Epoch 1091 is 0.00006286\n",
      "Train Loss at Epoch 1092 is 0.00757525\n",
      "Val Loss at Epoch 1092 is 0.00006282\n",
      "Train Loss at Epoch 1093 is 0.00756945\n",
      "Val Loss at Epoch 1093 is 0.00006278\n",
      "Train Loss at Epoch 1094 is 0.00756365\n",
      "Val Loss at Epoch 1094 is 0.00006274\n",
      "Train Loss at Epoch 1095 is 0.00755787\n",
      "Val Loss at Epoch 1095 is 0.00006269\n",
      "Train Loss at Epoch 1096 is 0.00755208\n",
      "Val Loss at Epoch 1096 is 0.00006265\n",
      "Train Loss at Epoch 1097 is 0.00754630\n",
      "Val Loss at Epoch 1097 is 0.00006261\n",
      "Train Loss at Epoch 1098 is 0.00754053\n",
      "Val Loss at Epoch 1098 is 0.00006257\n",
      "Train Loss at Epoch 1099 is 0.00753476\n",
      "Val Loss at Epoch 1099 is 0.00006252\n",
      "Train Loss at Epoch 1100 is 0.00752899\n",
      "Val Loss at Epoch 1100 is 0.00006248\n",
      "Train Loss at Epoch 1101 is 0.00752323\n",
      "Val Loss at Epoch 1101 is 0.00006244\n",
      "Train Loss at Epoch 1102 is 0.00751747\n",
      "Val Loss at Epoch 1102 is 0.00006240\n",
      "Train Loss at Epoch 1103 is 0.00751172\n",
      "Val Loss at Epoch 1103 is 0.00006236\n",
      "Train Loss at Epoch 1104 is 0.00750597\n",
      "Val Loss at Epoch 1104 is 0.00006231\n",
      "Train Loss at Epoch 1105 is 0.00750023\n",
      "Val Loss at Epoch 1105 is 0.00006227\n",
      "Train Loss at Epoch 1106 is 0.00749449\n",
      "Val Loss at Epoch 1106 is 0.00006223\n",
      "Train Loss at Epoch 1107 is 0.00748876\n",
      "Val Loss at Epoch 1107 is 0.00006219\n",
      "Train Loss at Epoch 1108 is 0.00748303\n",
      "Val Loss at Epoch 1108 is 0.00006215\n",
      "Train Loss at Epoch 1109 is 0.00747731\n",
      "Val Loss at Epoch 1109 is 0.00006211\n",
      "Train Loss at Epoch 1110 is 0.00747159\n",
      "Val Loss at Epoch 1110 is 0.00006206\n",
      "Train Loss at Epoch 1111 is 0.00746587\n",
      "Val Loss at Epoch 1111 is 0.00006202\n",
      "Train Loss at Epoch 1112 is 0.00746016\n",
      "Val Loss at Epoch 1112 is 0.00006198\n",
      "Train Loss at Epoch 1113 is 0.00745445\n",
      "Val Loss at Epoch 1113 is 0.00006194\n",
      "Train Loss at Epoch 1114 is 0.00744875\n",
      "Val Loss at Epoch 1114 is 0.00006190\n",
      "Train Loss at Epoch 1115 is 0.00744306\n",
      "Val Loss at Epoch 1115 is 0.00006186\n",
      "Train Loss at Epoch 1116 is 0.00743736\n",
      "Val Loss at Epoch 1116 is 0.00006182\n",
      "Train Loss at Epoch 1117 is 0.00743168\n",
      "Val Loss at Epoch 1117 is 0.00006178\n",
      "Train Loss at Epoch 1118 is 0.00742600\n",
      "Val Loss at Epoch 1118 is 0.00006173\n",
      "Train Loss at Epoch 1119 is 0.00742032\n",
      "Val Loss at Epoch 1119 is 0.00006169\n",
      "Train Loss at Epoch 1120 is 0.00741464\n",
      "Val Loss at Epoch 1120 is 0.00006165\n",
      "Train Loss at Epoch 1121 is 0.00740898\n",
      "Val Loss at Epoch 1121 is 0.00006161\n",
      "Train Loss at Epoch 1122 is 0.00740331\n",
      "Val Loss at Epoch 1122 is 0.00006157\n",
      "Train Loss at Epoch 1123 is 0.00739765\n",
      "Val Loss at Epoch 1123 is 0.00006153\n",
      "Train Loss at Epoch 1124 is 0.00739200\n",
      "Val Loss at Epoch 1124 is 0.00006149\n",
      "Train Loss at Epoch 1125 is 0.00738635\n",
      "Val Loss at Epoch 1125 is 0.00006145\n",
      "Train Loss at Epoch 1126 is 0.00738071\n",
      "Val Loss at Epoch 1126 is 0.00006141\n",
      "Train Loss at Epoch 1127 is 0.00737507\n",
      "Val Loss at Epoch 1127 is 0.00006137\n",
      "Train Loss at Epoch 1128 is 0.00736943\n",
      "Val Loss at Epoch 1128 is 0.00006133\n",
      "Train Loss at Epoch 1129 is 0.00736380\n",
      "Val Loss at Epoch 1129 is 0.00006129\n",
      "Train Loss at Epoch 1130 is 0.00735818\n",
      "Val Loss at Epoch 1130 is 0.00006125\n",
      "Train Loss at Epoch 1131 is 0.00735255\n",
      "Val Loss at Epoch 1131 is 0.00006121\n",
      "Train Loss at Epoch 1132 is 0.00734694\n",
      "Val Loss at Epoch 1132 is 0.00006117\n",
      "Train Loss at Epoch 1133 is 0.00734133\n",
      "Val Loss at Epoch 1133 is 0.00006113\n",
      "Train Loss at Epoch 1134 is 0.00733572\n",
      "Val Loss at Epoch 1134 is 0.00006109\n",
      "Train Loss at Epoch 1135 is 0.00733012\n",
      "Val Loss at Epoch 1135 is 0.00006105\n",
      "Train Loss at Epoch 1136 is 0.00732452\n",
      "Val Loss at Epoch 1136 is 0.00006101\n",
      "Train Loss at Epoch 1137 is 0.00731893\n",
      "Val Loss at Epoch 1137 is 0.00006097\n",
      "Train Loss at Epoch 1138 is 0.00731334\n",
      "Val Loss at Epoch 1138 is 0.00006093\n",
      "Train Loss at Epoch 1139 is 0.00730776\n",
      "Val Loss at Epoch 1139 is 0.00006089\n",
      "Train Loss at Epoch 1140 is 0.00730218\n",
      "Val Loss at Epoch 1140 is 0.00006085\n",
      "Train Loss at Epoch 1141 is 0.00729661\n",
      "Val Loss at Epoch 1141 is 0.00006081\n",
      "Train Loss at Epoch 1142 is 0.00729104\n",
      "Val Loss at Epoch 1142 is 0.00006077\n",
      "Train Loss at Epoch 1143 is 0.00728548\n",
      "Val Loss at Epoch 1143 is 0.00006073\n",
      "Train Loss at Epoch 1144 is 0.00727992\n",
      "Val Loss at Epoch 1144 is 0.00006069\n",
      "Train Loss at Epoch 1145 is 0.00727437\n",
      "Val Loss at Epoch 1145 is 0.00006065\n",
      "Train Loss at Epoch 1146 is 0.00726882\n",
      "Val Loss at Epoch 1146 is 0.00006061\n",
      "Train Loss at Epoch 1147 is 0.00726327\n",
      "Val Loss at Epoch 1147 is 0.00006057\n",
      "Train Loss at Epoch 1148 is 0.00725774\n",
      "Val Loss at Epoch 1148 is 0.00006053\n",
      "Train Loss at Epoch 1149 is 0.00725220\n",
      "Val Loss at Epoch 1149 is 0.00006049\n",
      "Train Loss at Epoch 1150 is 0.00724667\n",
      "Val Loss at Epoch 1150 is 0.00006045\n",
      "Train Loss at Epoch 1151 is 0.00724115\n",
      "Val Loss at Epoch 1151 is 0.00006041\n",
      "Train Loss at Epoch 1152 is 0.00723563\n",
      "Val Loss at Epoch 1152 is 0.00006037\n",
      "Train Loss at Epoch 1153 is 0.00723011\n",
      "Val Loss at Epoch 1153 is 0.00006034\n",
      "Train Loss at Epoch 1154 is 0.00722460\n",
      "Val Loss at Epoch 1154 is 0.00006030\n",
      "Train Loss at Epoch 1155 is 0.00721910\n",
      "Val Loss at Epoch 1155 is 0.00006026\n",
      "Train Loss at Epoch 1156 is 0.00721360\n",
      "Val Loss at Epoch 1156 is 0.00006022\n",
      "Train Loss at Epoch 1157 is 0.00720810\n",
      "Val Loss at Epoch 1157 is 0.00006018\n",
      "Train Loss at Epoch 1158 is 0.00720261\n",
      "Val Loss at Epoch 1158 is 0.00006014\n",
      "Train Loss at Epoch 1159 is 0.00719712\n",
      "Val Loss at Epoch 1159 is 0.00006010\n",
      "Train Loss at Epoch 1160 is 0.00719164\n",
      "Val Loss at Epoch 1160 is 0.00006006\n",
      "Train Loss at Epoch 1161 is 0.00718617\n",
      "Val Loss at Epoch 1161 is 0.00006003\n",
      "Train Loss at Epoch 1162 is 0.00718069\n",
      "Val Loss at Epoch 1162 is 0.00005999\n",
      "Train Loss at Epoch 1163 is 0.00717523\n",
      "Val Loss at Epoch 1163 is 0.00005995\n",
      "Train Loss at Epoch 1164 is 0.00716977\n",
      "Val Loss at Epoch 1164 is 0.00005991\n",
      "Train Loss at Epoch 1165 is 0.00716431\n",
      "Val Loss at Epoch 1165 is 0.00005987\n",
      "Train Loss at Epoch 1166 is 0.00715886\n",
      "Val Loss at Epoch 1166 is 0.00005983\n",
      "Train Loss at Epoch 1167 is 0.00715341\n",
      "Val Loss at Epoch 1167 is 0.00005980\n",
      "Train Loss at Epoch 1168 is 0.00714797\n",
      "Val Loss at Epoch 1168 is 0.00005976\n",
      "Train Loss at Epoch 1169 is 0.00714253\n",
      "Val Loss at Epoch 1169 is 0.00005972\n",
      "Train Loss at Epoch 1170 is 0.00713710\n",
      "Val Loss at Epoch 1170 is 0.00005968\n",
      "Train Loss at Epoch 1171 is 0.00713167\n",
      "Val Loss at Epoch 1171 is 0.00005964\n",
      "Train Loss at Epoch 1172 is 0.00712625\n",
      "Val Loss at Epoch 1172 is 0.00005961\n",
      "Train Loss at Epoch 1173 is 0.00712083\n",
      "Val Loss at Epoch 1173 is 0.00005957\n",
      "Train Loss at Epoch 1174 is 0.00711541\n",
      "Val Loss at Epoch 1174 is 0.00005953\n",
      "Train Loss at Epoch 1175 is 0.00711001\n",
      "Val Loss at Epoch 1175 is 0.00005949\n",
      "Train Loss at Epoch 1176 is 0.00710460\n",
      "Val Loss at Epoch 1176 is 0.00005945\n",
      "Train Loss at Epoch 1177 is 0.00709920\n",
      "Val Loss at Epoch 1177 is 0.00005942\n",
      "Train Loss at Epoch 1178 is 0.00709381\n",
      "Val Loss at Epoch 1178 is 0.00005938\n",
      "Train Loss at Epoch 1179 is 0.00708842\n",
      "Val Loss at Epoch 1179 is 0.00005934\n",
      "Train Loss at Epoch 1180 is 0.00708304\n",
      "Val Loss at Epoch 1180 is 0.00005930\n",
      "Train Loss at Epoch 1181 is 0.00707766\n",
      "Val Loss at Epoch 1181 is 0.00005927\n",
      "Train Loss at Epoch 1182 is 0.00707228\n",
      "Val Loss at Epoch 1182 is 0.00005923\n",
      "Train Loss at Epoch 1183 is 0.00706691\n",
      "Val Loss at Epoch 1183 is 0.00005919\n",
      "Train Loss at Epoch 1184 is 0.00706155\n",
      "Val Loss at Epoch 1184 is 0.00005915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1185 is 0.00705619\n",
      "Val Loss at Epoch 1185 is 0.00005912\n",
      "Train Loss at Epoch 1186 is 0.00705083\n",
      "Val Loss at Epoch 1186 is 0.00005908\n",
      "Train Loss at Epoch 1187 is 0.00704548\n",
      "Val Loss at Epoch 1187 is 0.00005904\n",
      "Train Loss at Epoch 1188 is 0.00704014\n",
      "Val Loss at Epoch 1188 is 0.00005900\n",
      "Train Loss at Epoch 1189 is 0.00703479\n",
      "Val Loss at Epoch 1189 is 0.00005897\n",
      "Train Loss at Epoch 1190 is 0.00702946\n",
      "Val Loss at Epoch 1190 is 0.00005893\n",
      "Train Loss at Epoch 1191 is 0.00702413\n",
      "Val Loss at Epoch 1191 is 0.00005889\n",
      "Train Loss at Epoch 1192 is 0.00701880\n",
      "Val Loss at Epoch 1192 is 0.00005886\n",
      "Train Loss at Epoch 1193 is 0.00701348\n",
      "Val Loss at Epoch 1193 is 0.00005882\n",
      "Train Loss at Epoch 1194 is 0.00700816\n",
      "Val Loss at Epoch 1194 is 0.00005878\n",
      "Train Loss at Epoch 1195 is 0.00700285\n",
      "Val Loss at Epoch 1195 is 0.00005875\n",
      "Train Loss at Epoch 1196 is 0.00699754\n",
      "Val Loss at Epoch 1196 is 0.00005871\n",
      "Train Loss at Epoch 1197 is 0.00699224\n",
      "Val Loss at Epoch 1197 is 0.00005867\n",
      "Train Loss at Epoch 1198 is 0.00698694\n",
      "Val Loss at Epoch 1198 is 0.00005864\n",
      "Train Loss at Epoch 1199 is 0.00698165\n",
      "Val Loss at Epoch 1199 is 0.00005860\n",
      "Train Loss at Epoch 1200 is 0.00697636\n",
      "Val Loss at Epoch 1200 is 0.00005856\n",
      "Train Loss at Epoch 1201 is 0.00697108\n",
      "Val Loss at Epoch 1201 is 0.00005853\n",
      "Train Loss at Epoch 1202 is 0.00696580\n",
      "Val Loss at Epoch 1202 is 0.00005849\n",
      "Train Loss at Epoch 1203 is 0.00696053\n",
      "Val Loss at Epoch 1203 is 0.00005845\n",
      "Train Loss at Epoch 1204 is 0.00695526\n",
      "Val Loss at Epoch 1204 is 0.00005842\n",
      "Train Loss at Epoch 1205 is 0.00695000\n",
      "Val Loss at Epoch 1205 is 0.00005838\n",
      "Train Loss at Epoch 1206 is 0.00694474\n",
      "Val Loss at Epoch 1206 is 0.00005834\n",
      "Train Loss at Epoch 1207 is 0.00693948\n",
      "Val Loss at Epoch 1207 is 0.00005831\n",
      "Train Loss at Epoch 1208 is 0.00693423\n",
      "Val Loss at Epoch 1208 is 0.00005827\n",
      "Train Loss at Epoch 1209 is 0.00692899\n",
      "Val Loss at Epoch 1209 is 0.00005824\n",
      "Train Loss at Epoch 1210 is 0.00692375\n",
      "Val Loss at Epoch 1210 is 0.00005820\n",
      "Train Loss at Epoch 1211 is 0.00691851\n",
      "Val Loss at Epoch 1211 is 0.00005816\n",
      "Train Loss at Epoch 1212 is 0.00691328\n",
      "Val Loss at Epoch 1212 is 0.00005813\n",
      "Train Loss at Epoch 1213 is 0.00690806\n",
      "Val Loss at Epoch 1213 is 0.00005809\n",
      "Train Loss at Epoch 1214 is 0.00690283\n",
      "Val Loss at Epoch 1214 is 0.00005806\n",
      "Train Loss at Epoch 1215 is 0.00689762\n",
      "Val Loss at Epoch 1215 is 0.00005802\n",
      "Train Loss at Epoch 1216 is 0.00689241\n",
      "Val Loss at Epoch 1216 is 0.00005798\n",
      "Train Loss at Epoch 1217 is 0.00688720\n",
      "Val Loss at Epoch 1217 is 0.00005795\n",
      "Train Loss at Epoch 1218 is 0.00688200\n",
      "Val Loss at Epoch 1218 is 0.00005791\n",
      "Train Loss at Epoch 1219 is 0.00687680\n",
      "Val Loss at Epoch 1219 is 0.00005788\n",
      "Train Loss at Epoch 1220 is 0.00687161\n",
      "Val Loss at Epoch 1220 is 0.00005784\n",
      "Train Loss at Epoch 1221 is 0.00686642\n",
      "Val Loss at Epoch 1221 is 0.00005781\n",
      "Train Loss at Epoch 1222 is 0.00686124\n",
      "Val Loss at Epoch 1222 is 0.00005777\n",
      "Train Loss at Epoch 1223 is 0.00685606\n",
      "Val Loss at Epoch 1223 is 0.00005774\n",
      "Train Loss at Epoch 1224 is 0.00685089\n",
      "Val Loss at Epoch 1224 is 0.00005770\n",
      "Train Loss at Epoch 1225 is 0.00684572\n",
      "Val Loss at Epoch 1225 is 0.00005766\n",
      "Train Loss at Epoch 1226 is 0.00684055\n",
      "Val Loss at Epoch 1226 is 0.00005763\n",
      "Train Loss at Epoch 1227 is 0.00683539\n",
      "Val Loss at Epoch 1227 is 0.00005759\n",
      "Train Loss at Epoch 1228 is 0.00683024\n",
      "Val Loss at Epoch 1228 is 0.00005756\n",
      "Train Loss at Epoch 1229 is 0.00682509\n",
      "Val Loss at Epoch 1229 is 0.00005752\n",
      "Train Loss at Epoch 1230 is 0.00681995\n",
      "Val Loss at Epoch 1230 is 0.00005749\n",
      "Train Loss at Epoch 1231 is 0.00681480\n",
      "Val Loss at Epoch 1231 is 0.00005745\n",
      "Train Loss at Epoch 1232 is 0.00680967\n",
      "Val Loss at Epoch 1232 is 0.00005742\n",
      "Train Loss at Epoch 1233 is 0.00680454\n",
      "Val Loss at Epoch 1233 is 0.00005738\n",
      "Train Loss at Epoch 1234 is 0.00679941\n",
      "Val Loss at Epoch 1234 is 0.00005735\n",
      "Train Loss at Epoch 1235 is 0.00679429\n",
      "Val Loss at Epoch 1235 is 0.00005731\n",
      "Train Loss at Epoch 1236 is 0.00678917\n",
      "Val Loss at Epoch 1236 is 0.00005728\n",
      "Train Loss at Epoch 1237 is 0.00678406\n",
      "Val Loss at Epoch 1237 is 0.00005724\n",
      "Train Loss at Epoch 1238 is 0.00677895\n",
      "Val Loss at Epoch 1238 is 0.00005721\n",
      "Train Loss at Epoch 1239 is 0.00677385\n",
      "Val Loss at Epoch 1239 is 0.00005717\n",
      "Train Loss at Epoch 1240 is 0.00676875\n",
      "Val Loss at Epoch 1240 is 0.00005714\n",
      "Train Loss at Epoch 1241 is 0.00676366\n",
      "Val Loss at Epoch 1241 is 0.00005710\n",
      "Train Loss at Epoch 1242 is 0.00675857\n",
      "Val Loss at Epoch 1242 is 0.00005707\n",
      "Train Loss at Epoch 1243 is 0.00675348\n",
      "Val Loss at Epoch 1243 is 0.00005704\n",
      "Train Loss at Epoch 1244 is 0.00674840\n",
      "Val Loss at Epoch 1244 is 0.00005700\n",
      "Train Loss at Epoch 1245 is 0.00674333\n",
      "Val Loss at Epoch 1245 is 0.00005697\n",
      "Train Loss at Epoch 1246 is 0.00673826\n",
      "Val Loss at Epoch 1246 is 0.00005693\n",
      "Train Loss at Epoch 1247 is 0.00673319\n",
      "Val Loss at Epoch 1247 is 0.00005690\n",
      "Train Loss at Epoch 1248 is 0.00672813\n",
      "Val Loss at Epoch 1248 is 0.00005686\n",
      "Train Loss at Epoch 1249 is 0.00672308\n",
      "Val Loss at Epoch 1249 is 0.00005683\n",
      "Train Loss at Epoch 1250 is 0.00671802\n",
      "Val Loss at Epoch 1250 is 0.00005679\n",
      "Train Loss at Epoch 1251 is 0.00671298\n",
      "Val Loss at Epoch 1251 is 0.00005676\n",
      "Train Loss at Epoch 1252 is 0.00670793\n",
      "Val Loss at Epoch 1252 is 0.00005673\n",
      "Train Loss at Epoch 1253 is 0.00670290\n",
      "Val Loss at Epoch 1253 is 0.00005669\n",
      "Train Loss at Epoch 1254 is 0.00669786\n",
      "Val Loss at Epoch 1254 is 0.00005666\n",
      "Train Loss at Epoch 1255 is 0.00669283\n",
      "Val Loss at Epoch 1255 is 0.00005662\n",
      "Train Loss at Epoch 1256 is 0.00668781\n",
      "Val Loss at Epoch 1256 is 0.00005659\n",
      "Train Loss at Epoch 1257 is 0.00668279\n",
      "Val Loss at Epoch 1257 is 0.00005656\n",
      "Train Loss at Epoch 1258 is 0.00667777\n",
      "Val Loss at Epoch 1258 is 0.00005652\n",
      "Train Loss at Epoch 1259 is 0.00667276\n",
      "Val Loss at Epoch 1259 is 0.00005649\n",
      "Train Loss at Epoch 1260 is 0.00666776\n",
      "Val Loss at Epoch 1260 is 0.00005645\n",
      "Train Loss at Epoch 1261 is 0.00666276\n",
      "Val Loss at Epoch 1261 is 0.00005642\n",
      "Train Loss at Epoch 1262 is 0.00665776\n",
      "Val Loss at Epoch 1262 is 0.00005639\n",
      "Train Loss at Epoch 1263 is 0.00665277\n",
      "Val Loss at Epoch 1263 is 0.00005635\n",
      "Train Loss at Epoch 1264 is 0.00664778\n",
      "Val Loss at Epoch 1264 is 0.00005632\n",
      "Train Loss at Epoch 1265 is 0.00664280\n",
      "Val Loss at Epoch 1265 is 0.00005629\n",
      "Train Loss at Epoch 1266 is 0.00663782\n",
      "Val Loss at Epoch 1266 is 0.00005625\n",
      "Train Loss at Epoch 1267 is 0.00663284\n",
      "Val Loss at Epoch 1267 is 0.00005622\n",
      "Train Loss at Epoch 1268 is 0.00662788\n",
      "Val Loss at Epoch 1268 is 0.00005619\n",
      "Train Loss at Epoch 1269 is 0.00662291\n",
      "Val Loss at Epoch 1269 is 0.00005615\n",
      "Train Loss at Epoch 1270 is 0.00661795\n",
      "Val Loss at Epoch 1270 is 0.00005612\n",
      "Train Loss at Epoch 1271 is 0.00661299\n",
      "Val Loss at Epoch 1271 is 0.00005608\n",
      "Train Loss at Epoch 1272 is 0.00660804\n",
      "Val Loss at Epoch 1272 is 0.00005605\n",
      "Train Loss at Epoch 1273 is 0.00660310\n",
      "Val Loss at Epoch 1273 is 0.00005602\n",
      "Train Loss at Epoch 1274 is 0.00659815\n",
      "Val Loss at Epoch 1274 is 0.00005598\n",
      "Train Loss at Epoch 1275 is 0.00659322\n",
      "Val Loss at Epoch 1275 is 0.00005595\n",
      "Train Loss at Epoch 1276 is 0.00658828\n",
      "Val Loss at Epoch 1276 is 0.00005592\n",
      "Train Loss at Epoch 1277 is 0.00658335\n",
      "Val Loss at Epoch 1277 is 0.00005589\n",
      "Train Loss at Epoch 1278 is 0.00657843\n",
      "Val Loss at Epoch 1278 is 0.00005585\n",
      "Train Loss at Epoch 1279 is 0.00657351\n",
      "Val Loss at Epoch 1279 is 0.00005582\n",
      "Train Loss at Epoch 1280 is 0.00656859\n",
      "Val Loss at Epoch 1280 is 0.00005579\n",
      "Train Loss at Epoch 1281 is 0.00656368\n",
      "Val Loss at Epoch 1281 is 0.00005575\n",
      "Train Loss at Epoch 1282 is 0.00655878\n",
      "Val Loss at Epoch 1282 is 0.00005572\n",
      "Train Loss at Epoch 1283 is 0.00655387\n",
      "Val Loss at Epoch 1283 is 0.00005569\n",
      "Train Loss at Epoch 1284 is 0.00654898\n",
      "Val Loss at Epoch 1284 is 0.00005565\n",
      "Train Loss at Epoch 1285 is 0.00654408\n",
      "Val Loss at Epoch 1285 is 0.00005562\n",
      "Train Loss at Epoch 1286 is 0.00653920\n",
      "Val Loss at Epoch 1286 is 0.00005559\n",
      "Train Loss at Epoch 1287 is 0.00653431\n",
      "Val Loss at Epoch 1287 is 0.00005556\n",
      "Train Loss at Epoch 1288 is 0.00652943\n",
      "Val Loss at Epoch 1288 is 0.00005552\n",
      "Train Loss at Epoch 1289 is 0.00652456\n",
      "Val Loss at Epoch 1289 is 0.00005549\n",
      "Train Loss at Epoch 1290 is 0.00651969\n",
      "Val Loss at Epoch 1290 is 0.00005546\n",
      "Train Loss at Epoch 1291 is 0.00651482\n",
      "Val Loss at Epoch 1291 is 0.00005543\n",
      "Train Loss at Epoch 1292 is 0.00650996\n",
      "Val Loss at Epoch 1292 is 0.00005539\n",
      "Train Loss at Epoch 1293 is 0.00650510\n",
      "Val Loss at Epoch 1293 is 0.00005536\n",
      "Train Loss at Epoch 1294 is 0.00650025\n",
      "Val Loss at Epoch 1294 is 0.00005533\n",
      "Train Loss at Epoch 1295 is 0.00649540\n",
      "Val Loss at Epoch 1295 is 0.00005530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1296 is 0.00649055\n",
      "Val Loss at Epoch 1296 is 0.00005526\n",
      "Train Loss at Epoch 1297 is 0.00648571\n",
      "Val Loss at Epoch 1297 is 0.00005523\n",
      "Train Loss at Epoch 1298 is 0.00648088\n",
      "Val Loss at Epoch 1298 is 0.00005520\n",
      "Train Loss at Epoch 1299 is 0.00647605\n",
      "Val Loss at Epoch 1299 is 0.00005517\n",
      "Train Loss at Epoch 1300 is 0.00647122\n",
      "Val Loss at Epoch 1300 is 0.00005513\n",
      "Train Loss at Epoch 1301 is 0.00646640\n",
      "Val Loss at Epoch 1301 is 0.00005510\n",
      "Train Loss at Epoch 1302 is 0.00646158\n",
      "Val Loss at Epoch 1302 is 0.00005507\n",
      "Train Loss at Epoch 1303 is 0.00645676\n",
      "Val Loss at Epoch 1303 is 0.00005504\n",
      "Train Loss at Epoch 1304 is 0.00645195\n",
      "Val Loss at Epoch 1304 is 0.00005500\n",
      "Train Loss at Epoch 1305 is 0.00644715\n",
      "Val Loss at Epoch 1305 is 0.00005497\n",
      "Train Loss at Epoch 1306 is 0.00644235\n",
      "Val Loss at Epoch 1306 is 0.00005494\n",
      "Train Loss at Epoch 1307 is 0.00643755\n",
      "Val Loss at Epoch 1307 is 0.00005491\n",
      "Train Loss at Epoch 1308 is 0.00643276\n",
      "Val Loss at Epoch 1308 is 0.00005488\n",
      "Train Loss at Epoch 1309 is 0.00642797\n",
      "Val Loss at Epoch 1309 is 0.00005484\n",
      "Train Loss at Epoch 1310 is 0.00642319\n",
      "Val Loss at Epoch 1310 is 0.00005481\n",
      "Train Loss at Epoch 1311 is 0.00641841\n",
      "Val Loss at Epoch 1311 is 0.00005478\n",
      "Train Loss at Epoch 1312 is 0.00641363\n",
      "Val Loss at Epoch 1312 is 0.00005475\n",
      "Train Loss at Epoch 1313 is 0.00640886\n",
      "Val Loss at Epoch 1313 is 0.00005472\n",
      "Train Loss at Epoch 1314 is 0.00640410\n",
      "Val Loss at Epoch 1314 is 0.00005469\n",
      "Train Loss at Epoch 1315 is 0.00639934\n",
      "Val Loss at Epoch 1315 is 0.00005465\n",
      "Train Loss at Epoch 1316 is 0.00639458\n",
      "Val Loss at Epoch 1316 is 0.00005462\n",
      "Train Loss at Epoch 1317 is 0.00638982\n",
      "Val Loss at Epoch 1317 is 0.00005459\n",
      "Train Loss at Epoch 1318 is 0.00638508\n",
      "Val Loss at Epoch 1318 is 0.00005456\n",
      "Train Loss at Epoch 1319 is 0.00638033\n",
      "Val Loss at Epoch 1319 is 0.00005453\n",
      "Train Loss at Epoch 1320 is 0.00637559\n",
      "Val Loss at Epoch 1320 is 0.00005450\n",
      "Train Loss at Epoch 1321 is 0.00637085\n",
      "Val Loss at Epoch 1321 is 0.00005446\n",
      "Train Loss at Epoch 1322 is 0.00636612\n",
      "Val Loss at Epoch 1322 is 0.00005443\n",
      "Train Loss at Epoch 1323 is 0.00636139\n",
      "Val Loss at Epoch 1323 is 0.00005440\n",
      "Train Loss at Epoch 1324 is 0.00635667\n",
      "Val Loss at Epoch 1324 is 0.00005437\n",
      "Train Loss at Epoch 1325 is 0.00635195\n",
      "Val Loss at Epoch 1325 is 0.00005434\n",
      "Train Loss at Epoch 1326 is 0.00634723\n",
      "Val Loss at Epoch 1326 is 0.00005431\n",
      "Train Loss at Epoch 1327 is 0.00634252\n",
      "Val Loss at Epoch 1327 is 0.00005428\n",
      "Train Loss at Epoch 1328 is 0.00633782\n",
      "Val Loss at Epoch 1328 is 0.00005425\n",
      "Train Loss at Epoch 1329 is 0.00633311\n",
      "Val Loss at Epoch 1329 is 0.00005421\n",
      "Train Loss at Epoch 1330 is 0.00632842\n",
      "Val Loss at Epoch 1330 is 0.00005418\n",
      "Train Loss at Epoch 1331 is 0.00632372\n",
      "Val Loss at Epoch 1331 is 0.00005415\n",
      "Train Loss at Epoch 1332 is 0.00631903\n",
      "Val Loss at Epoch 1332 is 0.00005412\n",
      "Train Loss at Epoch 1333 is 0.00631435\n",
      "Val Loss at Epoch 1333 is 0.00005409\n",
      "Train Loss at Epoch 1334 is 0.00630966\n",
      "Val Loss at Epoch 1334 is 0.00005406\n",
      "Train Loss at Epoch 1335 is 0.00630499\n",
      "Val Loss at Epoch 1335 is 0.00005403\n",
      "Train Loss at Epoch 1336 is 0.00630031\n",
      "Val Loss at Epoch 1336 is 0.00005400\n",
      "Train Loss at Epoch 1337 is 0.00629565\n",
      "Val Loss at Epoch 1337 is 0.00005397\n",
      "Train Loss at Epoch 1338 is 0.00629098\n",
      "Val Loss at Epoch 1338 is 0.00005394\n",
      "Train Loss at Epoch 1339 is 0.00628632\n",
      "Val Loss at Epoch 1339 is 0.00005390\n",
      "Train Loss at Epoch 1340 is 0.00628166\n",
      "Val Loss at Epoch 1340 is 0.00005387\n",
      "Train Loss at Epoch 1341 is 0.00627701\n",
      "Val Loss at Epoch 1341 is 0.00005384\n",
      "Train Loss at Epoch 1342 is 0.00627236\n",
      "Val Loss at Epoch 1342 is 0.00005381\n",
      "Train Loss at Epoch 1343 is 0.00626772\n",
      "Val Loss at Epoch 1343 is 0.00005378\n",
      "Train Loss at Epoch 1344 is 0.00626308\n",
      "Val Loss at Epoch 1344 is 0.00005375\n",
      "Train Loss at Epoch 1345 is 0.00625844\n",
      "Val Loss at Epoch 1345 is 0.00005372\n",
      "Train Loss at Epoch 1346 is 0.00625381\n",
      "Val Loss at Epoch 1346 is 0.00005369\n",
      "Train Loss at Epoch 1347 is 0.00624918\n",
      "Val Loss at Epoch 1347 is 0.00005366\n",
      "Train Loss at Epoch 1348 is 0.00624456\n",
      "Val Loss at Epoch 1348 is 0.00005363\n",
      "Train Loss at Epoch 1349 is 0.00623994\n",
      "Val Loss at Epoch 1349 is 0.00005360\n",
      "Train Loss at Epoch 1350 is 0.00623532\n",
      "Val Loss at Epoch 1350 is 0.00005357\n",
      "Train Loss at Epoch 1351 is 0.00623071\n",
      "Val Loss at Epoch 1351 is 0.00005354\n",
      "Train Loss at Epoch 1352 is 0.00622611\n",
      "Val Loss at Epoch 1352 is 0.00005351\n",
      "Train Loss at Epoch 1353 is 0.00622150\n",
      "Val Loss at Epoch 1353 is 0.00005348\n",
      "Train Loss at Epoch 1354 is 0.00621690\n",
      "Val Loss at Epoch 1354 is 0.00005345\n",
      "Train Loss at Epoch 1355 is 0.00621231\n",
      "Val Loss at Epoch 1355 is 0.00005342\n",
      "Train Loss at Epoch 1356 is 0.00620772\n",
      "Val Loss at Epoch 1356 is 0.00005339\n",
      "Train Loss at Epoch 1357 is 0.00620313\n",
      "Val Loss at Epoch 1357 is 0.00005336\n",
      "Train Loss at Epoch 1358 is 0.00619855\n",
      "Val Loss at Epoch 1358 is 0.00005332\n",
      "Train Loss at Epoch 1359 is 0.00619397\n",
      "Val Loss at Epoch 1359 is 0.00005329\n",
      "Train Loss at Epoch 1360 is 0.00618939\n",
      "Val Loss at Epoch 1360 is 0.00005326\n",
      "Train Loss at Epoch 1361 is 0.00618482\n",
      "Val Loss at Epoch 1361 is 0.00005323\n",
      "Train Loss at Epoch 1362 is 0.00618026\n",
      "Val Loss at Epoch 1362 is 0.00005320\n",
      "Train Loss at Epoch 1363 is 0.00617569\n",
      "Val Loss at Epoch 1363 is 0.00005317\n",
      "Train Loss at Epoch 1364 is 0.00617114\n",
      "Val Loss at Epoch 1364 is 0.00005314\n",
      "Train Loss at Epoch 1365 is 0.00616658\n",
      "Val Loss at Epoch 1365 is 0.00005311\n",
      "Train Loss at Epoch 1366 is 0.00616203\n",
      "Val Loss at Epoch 1366 is 0.00005308\n",
      "Train Loss at Epoch 1367 is 0.00615748\n",
      "Val Loss at Epoch 1367 is 0.00005305\n",
      "Train Loss at Epoch 1368 is 0.00615294\n",
      "Val Loss at Epoch 1368 is 0.00005302\n",
      "Train Loss at Epoch 1369 is 0.00614840\n",
      "Val Loss at Epoch 1369 is 0.00005300\n",
      "Train Loss at Epoch 1370 is 0.00614387\n",
      "Val Loss at Epoch 1370 is 0.00005297\n",
      "Train Loss at Epoch 1371 is 0.00613934\n",
      "Val Loss at Epoch 1371 is 0.00005294\n",
      "Train Loss at Epoch 1372 is 0.00613481\n",
      "Val Loss at Epoch 1372 is 0.00005291\n",
      "Train Loss at Epoch 1373 is 0.00613029\n",
      "Val Loss at Epoch 1373 is 0.00005288\n",
      "Train Loss at Epoch 1374 is 0.00612577\n",
      "Val Loss at Epoch 1374 is 0.00005285\n",
      "Train Loss at Epoch 1375 is 0.00612125\n",
      "Val Loss at Epoch 1375 is 0.00005282\n",
      "Train Loss at Epoch 1376 is 0.00611674\n",
      "Val Loss at Epoch 1376 is 0.00005279\n",
      "Train Loss at Epoch 1377 is 0.00611224\n",
      "Val Loss at Epoch 1377 is 0.00005276\n",
      "Train Loss at Epoch 1378 is 0.00610773\n",
      "Val Loss at Epoch 1378 is 0.00005273\n",
      "Train Loss at Epoch 1379 is 0.00610323\n",
      "Val Loss at Epoch 1379 is 0.00005270\n",
      "Train Loss at Epoch 1380 is 0.00609874\n",
      "Val Loss at Epoch 1380 is 0.00005267\n",
      "Train Loss at Epoch 1381 is 0.00609425\n",
      "Val Loss at Epoch 1381 is 0.00005264\n",
      "Train Loss at Epoch 1382 is 0.00608976\n",
      "Val Loss at Epoch 1382 is 0.00005261\n",
      "Train Loss at Epoch 1383 is 0.00608528\n",
      "Val Loss at Epoch 1383 is 0.00005258\n",
      "Train Loss at Epoch 1384 is 0.00608080\n",
      "Val Loss at Epoch 1384 is 0.00005255\n",
      "Train Loss at Epoch 1385 is 0.00607632\n",
      "Val Loss at Epoch 1385 is 0.00005252\n",
      "Train Loss at Epoch 1386 is 0.00607185\n",
      "Val Loss at Epoch 1386 is 0.00005249\n",
      "Train Loss at Epoch 1387 is 0.00606738\n",
      "Val Loss at Epoch 1387 is 0.00005246\n",
      "Train Loss at Epoch 1388 is 0.00606292\n",
      "Val Loss at Epoch 1388 is 0.00005243\n",
      "Train Loss at Epoch 1389 is 0.00605846\n",
      "Val Loss at Epoch 1389 is 0.00005241\n",
      "Train Loss at Epoch 1390 is 0.00605400\n",
      "Val Loss at Epoch 1390 is 0.00005238\n",
      "Train Loss at Epoch 1391 is 0.00604955\n",
      "Val Loss at Epoch 1391 is 0.00005235\n",
      "Train Loss at Epoch 1392 is 0.00604510\n",
      "Val Loss at Epoch 1392 is 0.00005232\n",
      "Train Loss at Epoch 1393 is 0.00604066\n",
      "Val Loss at Epoch 1393 is 0.00005229\n",
      "Train Loss at Epoch 1394 is 0.00603621\n",
      "Val Loss at Epoch 1394 is 0.00005226\n",
      "Train Loss at Epoch 1395 is 0.00603178\n",
      "Val Loss at Epoch 1395 is 0.00005223\n",
      "Train Loss at Epoch 1396 is 0.00602734\n",
      "Val Loss at Epoch 1396 is 0.00005220\n",
      "Train Loss at Epoch 1397 is 0.00602292\n",
      "Val Loss at Epoch 1397 is 0.00005217\n",
      "Train Loss at Epoch 1398 is 0.00601849\n",
      "Val Loss at Epoch 1398 is 0.00005214\n",
      "Train Loss at Epoch 1399 is 0.00601407\n",
      "Val Loss at Epoch 1399 is 0.00005212\n",
      "Train Loss at Epoch 1400 is 0.00600965\n",
      "Val Loss at Epoch 1400 is 0.00005209\n",
      "Train Loss at Epoch 1401 is 0.00600524\n",
      "Val Loss at Epoch 1401 is 0.00005206\n",
      "Train Loss at Epoch 1402 is 0.00600083\n",
      "Val Loss at Epoch 1402 is 0.00005203\n",
      "Train Loss at Epoch 1403 is 0.00599642\n",
      "Val Loss at Epoch 1403 is 0.00005200\n",
      "Train Loss at Epoch 1404 is 0.00599202\n",
      "Val Loss at Epoch 1404 is 0.00005197\n",
      "Train Loss at Epoch 1405 is 0.00598762\n",
      "Val Loss at Epoch 1405 is 0.00005194\n",
      "Train Loss at Epoch 1406 is 0.00598322\n",
      "Val Loss at Epoch 1406 is 0.00005191\n",
      "Train Loss at Epoch 1407 is 0.00597883\n",
      "Val Loss at Epoch 1407 is 0.00005189\n",
      "Train Loss at Epoch 1408 is 0.00597444\n",
      "Val Loss at Epoch 1408 is 0.00005186\n",
      "Train Loss at Epoch 1409 is 0.00597006\n",
      "Val Loss at Epoch 1409 is 0.00005183\n",
      "Train Loss at Epoch 1410 is 0.00596568\n",
      "Val Loss at Epoch 1410 is 0.00005180\n",
      "Train Loss at Epoch 1411 is 0.00596131\n",
      "Val Loss at Epoch 1411 is 0.00005177\n",
      "Train Loss at Epoch 1412 is 0.00595693\n",
      "Val Loss at Epoch 1412 is 0.00005174\n",
      "Train Loss at Epoch 1413 is 0.00595256\n",
      "Val Loss at Epoch 1413 is 0.00005172\n",
      "Train Loss at Epoch 1414 is 0.00594820\n",
      "Val Loss at Epoch 1414 is 0.00005169\n",
      "Train Loss at Epoch 1415 is 0.00594384\n",
      "Val Loss at Epoch 1415 is 0.00005166\n",
      "Train Loss at Epoch 1416 is 0.00593948\n",
      "Val Loss at Epoch 1416 is 0.00005163\n",
      "Train Loss at Epoch 1417 is 0.00593513\n",
      "Val Loss at Epoch 1417 is 0.00005160\n",
      "Train Loss at Epoch 1418 is 0.00593078\n",
      "Val Loss at Epoch 1418 is 0.00005157\n",
      "Train Loss at Epoch 1419 is 0.00592643\n",
      "Val Loss at Epoch 1419 is 0.00005155\n",
      "Train Loss at Epoch 1420 is 0.00592209\n",
      "Val Loss at Epoch 1420 is 0.00005152\n",
      "Train Loss at Epoch 1421 is 0.00591775\n",
      "Val Loss at Epoch 1421 is 0.00005149\n",
      "Train Loss at Epoch 1422 is 0.00591341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss at Epoch 1422 is 0.00005146\n",
      "Train Loss at Epoch 1423 is 0.00590908\n",
      "Val Loss at Epoch 1423 is 0.00005143\n",
      "Train Loss at Epoch 1424 is 0.00590475\n",
      "Val Loss at Epoch 1424 is 0.00005140\n",
      "Train Loss at Epoch 1425 is 0.00590043\n",
      "Val Loss at Epoch 1425 is 0.00005138\n",
      "Train Loss at Epoch 1426 is 0.00589611\n",
      "Val Loss at Epoch 1426 is 0.00005135\n",
      "Train Loss at Epoch 1427 is 0.00589179\n",
      "Val Loss at Epoch 1427 is 0.00005132\n",
      "Train Loss at Epoch 1428 is 0.00588748\n",
      "Val Loss at Epoch 1428 is 0.00005129\n",
      "Train Loss at Epoch 1429 is 0.00588317\n",
      "Val Loss at Epoch 1429 is 0.00005126\n",
      "Train Loss at Epoch 1430 is 0.00587886\n",
      "Val Loss at Epoch 1430 is 0.00005124\n",
      "Train Loss at Epoch 1431 is 0.00587456\n",
      "Val Loss at Epoch 1431 is 0.00005121\n",
      "Train Loss at Epoch 1432 is 0.00587026\n",
      "Val Loss at Epoch 1432 is 0.00005118\n",
      "Train Loss at Epoch 1433 is 0.00586597\n",
      "Val Loss at Epoch 1433 is 0.00005115\n",
      "Train Loss at Epoch 1434 is 0.00586168\n",
      "Val Loss at Epoch 1434 is 0.00005113\n",
      "Train Loss at Epoch 1435 is 0.00585739\n",
      "Val Loss at Epoch 1435 is 0.00005110\n",
      "Train Loss at Epoch 1436 is 0.00585311\n",
      "Val Loss at Epoch 1436 is 0.00005107\n",
      "Train Loss at Epoch 1437 is 0.00584883\n",
      "Val Loss at Epoch 1437 is 0.00005104\n",
      "Train Loss at Epoch 1438 is 0.00584455\n",
      "Val Loss at Epoch 1438 is 0.00005101\n",
      "Train Loss at Epoch 1439 is 0.00584028\n",
      "Val Loss at Epoch 1439 is 0.00005099\n",
      "Train Loss at Epoch 1440 is 0.00583601\n",
      "Val Loss at Epoch 1440 is 0.00005096\n",
      "Train Loss at Epoch 1441 is 0.00583174\n",
      "Val Loss at Epoch 1441 is 0.00005093\n",
      "Train Loss at Epoch 1442 is 0.00582748\n",
      "Val Loss at Epoch 1442 is 0.00005090\n",
      "Train Loss at Epoch 1443 is 0.00582322\n",
      "Val Loss at Epoch 1443 is 0.00005088\n",
      "Train Loss at Epoch 1444 is 0.00581896\n",
      "Val Loss at Epoch 1444 is 0.00005085\n",
      "Train Loss at Epoch 1445 is 0.00581471\n",
      "Val Loss at Epoch 1445 is 0.00005082\n",
      "Train Loss at Epoch 1446 is 0.00581047\n",
      "Val Loss at Epoch 1446 is 0.00005079\n",
      "Train Loss at Epoch 1447 is 0.00580622\n",
      "Val Loss at Epoch 1447 is 0.00005077\n",
      "Train Loss at Epoch 1448 is 0.00580198\n",
      "Val Loss at Epoch 1448 is 0.00005074\n",
      "Train Loss at Epoch 1449 is 0.00579774\n",
      "Val Loss at Epoch 1449 is 0.00005071\n",
      "Train Loss at Epoch 1450 is 0.00579351\n",
      "Val Loss at Epoch 1450 is 0.00005068\n",
      "Train Loss at Epoch 1451 is 0.00578928\n",
      "Val Loss at Epoch 1451 is 0.00005066\n",
      "Train Loss at Epoch 1452 is 0.00578505\n",
      "Val Loss at Epoch 1452 is 0.00005063\n",
      "Train Loss at Epoch 1453 is 0.00578083\n",
      "Val Loss at Epoch 1453 is 0.00005060\n",
      "Train Loss at Epoch 1454 is 0.00577661\n",
      "Val Loss at Epoch 1454 is 0.00005058\n",
      "Train Loss at Epoch 1455 is 0.00577239\n",
      "Val Loss at Epoch 1455 is 0.00005055\n",
      "Train Loss at Epoch 1456 is 0.00576818\n",
      "Val Loss at Epoch 1456 is 0.00005052\n",
      "Train Loss at Epoch 1457 is 0.00576397\n",
      "Val Loss at Epoch 1457 is 0.00005049\n",
      "Train Loss at Epoch 1458 is 0.00575977\n",
      "Val Loss at Epoch 1458 is 0.00005047\n",
      "Train Loss at Epoch 1459 is 0.00575556\n",
      "Val Loss at Epoch 1459 is 0.00005044\n",
      "Train Loss at Epoch 1460 is 0.00575137\n",
      "Val Loss at Epoch 1460 is 0.00005041\n",
      "Train Loss at Epoch 1461 is 0.00574717\n",
      "Val Loss at Epoch 1461 is 0.00005039\n",
      "Train Loss at Epoch 1462 is 0.00574298\n",
      "Val Loss at Epoch 1462 is 0.00005036\n",
      "Train Loss at Epoch 1463 is 0.00573879\n",
      "Val Loss at Epoch 1463 is 0.00005033\n",
      "Train Loss at Epoch 1464 is 0.00573461\n",
      "Val Loss at Epoch 1464 is 0.00005031\n",
      "Train Loss at Epoch 1465 is 0.00573043\n",
      "Val Loss at Epoch 1465 is 0.00005028\n",
      "Train Loss at Epoch 1466 is 0.00572625\n",
      "Val Loss at Epoch 1466 is 0.00005025\n",
      "Train Loss at Epoch 1467 is 0.00572207\n",
      "Val Loss at Epoch 1467 is 0.00005022\n",
      "Train Loss at Epoch 1468 is 0.00571790\n",
      "Val Loss at Epoch 1468 is 0.00005020\n",
      "Train Loss at Epoch 1469 is 0.00571374\n",
      "Val Loss at Epoch 1469 is 0.00005017\n",
      "Train Loss at Epoch 1470 is 0.00570957\n",
      "Val Loss at Epoch 1470 is 0.00005014\n",
      "Train Loss at Epoch 1471 is 0.00570541\n",
      "Val Loss at Epoch 1471 is 0.00005012\n",
      "Train Loss at Epoch 1472 is 0.00570126\n",
      "Val Loss at Epoch 1472 is 0.00005009\n",
      "Train Loss at Epoch 1473 is 0.00569710\n",
      "Val Loss at Epoch 1473 is 0.00005006\n",
      "Train Loss at Epoch 1474 is 0.00569295\n",
      "Val Loss at Epoch 1474 is 0.00005004\n",
      "Train Loss at Epoch 1475 is 0.00568881\n",
      "Val Loss at Epoch 1475 is 0.00005001\n",
      "Train Loss at Epoch 1476 is 0.00568466\n",
      "Val Loss at Epoch 1476 is 0.00004998\n",
      "Train Loss at Epoch 1477 is 0.00568052\n",
      "Val Loss at Epoch 1477 is 0.00004996\n",
      "Train Loss at Epoch 1478 is 0.00567639\n",
      "Val Loss at Epoch 1478 is 0.00004993\n",
      "Train Loss at Epoch 1479 is 0.00567226\n",
      "Val Loss at Epoch 1479 is 0.00004990\n",
      "Train Loss at Epoch 1480 is 0.00566813\n",
      "Val Loss at Epoch 1480 is 0.00004988\n",
      "Train Loss at Epoch 1481 is 0.00566400\n",
      "Val Loss at Epoch 1481 is 0.00004985\n",
      "Train Loss at Epoch 1482 is 0.00565988\n",
      "Val Loss at Epoch 1482 is 0.00004983\n",
      "Train Loss at Epoch 1483 is 0.00565576\n",
      "Val Loss at Epoch 1483 is 0.00004980\n",
      "Train Loss at Epoch 1484 is 0.00565164\n",
      "Val Loss at Epoch 1484 is 0.00004977\n",
      "Train Loss at Epoch 1485 is 0.00564753\n",
      "Val Loss at Epoch 1485 is 0.00004975\n",
      "Train Loss at Epoch 1486 is 0.00564342\n",
      "Val Loss at Epoch 1486 is 0.00004972\n",
      "Train Loss at Epoch 1487 is 0.00563932\n",
      "Val Loss at Epoch 1487 is 0.00004969\n",
      "Train Loss at Epoch 1488 is 0.00563521\n",
      "Val Loss at Epoch 1488 is 0.00004967\n",
      "Train Loss at Epoch 1489 is 0.00563111\n",
      "Val Loss at Epoch 1489 is 0.00004964\n",
      "Train Loss at Epoch 1490 is 0.00562702\n",
      "Val Loss at Epoch 1490 is 0.00004962\n",
      "Train Loss at Epoch 1491 is 0.00562293\n",
      "Val Loss at Epoch 1491 is 0.00004959\n",
      "Train Loss at Epoch 1492 is 0.00561884\n",
      "Val Loss at Epoch 1492 is 0.00004956\n",
      "Train Loss at Epoch 1493 is 0.00561475\n",
      "Val Loss at Epoch 1493 is 0.00004954\n",
      "Train Loss at Epoch 1494 is 0.00561067\n",
      "Val Loss at Epoch 1494 is 0.00004951\n",
      "Train Loss at Epoch 1495 is 0.00560659\n",
      "Val Loss at Epoch 1495 is 0.00004948\n",
      "Train Loss at Epoch 1496 is 0.00560252\n",
      "Val Loss at Epoch 1496 is 0.00004946\n",
      "Train Loss at Epoch 1497 is 0.00559844\n",
      "Val Loss at Epoch 1497 is 0.00004943\n",
      "Train Loss at Epoch 1498 is 0.00559437\n",
      "Val Loss at Epoch 1498 is 0.00004941\n",
      "Train Loss at Epoch 1499 is 0.00559031\n",
      "Val Loss at Epoch 1499 is 0.00004938\n",
      "Train Loss at Epoch 1500 is 0.00558625\n",
      "Val Loss at Epoch 1500 is 0.00004935\n",
      "Train Loss at Epoch 1501 is 0.00558219\n",
      "Val Loss at Epoch 1501 is 0.00004933\n",
      "Train Loss at Epoch 1502 is 0.00557813\n",
      "Val Loss at Epoch 1502 is 0.00004930\n",
      "Train Loss at Epoch 1503 is 0.00557408\n",
      "Val Loss at Epoch 1503 is 0.00004928\n",
      "Train Loss at Epoch 1504 is 0.00557003\n",
      "Val Loss at Epoch 1504 is 0.00004925\n",
      "Train Loss at Epoch 1505 is 0.00556599\n",
      "Val Loss at Epoch 1505 is 0.00004923\n",
      "Train Loss at Epoch 1506 is 0.00556194\n",
      "Val Loss at Epoch 1506 is 0.00004920\n",
      "Train Loss at Epoch 1507 is 0.00555790\n",
      "Val Loss at Epoch 1507 is 0.00004917\n",
      "Train Loss at Epoch 1508 is 0.00555387\n",
      "Val Loss at Epoch 1508 is 0.00004915\n",
      "Train Loss at Epoch 1509 is 0.00554984\n",
      "Val Loss at Epoch 1509 is 0.00004912\n",
      "Train Loss at Epoch 1510 is 0.00554581\n",
      "Val Loss at Epoch 1510 is 0.00004910\n",
      "Train Loss at Epoch 1511 is 0.00554178\n",
      "Val Loss at Epoch 1511 is 0.00004907\n",
      "Train Loss at Epoch 1512 is 0.00553776\n",
      "Val Loss at Epoch 1512 is 0.00004905\n",
      "Train Loss at Epoch 1513 is 0.00553374\n",
      "Val Loss at Epoch 1513 is 0.00004902\n",
      "Train Loss at Epoch 1514 is 0.00552972\n",
      "Val Loss at Epoch 1514 is 0.00004899\n",
      "Train Loss at Epoch 1515 is 0.00552571\n",
      "Val Loss at Epoch 1515 is 0.00004897\n",
      "Train Loss at Epoch 1516 is 0.00552170\n",
      "Val Loss at Epoch 1516 is 0.00004894\n",
      "Train Loss at Epoch 1517 is 0.00551769\n",
      "Val Loss at Epoch 1517 is 0.00004892\n",
      "Train Loss at Epoch 1518 is 0.00551369\n",
      "Val Loss at Epoch 1518 is 0.00004889\n",
      "Train Loss at Epoch 1519 is 0.00550969\n",
      "Val Loss at Epoch 1519 is 0.00004887\n",
      "Train Loss at Epoch 1520 is 0.00550569\n",
      "Val Loss at Epoch 1520 is 0.00004884\n",
      "Train Loss at Epoch 1521 is 0.00550170\n",
      "Val Loss at Epoch 1521 is 0.00004882\n",
      "Train Loss at Epoch 1522 is 0.00549771\n",
      "Val Loss at Epoch 1522 is 0.00004879\n",
      "Train Loss at Epoch 1523 is 0.00549372\n",
      "Val Loss at Epoch 1523 is 0.00004876\n",
      "Train Loss at Epoch 1524 is 0.00548974\n",
      "Val Loss at Epoch 1524 is 0.00004874\n",
      "Train Loss at Epoch 1525 is 0.00548576\n",
      "Val Loss at Epoch 1525 is 0.00004871\n",
      "Train Loss at Epoch 1526 is 0.00548178\n",
      "Val Loss at Epoch 1526 is 0.00004869\n",
      "Train Loss at Epoch 1527 is 0.00547780\n",
      "Val Loss at Epoch 1527 is 0.00004866\n",
      "Train Loss at Epoch 1528 is 0.00547383\n",
      "Val Loss at Epoch 1528 is 0.00004864\n",
      "Train Loss at Epoch 1529 is 0.00546986\n",
      "Val Loss at Epoch 1529 is 0.00004861\n",
      "Train Loss at Epoch 1530 is 0.00546590\n",
      "Val Loss at Epoch 1530 is 0.00004859\n",
      "Train Loss at Epoch 1531 is 0.00546194\n",
      "Val Loss at Epoch 1531 is 0.00004856\n",
      "Train Loss at Epoch 1532 is 0.00545798\n",
      "Val Loss at Epoch 1532 is 0.00004854\n",
      "Train Loss at Epoch 1533 is 0.00545402\n",
      "Val Loss at Epoch 1533 is 0.00004851\n",
      "Train Loss at Epoch 1534 is 0.00545007\n",
      "Val Loss at Epoch 1534 is 0.00004849\n",
      "Train Loss at Epoch 1535 is 0.00544612\n",
      "Val Loss at Epoch 1535 is 0.00004846\n",
      "Train Loss at Epoch 1536 is 0.00544218\n",
      "Val Loss at Epoch 1536 is 0.00004844\n",
      "Train Loss at Epoch 1537 is 0.00543823\n",
      "Val Loss at Epoch 1537 is 0.00004841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1538 is 0.00543429\n",
      "Val Loss at Epoch 1538 is 0.00004839\n",
      "Train Loss at Epoch 1539 is 0.00543036\n",
      "Val Loss at Epoch 1539 is 0.00004836\n",
      "Train Loss at Epoch 1540 is 0.00542642\n",
      "Val Loss at Epoch 1540 is 0.00004834\n",
      "Train Loss at Epoch 1541 is 0.00542249\n",
      "Val Loss at Epoch 1541 is 0.00004831\n",
      "Train Loss at Epoch 1542 is 0.00541857\n",
      "Val Loss at Epoch 1542 is 0.00004829\n",
      "Train Loss at Epoch 1543 is 0.00541464\n",
      "Val Loss at Epoch 1543 is 0.00004826\n",
      "Train Loss at Epoch 1544 is 0.00541072\n",
      "Val Loss at Epoch 1544 is 0.00004824\n",
      "Train Loss at Epoch 1545 is 0.00540680\n",
      "Val Loss at Epoch 1545 is 0.00004821\n",
      "Train Loss at Epoch 1546 is 0.00540289\n",
      "Val Loss at Epoch 1546 is 0.00004819\n",
      "Train Loss at Epoch 1547 is 0.00539898\n",
      "Val Loss at Epoch 1547 is 0.00004816\n",
      "Train Loss at Epoch 1548 is 0.00539507\n",
      "Val Loss at Epoch 1548 is 0.00004814\n",
      "Train Loss at Epoch 1549 is 0.00539116\n",
      "Val Loss at Epoch 1549 is 0.00004811\n",
      "Train Loss at Epoch 1550 is 0.00538726\n",
      "Val Loss at Epoch 1550 is 0.00004809\n",
      "Train Loss at Epoch 1551 is 0.00538336\n",
      "Val Loss at Epoch 1551 is 0.00004807\n",
      "Train Loss at Epoch 1552 is 0.00537947\n",
      "Val Loss at Epoch 1552 is 0.00004804\n",
      "Train Loss at Epoch 1553 is 0.00537557\n",
      "Val Loss at Epoch 1553 is 0.00004802\n",
      "Train Loss at Epoch 1554 is 0.00537168\n",
      "Val Loss at Epoch 1554 is 0.00004799\n",
      "Train Loss at Epoch 1555 is 0.00536780\n",
      "Val Loss at Epoch 1555 is 0.00004797\n",
      "Train Loss at Epoch 1556 is 0.00536391\n",
      "Val Loss at Epoch 1556 is 0.00004794\n",
      "Train Loss at Epoch 1557 is 0.00536003\n",
      "Val Loss at Epoch 1557 is 0.00004792\n",
      "Train Loss at Epoch 1558 is 0.00535616\n",
      "Val Loss at Epoch 1558 is 0.00004789\n",
      "Train Loss at Epoch 1559 is 0.00535228\n",
      "Val Loss at Epoch 1559 is 0.00004787\n",
      "Train Loss at Epoch 1560 is 0.00534841\n",
      "Val Loss at Epoch 1560 is 0.00004784\n",
      "Train Loss at Epoch 1561 is 0.00534454\n",
      "Val Loss at Epoch 1561 is 0.00004782\n",
      "Train Loss at Epoch 1562 is 0.00534068\n",
      "Val Loss at Epoch 1562 is 0.00004780\n",
      "Train Loss at Epoch 1563 is 0.00533681\n",
      "Val Loss at Epoch 1563 is 0.00004777\n",
      "Train Loss at Epoch 1564 is 0.00533295\n",
      "Val Loss at Epoch 1564 is 0.00004775\n",
      "Train Loss at Epoch 1565 is 0.00532910\n",
      "Val Loss at Epoch 1565 is 0.00004772\n",
      "Train Loss at Epoch 1566 is 0.00532524\n",
      "Val Loss at Epoch 1566 is 0.00004770\n",
      "Train Loss at Epoch 1567 is 0.00532139\n",
      "Val Loss at Epoch 1567 is 0.00004767\n",
      "Train Loss at Epoch 1568 is 0.00531755\n",
      "Val Loss at Epoch 1568 is 0.00004765\n",
      "Train Loss at Epoch 1569 is 0.00531370\n",
      "Val Loss at Epoch 1569 is 0.00004763\n",
      "Train Loss at Epoch 1570 is 0.00530986\n",
      "Val Loss at Epoch 1570 is 0.00004760\n",
      "Train Loss at Epoch 1571 is 0.00530602\n",
      "Val Loss at Epoch 1571 is 0.00004758\n",
      "Train Loss at Epoch 1572 is 0.00530219\n",
      "Val Loss at Epoch 1572 is 0.00004755\n",
      "Train Loss at Epoch 1573 is 0.00529836\n",
      "Val Loss at Epoch 1573 is 0.00004753\n",
      "Train Loss at Epoch 1574 is 0.00529453\n",
      "Val Loss at Epoch 1574 is 0.00004750\n",
      "Train Loss at Epoch 1575 is 0.00529070\n",
      "Val Loss at Epoch 1575 is 0.00004748\n",
      "Train Loss at Epoch 1576 is 0.00528688\n",
      "Val Loss at Epoch 1576 is 0.00004746\n",
      "Train Loss at Epoch 1577 is 0.00528306\n",
      "Val Loss at Epoch 1577 is 0.00004743\n",
      "Train Loss at Epoch 1578 is 0.00527924\n",
      "Val Loss at Epoch 1578 is 0.00004741\n",
      "Train Loss at Epoch 1579 is 0.00527543\n",
      "Val Loss at Epoch 1579 is 0.00004738\n",
      "Train Loss at Epoch 1580 is 0.00527162\n",
      "Val Loss at Epoch 1580 is 0.00004736\n",
      "Train Loss at Epoch 1581 is 0.00526781\n",
      "Val Loss at Epoch 1581 is 0.00004734\n",
      "Train Loss at Epoch 1582 is 0.00526400\n",
      "Val Loss at Epoch 1582 is 0.00004731\n",
      "Train Loss at Epoch 1583 is 0.00526020\n",
      "Val Loss at Epoch 1583 is 0.00004729\n",
      "Train Loss at Epoch 1584 is 0.00525640\n",
      "Val Loss at Epoch 1584 is 0.00004727\n",
      "Train Loss at Epoch 1585 is 0.00525260\n",
      "Val Loss at Epoch 1585 is 0.00004724\n",
      "Train Loss at Epoch 1586 is 0.00524881\n",
      "Val Loss at Epoch 1586 is 0.00004722\n",
      "Train Loss at Epoch 1587 is 0.00524502\n",
      "Val Loss at Epoch 1587 is 0.00004719\n",
      "Train Loss at Epoch 1588 is 0.00524123\n",
      "Val Loss at Epoch 1588 is 0.00004717\n",
      "Train Loss at Epoch 1589 is 0.00523745\n",
      "Val Loss at Epoch 1589 is 0.00004715\n",
      "Train Loss at Epoch 1590 is 0.00523367\n",
      "Val Loss at Epoch 1590 is 0.00004712\n",
      "Train Loss at Epoch 1591 is 0.00522989\n",
      "Val Loss at Epoch 1591 is 0.00004710\n",
      "Train Loss at Epoch 1592 is 0.00522611\n",
      "Val Loss at Epoch 1592 is 0.00004708\n",
      "Train Loss at Epoch 1593 is 0.00522234\n",
      "Val Loss at Epoch 1593 is 0.00004705\n",
      "Train Loss at Epoch 1594 is 0.00521857\n",
      "Val Loss at Epoch 1594 is 0.00004703\n",
      "Train Loss at Epoch 1595 is 0.00521480\n",
      "Val Loss at Epoch 1595 is 0.00004700\n",
      "Train Loss at Epoch 1596 is 0.00521104\n",
      "Val Loss at Epoch 1596 is 0.00004698\n",
      "Train Loss at Epoch 1597 is 0.00520728\n",
      "Val Loss at Epoch 1597 is 0.00004696\n",
      "Train Loss at Epoch 1598 is 0.00520352\n",
      "Val Loss at Epoch 1598 is 0.00004693\n",
      "Train Loss at Epoch 1599 is 0.00519976\n",
      "Val Loss at Epoch 1599 is 0.00004691\n",
      "Train Loss at Epoch 1600 is 0.00519601\n",
      "Val Loss at Epoch 1600 is 0.00004689\n",
      "Train Loss at Epoch 1601 is 0.00519226\n",
      "Val Loss at Epoch 1601 is 0.00004686\n",
      "Train Loss at Epoch 1602 is 0.00518851\n",
      "Val Loss at Epoch 1602 is 0.00004684\n",
      "Train Loss at Epoch 1603 is 0.00518477\n",
      "Val Loss at Epoch 1603 is 0.00004682\n",
      "Train Loss at Epoch 1604 is 0.00518103\n",
      "Val Loss at Epoch 1604 is 0.00004679\n",
      "Train Loss at Epoch 1605 is 0.00517729\n",
      "Val Loss at Epoch 1605 is 0.00004677\n",
      "Train Loss at Epoch 1606 is 0.00517356\n",
      "Val Loss at Epoch 1606 is 0.00004675\n",
      "Train Loss at Epoch 1607 is 0.00516982\n",
      "Val Loss at Epoch 1607 is 0.00004672\n",
      "Train Loss at Epoch 1608 is 0.00516609\n",
      "Val Loss at Epoch 1608 is 0.00004670\n",
      "Train Loss at Epoch 1609 is 0.00516237\n",
      "Val Loss at Epoch 1609 is 0.00004668\n",
      "Train Loss at Epoch 1610 is 0.00515864\n",
      "Val Loss at Epoch 1610 is 0.00004665\n",
      "Train Loss at Epoch 1611 is 0.00515492\n",
      "Val Loss at Epoch 1611 is 0.00004663\n",
      "Train Loss at Epoch 1612 is 0.00515120\n",
      "Val Loss at Epoch 1612 is 0.00004661\n",
      "Train Loss at Epoch 1613 is 0.00514749\n",
      "Val Loss at Epoch 1613 is 0.00004658\n",
      "Train Loss at Epoch 1614 is 0.00514378\n",
      "Val Loss at Epoch 1614 is 0.00004656\n",
      "Train Loss at Epoch 1615 is 0.00514007\n",
      "Val Loss at Epoch 1615 is 0.00004654\n",
      "Train Loss at Epoch 1616 is 0.00513636\n",
      "Val Loss at Epoch 1616 is 0.00004651\n",
      "Train Loss at Epoch 1617 is 0.00513266\n",
      "Val Loss at Epoch 1617 is 0.00004649\n",
      "Train Loss at Epoch 1618 is 0.00512896\n",
      "Val Loss at Epoch 1618 is 0.00004647\n",
      "Train Loss at Epoch 1619 is 0.00512526\n",
      "Val Loss at Epoch 1619 is 0.00004644\n",
      "Train Loss at Epoch 1620 is 0.00512156\n",
      "Val Loss at Epoch 1620 is 0.00004642\n",
      "Train Loss at Epoch 1621 is 0.00511787\n",
      "Val Loss at Epoch 1621 is 0.00004640\n",
      "Train Loss at Epoch 1622 is 0.00511418\n",
      "Val Loss at Epoch 1622 is 0.00004638\n",
      "Train Loss at Epoch 1623 is 0.00511049\n",
      "Val Loss at Epoch 1623 is 0.00004635\n",
      "Train Loss at Epoch 1624 is 0.00510681\n",
      "Val Loss at Epoch 1624 is 0.00004633\n",
      "Train Loss at Epoch 1625 is 0.00510313\n",
      "Val Loss at Epoch 1625 is 0.00004631\n",
      "Train Loss at Epoch 1626 is 0.00509945\n",
      "Val Loss at Epoch 1626 is 0.00004628\n",
      "Train Loss at Epoch 1627 is 0.00509577\n",
      "Val Loss at Epoch 1627 is 0.00004626\n",
      "Train Loss at Epoch 1628 is 0.00509210\n",
      "Val Loss at Epoch 1628 is 0.00004624\n",
      "Train Loss at Epoch 1629 is 0.00508843\n",
      "Val Loss at Epoch 1629 is 0.00004621\n",
      "Train Loss at Epoch 1630 is 0.00508476\n",
      "Val Loss at Epoch 1630 is 0.00004619\n",
      "Train Loss at Epoch 1631 is 0.00508110\n",
      "Val Loss at Epoch 1631 is 0.00004617\n",
      "Train Loss at Epoch 1632 is 0.00507744\n",
      "Val Loss at Epoch 1632 is 0.00004615\n",
      "Train Loss at Epoch 1633 is 0.00507378\n",
      "Val Loss at Epoch 1633 is 0.00004612\n",
      "Train Loss at Epoch 1634 is 0.00507012\n",
      "Val Loss at Epoch 1634 is 0.00004610\n",
      "Train Loss at Epoch 1635 is 0.00506647\n",
      "Val Loss at Epoch 1635 is 0.00004608\n",
      "Train Loss at Epoch 1636 is 0.00506282\n",
      "Val Loss at Epoch 1636 is 0.00004606\n",
      "Train Loss at Epoch 1637 is 0.00505917\n",
      "Val Loss at Epoch 1637 is 0.00004603\n",
      "Train Loss at Epoch 1638 is 0.00505553\n",
      "Val Loss at Epoch 1638 is 0.00004601\n",
      "Train Loss at Epoch 1639 is 0.00505188\n",
      "Val Loss at Epoch 1639 is 0.00004599\n",
      "Train Loss at Epoch 1640 is 0.00504825\n",
      "Val Loss at Epoch 1640 is 0.00004596\n",
      "Train Loss at Epoch 1641 is 0.00504461\n",
      "Val Loss at Epoch 1641 is 0.00004594\n",
      "Train Loss at Epoch 1642 is 0.00504097\n",
      "Val Loss at Epoch 1642 is 0.00004592\n",
      "Train Loss at Epoch 1643 is 0.00503734\n",
      "Val Loss at Epoch 1643 is 0.00004590\n",
      "Train Loss at Epoch 1644 is 0.00503371\n",
      "Val Loss at Epoch 1644 is 0.00004587\n",
      "Train Loss at Epoch 1645 is 0.00503009\n",
      "Val Loss at Epoch 1645 is 0.00004585\n",
      "Train Loss at Epoch 1646 is 0.00502647\n",
      "Val Loss at Epoch 1646 is 0.00004583\n",
      "Train Loss at Epoch 1647 is 0.00502285\n",
      "Val Loss at Epoch 1647 is 0.00004581\n",
      "Train Loss at Epoch 1648 is 0.00501923\n",
      "Val Loss at Epoch 1648 is 0.00004578\n",
      "Train Loss at Epoch 1649 is 0.00501561\n",
      "Val Loss at Epoch 1649 is 0.00004576\n",
      "Train Loss at Epoch 1650 is 0.00501200\n",
      "Val Loss at Epoch 1650 is 0.00004574\n",
      "Train Loss at Epoch 1651 is 0.00500839\n",
      "Val Loss at Epoch 1651 is 0.00004572\n",
      "Train Loss at Epoch 1652 is 0.00500478\n",
      "Val Loss at Epoch 1652 is 0.00004570\n",
      "Train Loss at Epoch 1653 is 0.00500118\n",
      "Val Loss at Epoch 1653 is 0.00004567\n",
      "Train Loss at Epoch 1654 is 0.00499758\n",
      "Val Loss at Epoch 1654 is 0.00004565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1655 is 0.00499398\n",
      "Val Loss at Epoch 1655 is 0.00004563\n",
      "Train Loss at Epoch 1656 is 0.00499039\n",
      "Val Loss at Epoch 1656 is 0.00004561\n",
      "Train Loss at Epoch 1657 is 0.00498679\n",
      "Val Loss at Epoch 1657 is 0.00004558\n",
      "Train Loss at Epoch 1658 is 0.00498320\n",
      "Val Loss at Epoch 1658 is 0.00004556\n",
      "Train Loss at Epoch 1659 is 0.00497961\n",
      "Val Loss at Epoch 1659 is 0.00004554\n",
      "Train Loss at Epoch 1660 is 0.00497603\n",
      "Val Loss at Epoch 1660 is 0.00004552\n",
      "Train Loss at Epoch 1661 is 0.00497245\n",
      "Val Loss at Epoch 1661 is 0.00004549\n",
      "Train Loss at Epoch 1662 is 0.00496887\n",
      "Val Loss at Epoch 1662 is 0.00004547\n",
      "Train Loss at Epoch 1663 is 0.00496529\n",
      "Val Loss at Epoch 1663 is 0.00004545\n",
      "Train Loss at Epoch 1664 is 0.00496172\n",
      "Val Loss at Epoch 1664 is 0.00004543\n",
      "Train Loss at Epoch 1665 is 0.00495814\n",
      "Val Loss at Epoch 1665 is 0.00004541\n",
      "Train Loss at Epoch 1666 is 0.00495457\n",
      "Val Loss at Epoch 1666 is 0.00004538\n",
      "Train Loss at Epoch 1667 is 0.00495101\n",
      "Val Loss at Epoch 1667 is 0.00004536\n",
      "Train Loss at Epoch 1668 is 0.00494744\n",
      "Val Loss at Epoch 1668 is 0.00004534\n",
      "Train Loss at Epoch 1669 is 0.00494388\n",
      "Val Loss at Epoch 1669 is 0.00004532\n",
      "Train Loss at Epoch 1670 is 0.00494033\n",
      "Val Loss at Epoch 1670 is 0.00004530\n",
      "Train Loss at Epoch 1671 is 0.00493677\n",
      "Val Loss at Epoch 1671 is 0.00004527\n",
      "Train Loss at Epoch 1672 is 0.00493322\n",
      "Val Loss at Epoch 1672 is 0.00004525\n",
      "Train Loss at Epoch 1673 is 0.00492967\n",
      "Val Loss at Epoch 1673 is 0.00004523\n",
      "Train Loss at Epoch 1674 is 0.00492612\n",
      "Val Loss at Epoch 1674 is 0.00004521\n",
      "Train Loss at Epoch 1675 is 0.00492257\n",
      "Val Loss at Epoch 1675 is 0.00004519\n",
      "Train Loss at Epoch 1676 is 0.00491903\n",
      "Val Loss at Epoch 1676 is 0.00004516\n",
      "Train Loss at Epoch 1677 is 0.00491549\n",
      "Val Loss at Epoch 1677 is 0.00004514\n",
      "Train Loss at Epoch 1678 is 0.00491195\n",
      "Val Loss at Epoch 1678 is 0.00004512\n",
      "Train Loss at Epoch 1679 is 0.00490842\n",
      "Val Loss at Epoch 1679 is 0.00004510\n",
      "Train Loss at Epoch 1680 is 0.00490489\n",
      "Val Loss at Epoch 1680 is 0.00004508\n",
      "Train Loss at Epoch 1681 is 0.00490136\n",
      "Val Loss at Epoch 1681 is 0.00004506\n",
      "Train Loss at Epoch 1682 is 0.00489783\n",
      "Val Loss at Epoch 1682 is 0.00004503\n",
      "Train Loss at Epoch 1683 is 0.00489431\n",
      "Val Loss at Epoch 1683 is 0.00004501\n",
      "Train Loss at Epoch 1684 is 0.00489079\n",
      "Val Loss at Epoch 1684 is 0.00004499\n",
      "Train Loss at Epoch 1685 is 0.00488727\n",
      "Val Loss at Epoch 1685 is 0.00004497\n",
      "Train Loss at Epoch 1686 is 0.00488375\n",
      "Val Loss at Epoch 1686 is 0.00004495\n",
      "Train Loss at Epoch 1687 is 0.00488024\n",
      "Val Loss at Epoch 1687 is 0.00004493\n",
      "Train Loss at Epoch 1688 is 0.00487673\n",
      "Val Loss at Epoch 1688 is 0.00004490\n",
      "Train Loss at Epoch 1689 is 0.00487322\n",
      "Val Loss at Epoch 1689 is 0.00004488\n",
      "Train Loss at Epoch 1690 is 0.00486971\n",
      "Val Loss at Epoch 1690 is 0.00004486\n",
      "Train Loss at Epoch 1691 is 0.00486621\n",
      "Val Loss at Epoch 1691 is 0.00004484\n",
      "Train Loss at Epoch 1692 is 0.00486271\n",
      "Val Loss at Epoch 1692 is 0.00004482\n",
      "Train Loss at Epoch 1693 is 0.00485921\n",
      "Val Loss at Epoch 1693 is 0.00004480\n",
      "Train Loss at Epoch 1694 is 0.00485571\n",
      "Val Loss at Epoch 1694 is 0.00004477\n",
      "Train Loss at Epoch 1695 is 0.00485222\n",
      "Val Loss at Epoch 1695 is 0.00004475\n",
      "Train Loss at Epoch 1696 is 0.00484873\n",
      "Val Loss at Epoch 1696 is 0.00004473\n",
      "Train Loss at Epoch 1697 is 0.00484524\n",
      "Val Loss at Epoch 1697 is 0.00004471\n",
      "Train Loss at Epoch 1698 is 0.00484176\n",
      "Val Loss at Epoch 1698 is 0.00004469\n",
      "Train Loss at Epoch 1699 is 0.00483827\n",
      "Val Loss at Epoch 1699 is 0.00004467\n",
      "Train Loss at Epoch 1700 is 0.00483479\n",
      "Val Loss at Epoch 1700 is 0.00004465\n",
      "Train Loss at Epoch 1701 is 0.00483132\n",
      "Val Loss at Epoch 1701 is 0.00004462\n",
      "Train Loss at Epoch 1702 is 0.00482784\n",
      "Val Loss at Epoch 1702 is 0.00004460\n",
      "Train Loss at Epoch 1703 is 0.00482437\n",
      "Val Loss at Epoch 1703 is 0.00004458\n",
      "Train Loss at Epoch 1704 is 0.00482090\n",
      "Val Loss at Epoch 1704 is 0.00004456\n",
      "Train Loss at Epoch 1705 is 0.00481743\n",
      "Val Loss at Epoch 1705 is 0.00004454\n",
      "Train Loss at Epoch 1706 is 0.00481397\n",
      "Val Loss at Epoch 1706 is 0.00004452\n",
      "Train Loss at Epoch 1707 is 0.00481051\n",
      "Val Loss at Epoch 1707 is 0.00004450\n",
      "Train Loss at Epoch 1708 is 0.00480705\n",
      "Val Loss at Epoch 1708 is 0.00004448\n",
      "Train Loss at Epoch 1709 is 0.00480359\n",
      "Val Loss at Epoch 1709 is 0.00004445\n",
      "Train Loss at Epoch 1710 is 0.00480013\n",
      "Val Loss at Epoch 1710 is 0.00004443\n",
      "Train Loss at Epoch 1711 is 0.00479668\n",
      "Val Loss at Epoch 1711 is 0.00004441\n",
      "Train Loss at Epoch 1712 is 0.00479323\n",
      "Val Loss at Epoch 1712 is 0.00004439\n",
      "Train Loss at Epoch 1713 is 0.00478979\n",
      "Val Loss at Epoch 1713 is 0.00004437\n",
      "Train Loss at Epoch 1714 is 0.00478634\n",
      "Val Loss at Epoch 1714 is 0.00004435\n",
      "Train Loss at Epoch 1715 is 0.00478290\n",
      "Val Loss at Epoch 1715 is 0.00004433\n",
      "Train Loss at Epoch 1716 is 0.00477946\n",
      "Val Loss at Epoch 1716 is 0.00004431\n",
      "Train Loss at Epoch 1717 is 0.00477602\n",
      "Val Loss at Epoch 1717 is 0.00004428\n",
      "Train Loss at Epoch 1718 is 0.00477259\n",
      "Val Loss at Epoch 1718 is 0.00004426\n",
      "Train Loss at Epoch 1719 is 0.00476916\n",
      "Val Loss at Epoch 1719 is 0.00004424\n",
      "Train Loss at Epoch 1720 is 0.00476573\n",
      "Val Loss at Epoch 1720 is 0.00004422\n",
      "Train Loss at Epoch 1721 is 0.00476230\n",
      "Val Loss at Epoch 1721 is 0.00004420\n",
      "Train Loss at Epoch 1722 is 0.00475888\n",
      "Val Loss at Epoch 1722 is 0.00004418\n",
      "Train Loss at Epoch 1723 is 0.00475545\n",
      "Val Loss at Epoch 1723 is 0.00004416\n",
      "Train Loss at Epoch 1724 is 0.00475203\n",
      "Val Loss at Epoch 1724 is 0.00004414\n",
      "Train Loss at Epoch 1725 is 0.00474862\n",
      "Val Loss at Epoch 1725 is 0.00004412\n",
      "Train Loss at Epoch 1726 is 0.00474520\n",
      "Val Loss at Epoch 1726 is 0.00004410\n",
      "Train Loss at Epoch 1727 is 0.00474179\n",
      "Val Loss at Epoch 1727 is 0.00004408\n",
      "Train Loss at Epoch 1728 is 0.00473838\n",
      "Val Loss at Epoch 1728 is 0.00004405\n",
      "Train Loss at Epoch 1729 is 0.00473497\n",
      "Val Loss at Epoch 1729 is 0.00004403\n",
      "Train Loss at Epoch 1730 is 0.00473157\n",
      "Val Loss at Epoch 1730 is 0.00004401\n",
      "Train Loss at Epoch 1731 is 0.00472817\n",
      "Val Loss at Epoch 1731 is 0.00004399\n",
      "Train Loss at Epoch 1732 is 0.00472477\n",
      "Val Loss at Epoch 1732 is 0.00004397\n",
      "Train Loss at Epoch 1733 is 0.00472137\n",
      "Val Loss at Epoch 1733 is 0.00004395\n",
      "Train Loss at Epoch 1734 is 0.00471798\n",
      "Val Loss at Epoch 1734 is 0.00004393\n",
      "Train Loss at Epoch 1735 is 0.00471458\n",
      "Val Loss at Epoch 1735 is 0.00004391\n",
      "Train Loss at Epoch 1736 is 0.00471119\n",
      "Val Loss at Epoch 1736 is 0.00004389\n",
      "Train Loss at Epoch 1737 is 0.00470781\n",
      "Val Loss at Epoch 1737 is 0.00004387\n",
      "Train Loss at Epoch 1738 is 0.00470442\n",
      "Val Loss at Epoch 1738 is 0.00004385\n",
      "Train Loss at Epoch 1739 is 0.00470104\n",
      "Val Loss at Epoch 1739 is 0.00004383\n",
      "Train Loss at Epoch 1740 is 0.00469766\n",
      "Val Loss at Epoch 1740 is 0.00004381\n",
      "Train Loss at Epoch 1741 is 0.00469428\n",
      "Val Loss at Epoch 1741 is 0.00004379\n",
      "Train Loss at Epoch 1742 is 0.00469091\n",
      "Val Loss at Epoch 1742 is 0.00004376\n",
      "Train Loss at Epoch 1743 is 0.00468753\n",
      "Val Loss at Epoch 1743 is 0.00004374\n",
      "Train Loss at Epoch 1744 is 0.00468416\n",
      "Val Loss at Epoch 1744 is 0.00004372\n",
      "Train Loss at Epoch 1745 is 0.00468080\n",
      "Val Loss at Epoch 1745 is 0.00004370\n",
      "Train Loss at Epoch 1746 is 0.00467743\n",
      "Val Loss at Epoch 1746 is 0.00004368\n",
      "Train Loss at Epoch 1747 is 0.00467407\n",
      "Val Loss at Epoch 1747 is 0.00004366\n",
      "Train Loss at Epoch 1748 is 0.00467071\n",
      "Val Loss at Epoch 1748 is 0.00004364\n",
      "Train Loss at Epoch 1749 is 0.00466735\n",
      "Val Loss at Epoch 1749 is 0.00004362\n",
      "Train Loss at Epoch 1750 is 0.00466399\n",
      "Val Loss at Epoch 1750 is 0.00004360\n",
      "Train Loss at Epoch 1751 is 0.00466064\n",
      "Val Loss at Epoch 1751 is 0.00004358\n",
      "Train Loss at Epoch 1752 is 0.00465729\n",
      "Val Loss at Epoch 1752 is 0.00004356\n",
      "Train Loss at Epoch 1753 is 0.00465394\n",
      "Val Loss at Epoch 1753 is 0.00004354\n",
      "Train Loss at Epoch 1754 is 0.00465060\n",
      "Val Loss at Epoch 1754 is 0.00004352\n",
      "Train Loss at Epoch 1755 is 0.00464725\n",
      "Val Loss at Epoch 1755 is 0.00004350\n",
      "Train Loss at Epoch 1756 is 0.00464391\n",
      "Val Loss at Epoch 1756 is 0.00004348\n",
      "Train Loss at Epoch 1757 is 0.00464057\n",
      "Val Loss at Epoch 1757 is 0.00004346\n",
      "Train Loss at Epoch 1758 is 0.00463724\n",
      "Val Loss at Epoch 1758 is 0.00004344\n",
      "Train Loss at Epoch 1759 is 0.00463390\n",
      "Val Loss at Epoch 1759 is 0.00004342\n",
      "Train Loss at Epoch 1760 is 0.00463057\n",
      "Val Loss at Epoch 1760 is 0.00004340\n",
      "Train Loss at Epoch 1761 is 0.00462724\n",
      "Val Loss at Epoch 1761 is 0.00004338\n",
      "Train Loss at Epoch 1762 is 0.00462391\n",
      "Val Loss at Epoch 1762 is 0.00004336\n",
      "Train Loss at Epoch 1763 is 0.00462059\n",
      "Val Loss at Epoch 1763 is 0.00004334\n",
      "Train Loss at Epoch 1764 is 0.00461727\n",
      "Val Loss at Epoch 1764 is 0.00004332\n",
      "Train Loss at Epoch 1765 is 0.00461395\n",
      "Val Loss at Epoch 1765 is 0.00004330\n",
      "Train Loss at Epoch 1766 is 0.00461063\n",
      "Val Loss at Epoch 1766 is 0.00004328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1767 is 0.00460732\n",
      "Val Loss at Epoch 1767 is 0.00004326\n",
      "Train Loss at Epoch 1768 is 0.00460400\n",
      "Val Loss at Epoch 1768 is 0.00004324\n",
      "Train Loss at Epoch 1769 is 0.00460069\n",
      "Val Loss at Epoch 1769 is 0.00004321\n",
      "Train Loss at Epoch 1770 is 0.00459739\n",
      "Val Loss at Epoch 1770 is 0.00004319\n",
      "Train Loss at Epoch 1771 is 0.00459408\n",
      "Val Loss at Epoch 1771 is 0.00004317\n",
      "Train Loss at Epoch 1772 is 0.00459078\n",
      "Val Loss at Epoch 1772 is 0.00004315\n",
      "Train Loss at Epoch 1773 is 0.00458748\n",
      "Val Loss at Epoch 1773 is 0.00004313\n",
      "Train Loss at Epoch 1774 is 0.00458418\n",
      "Val Loss at Epoch 1774 is 0.00004311\n",
      "Train Loss at Epoch 1775 is 0.00458088\n",
      "Val Loss at Epoch 1775 is 0.00004309\n",
      "Train Loss at Epoch 1776 is 0.00457759\n",
      "Val Loss at Epoch 1776 is 0.00004307\n",
      "Train Loss at Epoch 1777 is 0.00457430\n",
      "Val Loss at Epoch 1777 is 0.00004305\n",
      "Train Loss at Epoch 1778 is 0.00457101\n",
      "Val Loss at Epoch 1778 is 0.00004303\n",
      "Train Loss at Epoch 1779 is 0.00456772\n",
      "Val Loss at Epoch 1779 is 0.00004301\n",
      "Train Loss at Epoch 1780 is 0.00456444\n",
      "Val Loss at Epoch 1780 is 0.00004299\n",
      "Train Loss at Epoch 1781 is 0.00456115\n",
      "Val Loss at Epoch 1781 is 0.00004297\n",
      "Train Loss at Epoch 1782 is 0.00455787\n",
      "Val Loss at Epoch 1782 is 0.00004296\n",
      "Train Loss at Epoch 1783 is 0.00455460\n",
      "Val Loss at Epoch 1783 is 0.00004294\n",
      "Train Loss at Epoch 1784 is 0.00455132\n",
      "Val Loss at Epoch 1784 is 0.00004292\n",
      "Train Loss at Epoch 1785 is 0.00454805\n",
      "Val Loss at Epoch 1785 is 0.00004290\n",
      "Train Loss at Epoch 1786 is 0.00454478\n",
      "Val Loss at Epoch 1786 is 0.00004288\n",
      "Train Loss at Epoch 1787 is 0.00454151\n",
      "Val Loss at Epoch 1787 is 0.00004286\n",
      "Train Loss at Epoch 1788 is 0.00453825\n",
      "Val Loss at Epoch 1788 is 0.00004284\n",
      "Train Loss at Epoch 1789 is 0.00453498\n",
      "Val Loss at Epoch 1789 is 0.00004282\n",
      "Train Loss at Epoch 1790 is 0.00453172\n",
      "Val Loss at Epoch 1790 is 0.00004280\n",
      "Train Loss at Epoch 1791 is 0.00452846\n",
      "Val Loss at Epoch 1791 is 0.00004278\n",
      "Train Loss at Epoch 1792 is 0.00452521\n",
      "Val Loss at Epoch 1792 is 0.00004276\n",
      "Train Loss at Epoch 1793 is 0.00452195\n",
      "Val Loss at Epoch 1793 is 0.00004274\n",
      "Train Loss at Epoch 1794 is 0.00451870\n",
      "Val Loss at Epoch 1794 is 0.00004272\n",
      "Train Loss at Epoch 1795 is 0.00451545\n",
      "Val Loss at Epoch 1795 is 0.00004270\n",
      "Train Loss at Epoch 1796 is 0.00451220\n",
      "Val Loss at Epoch 1796 is 0.00004268\n",
      "Train Loss at Epoch 1797 is 0.00450896\n",
      "Val Loss at Epoch 1797 is 0.00004266\n",
      "Train Loss at Epoch 1798 is 0.00450571\n",
      "Val Loss at Epoch 1798 is 0.00004264\n",
      "Train Loss at Epoch 1799 is 0.00450247\n",
      "Val Loss at Epoch 1799 is 0.00004262\n",
      "Train Loss at Epoch 1800 is 0.00449924\n",
      "Val Loss at Epoch 1800 is 0.00004260\n",
      "Train Loss at Epoch 1801 is 0.00449600\n",
      "Val Loss at Epoch 1801 is 0.00004258\n",
      "Train Loss at Epoch 1802 is 0.00449277\n",
      "Val Loss at Epoch 1802 is 0.00004256\n",
      "Train Loss at Epoch 1803 is 0.00448954\n",
      "Val Loss at Epoch 1803 is 0.00004254\n",
      "Train Loss at Epoch 1804 is 0.00448631\n",
      "Val Loss at Epoch 1804 is 0.00004252\n",
      "Train Loss at Epoch 1805 is 0.00448308\n",
      "Val Loss at Epoch 1805 is 0.00004250\n",
      "Train Loss at Epoch 1806 is 0.00447986\n",
      "Val Loss at Epoch 1806 is 0.00004248\n",
      "Train Loss at Epoch 1807 is 0.00447663\n",
      "Val Loss at Epoch 1807 is 0.00004246\n",
      "Train Loss at Epoch 1808 is 0.00447341\n",
      "Val Loss at Epoch 1808 is 0.00004244\n",
      "Train Loss at Epoch 1809 is 0.00447020\n",
      "Val Loss at Epoch 1809 is 0.00004242\n",
      "Train Loss at Epoch 1810 is 0.00446698\n",
      "Val Loss at Epoch 1810 is 0.00004240\n",
      "Train Loss at Epoch 1811 is 0.00446377\n",
      "Val Loss at Epoch 1811 is 0.00004239\n",
      "Train Loss at Epoch 1812 is 0.00446056\n",
      "Val Loss at Epoch 1812 is 0.00004237\n",
      "Train Loss at Epoch 1813 is 0.00445735\n",
      "Val Loss at Epoch 1813 is 0.00004235\n",
      "Train Loss at Epoch 1814 is 0.00445414\n",
      "Val Loss at Epoch 1814 is 0.00004233\n",
      "Train Loss at Epoch 1815 is 0.00445094\n",
      "Val Loss at Epoch 1815 is 0.00004231\n",
      "Train Loss at Epoch 1816 is 0.00444773\n",
      "Val Loss at Epoch 1816 is 0.00004229\n",
      "Train Loss at Epoch 1817 is 0.00444453\n",
      "Val Loss at Epoch 1817 is 0.00004227\n",
      "Train Loss at Epoch 1818 is 0.00444134\n",
      "Val Loss at Epoch 1818 is 0.00004225\n",
      "Train Loss at Epoch 1819 is 0.00443814\n",
      "Val Loss at Epoch 1819 is 0.00004223\n",
      "Train Loss at Epoch 1820 is 0.00443495\n",
      "Val Loss at Epoch 1820 is 0.00004221\n",
      "Train Loss at Epoch 1821 is 0.00443176\n",
      "Val Loss at Epoch 1821 is 0.00004219\n",
      "Train Loss at Epoch 1822 is 0.00442857\n",
      "Val Loss at Epoch 1822 is 0.00004217\n",
      "Train Loss at Epoch 1823 is 0.00442538\n",
      "Val Loss at Epoch 1823 is 0.00004215\n",
      "Train Loss at Epoch 1824 is 0.00442220\n",
      "Val Loss at Epoch 1824 is 0.00004213\n",
      "Train Loss at Epoch 1825 is 0.00441902\n",
      "Val Loss at Epoch 1825 is 0.00004212\n",
      "Train Loss at Epoch 1826 is 0.00441584\n",
      "Val Loss at Epoch 1826 is 0.00004210\n",
      "Train Loss at Epoch 1827 is 0.00441266\n",
      "Val Loss at Epoch 1827 is 0.00004208\n",
      "Train Loss at Epoch 1828 is 0.00440949\n",
      "Val Loss at Epoch 1828 is 0.00004206\n",
      "Train Loss at Epoch 1829 is 0.00440631\n",
      "Val Loss at Epoch 1829 is 0.00004204\n",
      "Train Loss at Epoch 1830 is 0.00440314\n",
      "Val Loss at Epoch 1830 is 0.00004202\n",
      "Train Loss at Epoch 1831 is 0.00439997\n",
      "Val Loss at Epoch 1831 is 0.00004200\n",
      "Train Loss at Epoch 1832 is 0.00439681\n",
      "Val Loss at Epoch 1832 is 0.00004198\n",
      "Train Loss at Epoch 1833 is 0.00439364\n",
      "Val Loss at Epoch 1833 is 0.00004196\n",
      "Train Loss at Epoch 1834 is 0.00439048\n",
      "Val Loss at Epoch 1834 is 0.00004194\n",
      "Train Loss at Epoch 1835 is 0.00438732\n",
      "Val Loss at Epoch 1835 is 0.00004192\n",
      "Train Loss at Epoch 1836 is 0.00438416\n",
      "Val Loss at Epoch 1836 is 0.00004191\n",
      "Train Loss at Epoch 1837 is 0.00438101\n",
      "Val Loss at Epoch 1837 is 0.00004189\n",
      "Train Loss at Epoch 1838 is 0.00437785\n",
      "Val Loss at Epoch 1838 is 0.00004187\n",
      "Train Loss at Epoch 1839 is 0.00437470\n",
      "Val Loss at Epoch 1839 is 0.00004185\n",
      "Train Loss at Epoch 1840 is 0.00437155\n",
      "Val Loss at Epoch 1840 is 0.00004183\n",
      "Train Loss at Epoch 1841 is 0.00436841\n",
      "Val Loss at Epoch 1841 is 0.00004181\n",
      "Train Loss at Epoch 1842 is 0.00436526\n",
      "Val Loss at Epoch 1842 is 0.00004179\n",
      "Train Loss at Epoch 1843 is 0.00436212\n",
      "Val Loss at Epoch 1843 is 0.00004177\n",
      "Train Loss at Epoch 1844 is 0.00435898\n",
      "Val Loss at Epoch 1844 is 0.00004175\n",
      "Train Loss at Epoch 1845 is 0.00435584\n",
      "Val Loss at Epoch 1845 is 0.00004173\n",
      "Train Loss at Epoch 1846 is 0.00435271\n",
      "Val Loss at Epoch 1846 is 0.00004172\n",
      "Train Loss at Epoch 1847 is 0.00434957\n",
      "Val Loss at Epoch 1847 is 0.00004170\n",
      "Train Loss at Epoch 1848 is 0.00434644\n",
      "Val Loss at Epoch 1848 is 0.00004168\n",
      "Train Loss at Epoch 1849 is 0.00434331\n",
      "Val Loss at Epoch 1849 is 0.00004166\n",
      "Train Loss at Epoch 1850 is 0.00434018\n",
      "Val Loss at Epoch 1850 is 0.00004164\n",
      "Train Loss at Epoch 1851 is 0.00433706\n",
      "Val Loss at Epoch 1851 is 0.00004162\n",
      "Train Loss at Epoch 1852 is 0.00433394\n",
      "Val Loss at Epoch 1852 is 0.00004160\n",
      "Train Loss at Epoch 1853 is 0.00433082\n",
      "Val Loss at Epoch 1853 is 0.00004158\n",
      "Train Loss at Epoch 1854 is 0.00432770\n",
      "Val Loss at Epoch 1854 is 0.00004157\n",
      "Train Loss at Epoch 1855 is 0.00432458\n",
      "Val Loss at Epoch 1855 is 0.00004155\n",
      "Train Loss at Epoch 1856 is 0.00432147\n",
      "Val Loss at Epoch 1856 is 0.00004153\n",
      "Train Loss at Epoch 1857 is 0.00431835\n",
      "Val Loss at Epoch 1857 is 0.00004151\n",
      "Train Loss at Epoch 1858 is 0.00431524\n",
      "Val Loss at Epoch 1858 is 0.00004149\n",
      "Train Loss at Epoch 1859 is 0.00431214\n",
      "Val Loss at Epoch 1859 is 0.00004147\n",
      "Train Loss at Epoch 1860 is 0.00430903\n",
      "Val Loss at Epoch 1860 is 0.00004145\n",
      "Train Loss at Epoch 1861 is 0.00430593\n",
      "Val Loss at Epoch 1861 is 0.00004143\n",
      "Train Loss at Epoch 1862 is 0.00430283\n",
      "Val Loss at Epoch 1862 is 0.00004142\n",
      "Train Loss at Epoch 1863 is 0.00429973\n",
      "Val Loss at Epoch 1863 is 0.00004140\n",
      "Train Loss at Epoch 1864 is 0.00429663\n",
      "Val Loss at Epoch 1864 is 0.00004138\n",
      "Train Loss at Epoch 1865 is 0.00429353\n",
      "Val Loss at Epoch 1865 is 0.00004136\n",
      "Train Loss at Epoch 1866 is 0.00429044\n",
      "Val Loss at Epoch 1866 is 0.00004134\n",
      "Train Loss at Epoch 1867 is 0.00428735\n",
      "Val Loss at Epoch 1867 is 0.00004132\n",
      "Train Loss at Epoch 1868 is 0.00428426\n",
      "Val Loss at Epoch 1868 is 0.00004130\n",
      "Train Loss at Epoch 1869 is 0.00428117\n",
      "Val Loss at Epoch 1869 is 0.00004129\n",
      "Train Loss at Epoch 1870 is 0.00427809\n",
      "Val Loss at Epoch 1870 is 0.00004127\n",
      "Train Loss at Epoch 1871 is 0.00427501\n",
      "Val Loss at Epoch 1871 is 0.00004125\n",
      "Train Loss at Epoch 1872 is 0.00427193\n",
      "Val Loss at Epoch 1872 is 0.00004123\n",
      "Train Loss at Epoch 1873 is 0.00426885\n",
      "Val Loss at Epoch 1873 is 0.00004121\n",
      "Train Loss at Epoch 1874 is 0.00426577\n",
      "Val Loss at Epoch 1874 is 0.00004119\n",
      "Train Loss at Epoch 1875 is 0.00426270\n",
      "Val Loss at Epoch 1875 is 0.00004117\n",
      "Train Loss at Epoch 1876 is 0.00425963\n",
      "Val Loss at Epoch 1876 is 0.00004116\n",
      "Train Loss at Epoch 1877 is 0.00425656\n",
      "Val Loss at Epoch 1877 is 0.00004114\n",
      "Train Loss at Epoch 1878 is 0.00425349\n",
      "Val Loss at Epoch 1878 is 0.00004112\n",
      "Train Loss at Epoch 1879 is 0.00425042\n",
      "Val Loss at Epoch 1879 is 0.00004110\n",
      "Train Loss at Epoch 1880 is 0.00424736\n",
      "Val Loss at Epoch 1880 is 0.00004108\n",
      "Train Loss at Epoch 1881 is 0.00424430\n",
      "Val Loss at Epoch 1881 is 0.00004106\n",
      "Train Loss at Epoch 1882 is 0.00424124\n",
      "Val Loss at Epoch 1882 is 0.00004105\n",
      "Train Loss at Epoch 1883 is 0.00423818\n",
      "Val Loss at Epoch 1883 is 0.00004103\n",
      "Train Loss at Epoch 1884 is 0.00423513\n",
      "Val Loss at Epoch 1884 is 0.00004101\n",
      "Train Loss at Epoch 1885 is 0.00423207\n",
      "Val Loss at Epoch 1885 is 0.00004099\n",
      "Train Loss at Epoch 1886 is 0.00422902\n",
      "Val Loss at Epoch 1886 is 0.00004097\n",
      "Train Loss at Epoch 1887 is 0.00422597\n",
      "Val Loss at Epoch 1887 is 0.00004095\n",
      "Train Loss at Epoch 1888 is 0.00422293\n",
      "Val Loss at Epoch 1888 is 0.00004094\n",
      "Train Loss at Epoch 1889 is 0.00421988\n",
      "Val Loss at Epoch 1889 is 0.00004092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 1890 is 0.00421684\n",
      "Val Loss at Epoch 1890 is 0.00004090\n",
      "Train Loss at Epoch 1891 is 0.00421380\n",
      "Val Loss at Epoch 1891 is 0.00004088\n",
      "Train Loss at Epoch 1892 is 0.00421076\n",
      "Val Loss at Epoch 1892 is 0.00004086\n",
      "Train Loss at Epoch 1893 is 0.00420772\n",
      "Val Loss at Epoch 1893 is 0.00004084\n",
      "Train Loss at Epoch 1894 is 0.00420469\n",
      "Val Loss at Epoch 1894 is 0.00004083\n",
      "Train Loss at Epoch 1895 is 0.00420165\n",
      "Val Loss at Epoch 1895 is 0.00004081\n",
      "Train Loss at Epoch 1896 is 0.00419862\n",
      "Val Loss at Epoch 1896 is 0.00004079\n",
      "Train Loss at Epoch 1897 is 0.00419559\n",
      "Val Loss at Epoch 1897 is 0.00004077\n",
      "Train Loss at Epoch 1898 is 0.00419257\n",
      "Val Loss at Epoch 1898 is 0.00004075\n",
      "Train Loss at Epoch 1899 is 0.00418954\n",
      "Val Loss at Epoch 1899 is 0.00004074\n",
      "Train Loss at Epoch 1900 is 0.00418652\n",
      "Val Loss at Epoch 1900 is 0.00004072\n",
      "Train Loss at Epoch 1901 is 0.00418350\n",
      "Val Loss at Epoch 1901 is 0.00004070\n",
      "Train Loss at Epoch 1902 is 0.00418048\n",
      "Val Loss at Epoch 1902 is 0.00004068\n",
      "Train Loss at Epoch 1903 is 0.00417747\n",
      "Val Loss at Epoch 1903 is 0.00004066\n",
      "Train Loss at Epoch 1904 is 0.00417445\n",
      "Val Loss at Epoch 1904 is 0.00004065\n",
      "Train Loss at Epoch 1905 is 0.00417144\n",
      "Val Loss at Epoch 1905 is 0.00004063\n",
      "Train Loss at Epoch 1906 is 0.00416843\n",
      "Val Loss at Epoch 1906 is 0.00004061\n",
      "Train Loss at Epoch 1907 is 0.00416542\n",
      "Val Loss at Epoch 1907 is 0.00004059\n",
      "Train Loss at Epoch 1908 is 0.00416241\n",
      "Val Loss at Epoch 1908 is 0.00004057\n",
      "Train Loss at Epoch 1909 is 0.00415941\n",
      "Val Loss at Epoch 1909 is 0.00004056\n",
      "Train Loss at Epoch 1910 is 0.00415641\n",
      "Val Loss at Epoch 1910 is 0.00004054\n",
      "Train Loss at Epoch 1911 is 0.00415341\n",
      "Val Loss at Epoch 1911 is 0.00004052\n",
      "Train Loss at Epoch 1912 is 0.00415041\n",
      "Val Loss at Epoch 1912 is 0.00004050\n",
      "Train Loss at Epoch 1913 is 0.00414741\n",
      "Val Loss at Epoch 1913 is 0.00004048\n",
      "Train Loss at Epoch 1914 is 0.00414442\n",
      "Val Loss at Epoch 1914 is 0.00004047\n",
      "Train Loss at Epoch 1915 is 0.00414143\n",
      "Val Loss at Epoch 1915 is 0.00004045\n",
      "Train Loss at Epoch 1916 is 0.00413844\n",
      "Val Loss at Epoch 1916 is 0.00004043\n",
      "Train Loss at Epoch 1917 is 0.00413545\n",
      "Val Loss at Epoch 1917 is 0.00004041\n",
      "Train Loss at Epoch 1918 is 0.00413246\n",
      "Val Loss at Epoch 1918 is 0.00004039\n",
      "Train Loss at Epoch 1919 is 0.00412948\n",
      "Val Loss at Epoch 1919 is 0.00004038\n",
      "Train Loss at Epoch 1920 is 0.00412649\n",
      "Val Loss at Epoch 1920 is 0.00004036\n",
      "Train Loss at Epoch 1921 is 0.00412351\n",
      "Val Loss at Epoch 1921 is 0.00004034\n",
      "Train Loss at Epoch 1922 is 0.00412054\n",
      "Val Loss at Epoch 1922 is 0.00004032\n",
      "Train Loss at Epoch 1923 is 0.00411756\n",
      "Val Loss at Epoch 1923 is 0.00004030\n",
      "Train Loss at Epoch 1924 is 0.00411458\n",
      "Val Loss at Epoch 1924 is 0.00004029\n",
      "Train Loss at Epoch 1925 is 0.00411161\n",
      "Val Loss at Epoch 1925 is 0.00004027\n",
      "Train Loss at Epoch 1926 is 0.00410864\n",
      "Val Loss at Epoch 1926 is 0.00004025\n",
      "Train Loss at Epoch 1927 is 0.00410567\n",
      "Val Loss at Epoch 1927 is 0.00004023\n",
      "Train Loss at Epoch 1928 is 0.00410271\n",
      "Val Loss at Epoch 1928 is 0.00004022\n",
      "Train Loss at Epoch 1929 is 0.00409974\n",
      "Val Loss at Epoch 1929 is 0.00004020\n",
      "Train Loss at Epoch 1930 is 0.00409678\n",
      "Val Loss at Epoch 1930 is 0.00004018\n",
      "Train Loss at Epoch 1931 is 0.00409382\n",
      "Val Loss at Epoch 1931 is 0.00004016\n",
      "Train Loss at Epoch 1932 is 0.00409086\n",
      "Val Loss at Epoch 1932 is 0.00004014\n",
      "Train Loss at Epoch 1933 is 0.00408790\n",
      "Val Loss at Epoch 1933 is 0.00004013\n",
      "Train Loss at Epoch 1934 is 0.00408495\n",
      "Val Loss at Epoch 1934 is 0.00004011\n",
      "Train Loss at Epoch 1935 is 0.00408200\n",
      "Val Loss at Epoch 1935 is 0.00004009\n",
      "Train Loss at Epoch 1936 is 0.00407904\n",
      "Val Loss at Epoch 1936 is 0.00004007\n",
      "Train Loss at Epoch 1937 is 0.00407610\n",
      "Val Loss at Epoch 1937 is 0.00004006\n",
      "Train Loss at Epoch 1938 is 0.00407315\n",
      "Val Loss at Epoch 1938 is 0.00004004\n",
      "Train Loss at Epoch 1939 is 0.00407020\n",
      "Val Loss at Epoch 1939 is 0.00004002\n",
      "Train Loss at Epoch 1940 is 0.00406726\n",
      "Val Loss at Epoch 1940 is 0.00004000\n",
      "Train Loss at Epoch 1941 is 0.00406432\n",
      "Val Loss at Epoch 1941 is 0.00003999\n",
      "Train Loss at Epoch 1942 is 0.00406138\n",
      "Val Loss at Epoch 1942 is 0.00003997\n",
      "Train Loss at Epoch 1943 is 0.00405844\n",
      "Val Loss at Epoch 1943 is 0.00003995\n",
      "Train Loss at Epoch 1944 is 0.00405551\n",
      "Val Loss at Epoch 1944 is 0.00003993\n",
      "Train Loss at Epoch 1945 is 0.00405257\n",
      "Val Loss at Epoch 1945 is 0.00003992\n",
      "Train Loss at Epoch 1946 is 0.00404964\n",
      "Val Loss at Epoch 1946 is 0.00003990\n",
      "Train Loss at Epoch 1947 is 0.00404671\n",
      "Val Loss at Epoch 1947 is 0.00003988\n",
      "Train Loss at Epoch 1948 is 0.00404378\n",
      "Val Loss at Epoch 1948 is 0.00003986\n",
      "Train Loss at Epoch 1949 is 0.00404086\n",
      "Val Loss at Epoch 1949 is 0.00003985\n",
      "Train Loss at Epoch 1950 is 0.00403793\n",
      "Val Loss at Epoch 1950 is 0.00003983\n",
      "Train Loss at Epoch 1951 is 0.00403501\n",
      "Val Loss at Epoch 1951 is 0.00003981\n",
      "Train Loss at Epoch 1952 is 0.00403209\n",
      "Val Loss at Epoch 1952 is 0.00003979\n",
      "Train Loss at Epoch 1953 is 0.00402917\n",
      "Val Loss at Epoch 1953 is 0.00003978\n",
      "Train Loss at Epoch 1954 is 0.00402626\n",
      "Val Loss at Epoch 1954 is 0.00003976\n",
      "Train Loss at Epoch 1955 is 0.00402334\n",
      "Val Loss at Epoch 1955 is 0.00003974\n",
      "Train Loss at Epoch 1956 is 0.00402043\n",
      "Val Loss at Epoch 1956 is 0.00003972\n",
      "Train Loss at Epoch 1957 is 0.00401752\n",
      "Val Loss at Epoch 1957 is 0.00003971\n",
      "Train Loss at Epoch 1958 is 0.00401461\n",
      "Val Loss at Epoch 1958 is 0.00003969\n",
      "Train Loss at Epoch 1959 is 0.00401171\n",
      "Val Loss at Epoch 1959 is 0.00003967\n",
      "Train Loss at Epoch 1960 is 0.00400880\n",
      "Val Loss at Epoch 1960 is 0.00003965\n",
      "Train Loss at Epoch 1961 is 0.00400590\n",
      "Val Loss at Epoch 1961 is 0.00003964\n",
      "Train Loss at Epoch 1962 is 0.00400300\n",
      "Val Loss at Epoch 1962 is 0.00003962\n",
      "Train Loss at Epoch 1963 is 0.00400010\n",
      "Val Loss at Epoch 1963 is 0.00003960\n",
      "Train Loss at Epoch 1964 is 0.00399720\n",
      "Val Loss at Epoch 1964 is 0.00003958\n",
      "Train Loss at Epoch 1965 is 0.00399430\n",
      "Val Loss at Epoch 1965 is 0.00003957\n",
      "Train Loss at Epoch 1966 is 0.00399141\n",
      "Val Loss at Epoch 1966 is 0.00003955\n",
      "Train Loss at Epoch 1967 is 0.00398852\n",
      "Val Loss at Epoch 1967 is 0.00003953\n",
      "Train Loss at Epoch 1968 is 0.00398563\n",
      "Val Loss at Epoch 1968 is 0.00003951\n",
      "Train Loss at Epoch 1969 is 0.00398274\n",
      "Val Loss at Epoch 1969 is 0.00003950\n",
      "Train Loss at Epoch 1970 is 0.00397985\n",
      "Val Loss at Epoch 1970 is 0.00003948\n",
      "Train Loss at Epoch 1971 is 0.00397697\n",
      "Val Loss at Epoch 1971 is 0.00003946\n",
      "Train Loss at Epoch 1972 is 0.00397409\n",
      "Val Loss at Epoch 1972 is 0.00003945\n",
      "Train Loss at Epoch 1973 is 0.00397121\n",
      "Val Loss at Epoch 1973 is 0.00003943\n",
      "Train Loss at Epoch 1974 is 0.00396833\n",
      "Val Loss at Epoch 1974 is 0.00003941\n",
      "Train Loss at Epoch 1975 is 0.00396545\n",
      "Val Loss at Epoch 1975 is 0.00003939\n",
      "Train Loss at Epoch 1976 is 0.00396258\n",
      "Val Loss at Epoch 1976 is 0.00003938\n",
      "Train Loss at Epoch 1977 is 0.00395970\n",
      "Val Loss at Epoch 1977 is 0.00003936\n",
      "Train Loss at Epoch 1978 is 0.00395683\n",
      "Val Loss at Epoch 1978 is 0.00003934\n",
      "Train Loss at Epoch 1979 is 0.00395396\n",
      "Val Loss at Epoch 1979 is 0.00003932\n",
      "Train Loss at Epoch 1980 is 0.00395109\n",
      "Val Loss at Epoch 1980 is 0.00003931\n",
      "Train Loss at Epoch 1981 is 0.00394823\n",
      "Val Loss at Epoch 1981 is 0.00003929\n",
      "Train Loss at Epoch 1982 is 0.00394536\n",
      "Val Loss at Epoch 1982 is 0.00003927\n",
      "Train Loss at Epoch 1983 is 0.00394250\n",
      "Val Loss at Epoch 1983 is 0.00003926\n",
      "Train Loss at Epoch 1984 is 0.00393964\n",
      "Val Loss at Epoch 1984 is 0.00003924\n",
      "Train Loss at Epoch 1985 is 0.00393678\n",
      "Val Loss at Epoch 1985 is 0.00003922\n",
      "Train Loss at Epoch 1986 is 0.00393393\n",
      "Val Loss at Epoch 1986 is 0.00003920\n",
      "Train Loss at Epoch 1987 is 0.00393107\n",
      "Val Loss at Epoch 1987 is 0.00003919\n",
      "Train Loss at Epoch 1988 is 0.00392822\n",
      "Val Loss at Epoch 1988 is 0.00003917\n",
      "Train Loss at Epoch 1989 is 0.00392537\n",
      "Val Loss at Epoch 1989 is 0.00003915\n",
      "Train Loss at Epoch 1990 is 0.00392252\n",
      "Val Loss at Epoch 1990 is 0.00003914\n",
      "Train Loss at Epoch 1991 is 0.00391967\n",
      "Val Loss at Epoch 1991 is 0.00003912\n",
      "Train Loss at Epoch 1992 is 0.00391682\n",
      "Val Loss at Epoch 1992 is 0.00003910\n",
      "Train Loss at Epoch 1993 is 0.00391398\n",
      "Val Loss at Epoch 1993 is 0.00003908\n",
      "Train Loss at Epoch 1994 is 0.00391114\n",
      "Val Loss at Epoch 1994 is 0.00003907\n",
      "Train Loss at Epoch 1995 is 0.00390830\n",
      "Val Loss at Epoch 1995 is 0.00003905\n",
      "Train Loss at Epoch 1996 is 0.00390546\n",
      "Val Loss at Epoch 1996 is 0.00003903\n",
      "Train Loss at Epoch 1997 is 0.00390262\n",
      "Val Loss at Epoch 1997 is 0.00003902\n",
      "Train Loss at Epoch 1998 is 0.00389979\n",
      "Val Loss at Epoch 1998 is 0.00003900\n",
      "Train Loss at Epoch 1999 is 0.00389695\n",
      "Val Loss at Epoch 1999 is 0.00003898\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, 16, 2000, (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "[[0.9768986 ]\n",
      " [1.28180966]\n",
      " [1.587677  ]\n",
      " [1.8925887 ]]\n",
      "y_test\n",
      "[[0.98]\n",
      " [1.28]\n",
      " [1.58]\n",
      " [1.88]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print('y_pred'); print(y_pred)\n",
    "print('y_test'); print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses의 결과를 이전과 같이 시각화하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7b25f77b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loss의 결과를 시각화하세요.\n",
    "pd.DataFrame(hist).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7b2f48f28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(hist)[1980:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
